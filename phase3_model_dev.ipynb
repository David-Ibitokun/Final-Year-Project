{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "bd81e7aa",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c491b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: False - []\n",
      "âœ“ All libraries imported successfully!\n",
      "TensorFlow version: 2.20.0\n",
      "Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Check for GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"GPU available: {len(gpus) > 0} - {gpus}\")\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(f\"âœ“ All libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f302f79e",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9096f0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Configuration complete\n",
      "  CNN features: 26\n",
      "  GRU features: 26\n",
      "  Hybrid temporal: 17\n",
      "  Hybrid static: 13\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "data_path = Path('project_data')\n",
    "splits_path = data_path / 'train_test_split'\n",
    "\n",
    "# Crops and regions\n",
    "CROPS = ['Maize', 'Rice', 'Cassava', 'Yams']\n",
    "ZONES = [\"North West\", \"North East\", \"North Central\", \"South West\", \"South East\", \"South South\"]\n",
    "\n",
    "# Feature columns\n",
    "cnn_feature_cols = [\n",
    "    'Temperature_C', 'Rainfall_mm', 'Humidity_percent', 'CO2_ppm',\n",
    "    'GDD', 'Cumulative_Rainfall', 'Days_Into_Season',\n",
    "    'pH_Temperature_Interaction', 'Nitrogen_Rainfall_Interaction',\n",
    "    'Is_Rainy_Season', 'Is_Peak_Growing',\n",
    "    'Heat_Stress', 'Cold_Stress', 'Rainfall_Anomaly',\n",
    "    'Drought_Risk', 'Flood_Risk',\n",
    "    # Lag features\n",
    "    'Yield_Lag_1', 'Yield_Lag_2', 'Yield_Lag_3',\n",
    "    'Yield_MA_3yr', 'Temp_MA_3yr', 'Rain_MA_3yr',\n",
    "    'Yield_YoY_Change', 'Temp_YoY_Change', 'Rain_YoY_Change',\n",
    "    'Yield_Volatility_3yr'\n",
    "]\n",
    "\n",
    "gru_feature_cols = cnn_feature_cols.copy()  # Same features for GRU\n",
    "\n",
    "# Hybrid features\n",
    "hybrid_temporal_cols = [\n",
    "    'Temperature_C', 'Rainfall_mm', 'Humidity_percent', 'CO2_ppm',\n",
    "    'GDD', 'Cumulative_Rainfall', 'Days_Into_Season',\n",
    "    'Is_Rainy_Season', 'Is_Peak_Growing',\n",
    "    'Heat_Stress', 'Cold_Stress', 'Rainfall_Anomaly',\n",
    "    'Drought_Risk', 'Flood_Risk',\n",
    "    'Yield_Lag_1', 'Yield_MA_3yr', 'Yield_YoY_Change'\n",
    "]\n",
    "\n",
    "hybrid_static_cols = [\n",
    "    'Avg_pH', 'Avg_Nitrogen_ppm', 'Avg_Phosphorus_ppm', 'Avg_Organic_Matter_Percent',\n",
    "    'pH_Temperature_Interaction', 'Nitrogen_Rainfall_Interaction',\n",
    "    'Yield_Lag_2', 'Yield_Lag_3', 'Temp_MA_3yr', 'Rain_MA_3yr',\n",
    "    'Temp_YoY_Change', 'Rain_YoY_Change', 'Yield_Volatility_3yr'\n",
    "]\n",
    "\n",
    "target_col = 'Yield_kg_per_ha'\n",
    "\n",
    "print(\"âœ“ Configuration complete\")\n",
    "print(f\"  CNN features: {len(cnn_feature_cols)}\")\n",
    "print(f\"  GRU features: {len(gru_feature_cols)}\")\n",
    "print(f\"  Hybrid temporal: {len(hybrid_temporal_cols)}\")\n",
    "print(f\"  Hybrid static: {len(hybrid_static_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae0106",
   "metadata": {},
   "source": [
    "---\n",
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f1831d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "def categorize_yield_balanced(yields, method='percentile'):\n",
    "    \"\"\"\n",
    "    Categorize yields into Low/Medium/High with balanced thresholds.\n",
    "    \"\"\"\n",
    "    if method == 'percentile':\n",
    "        low_thresh = np.percentile(yields, 33.33)\n",
    "        high_thresh = np.percentile(yields, 66.67)\n",
    "    else:\n",
    "        low_thresh = 5.0\n",
    "        high_thresh = 15.0\n",
    "    \n",
    "    categories = np.zeros(len(yields), dtype=int)\n",
    "    categories[yields <= low_thresh] = 0  # Low\n",
    "    categories[(yields > low_thresh) & (yields <= high_thresh)] = 1  # Medium\n",
    "    categories[yields > high_thresh] = 2  # High\n",
    "    \n",
    "    return categories, (low_thresh, high_thresh)\n",
    "\n",
    "def augment_data(X, y, num_augmented=2, noise_level=0.05):\n",
    "    \"\"\"\n",
    "    Augment training data with Gaussian noise.\n",
    "    \"\"\"\n",
    "    X_list = [X]\n",
    "    y_list = [y]\n",
    "    \n",
    "    feature_stds = np.std(X, axis=0)\n",
    "    \n",
    "    for i in range(num_augmented):\n",
    "        noise = np.random.normal(0, noise_level, size=X.shape) * feature_stds\n",
    "        X_noisy = X + noise\n",
    "        X_noisy = np.clip(X_noisy, X.min(axis=0) * 0.8, X.max(axis=0) * 1.2)\n",
    "        \n",
    "        X_list.append(X_noisy)\n",
    "        y_list.append(y)\n",
    "    \n",
    "    X_augmented = np.vstack(X_list)\n",
    "    y_augmented = np.vstack(y_list)\n",
    "    \n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "def augment_time_series(X, y, num_augmented=1, noise_level=0.03):\n",
    "    \"\"\"\n",
    "    Augment time series data with noise.\n",
    "    \"\"\"\n",
    "    X_list = [X]\n",
    "    y_list = [y]\n",
    "    \n",
    "    feature_stds = np.std(X.reshape(-1, X.shape[2]), axis=0)\n",
    "    \n",
    "    for i in range(num_augmented):\n",
    "        noise = np.random.normal(0, noise_level, size=X.shape) * feature_stds\n",
    "        X_noisy = X + noise\n",
    "        X_noisy = np.clip(X_noisy, X.min(axis=(0,1)) * 0.8, X.max(axis=(0,1)) * 1.2)\n",
    "        \n",
    "        X_list.append(X_noisy)\n",
    "        y_list.append(y)\n",
    "    \n",
    "    X_augmented = np.vstack([x.reshape(x.shape[0], -1) for x in X_list])\n",
    "    X_augmented = X_augmented.reshape(-1, X.shape[1], X.shape[2])\n",
    "    y_augmented = np.vstack(y_list)\n",
    "    \n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "def augment_hybrid_data(X_temp, X_stat, y, num_augmented=1, noise_level=0.03):\n",
    "    \"\"\"\n",
    "    Augment Hybrid model data (temporal + static inputs).\n",
    "    \"\"\"\n",
    "    X_temp_list = [X_temp]\n",
    "    X_stat_list = [X_stat]\n",
    "    y_list = [y]\n",
    "    \n",
    "    temp_stds = np.std(X_temp.reshape(-1, X_temp.shape[2]), axis=0)\n",
    "    stat_stds = np.std(X_stat, axis=0)\n",
    "    \n",
    "    for i in range(num_augmented):\n",
    "        noise_temp = np.random.normal(0, noise_level, size=X_temp.shape) * temp_stds\n",
    "        X_temp_noisy = X_temp + noise_temp\n",
    "        X_temp_noisy = np.clip(X_temp_noisy, X_temp.min(axis=(0,1)) * 0.8, X_temp.max(axis=(0,1)) * 1.2)\n",
    "        \n",
    "        noise_stat = np.random.normal(0, noise_level, size=X_stat.shape) * stat_stds\n",
    "        X_stat_noisy = X_stat + noise_stat\n",
    "        X_stat_noisy = np.clip(X_stat_noisy, X_stat.min(axis=0) * 0.8, X_stat.max(axis=0) * 1.2)\n",
    "        \n",
    "        X_temp_list.append(X_temp_noisy)\n",
    "        X_stat_list.append(X_stat_noisy)\n",
    "        y_list.append(y)\n",
    "    \n",
    "    X_temp_aug = np.vstack([x.reshape(x.shape[0], -1) for x in X_temp_list])\n",
    "    X_temp_aug = X_temp_aug.reshape(-1, X_temp.shape[1], X_temp.shape[2])\n",
    "    \n",
    "    X_stat_aug = np.vstack(X_stat_list)\n",
    "    y_aug = np.vstack(y_list)\n",
    "    \n",
    "    return X_temp_aug, X_stat_aug, y_aug\n",
    "\n",
    "print(\"âœ“ Utility functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ff9fb",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: CNN Model (1D Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d8fc9d",
   "metadata": {},
   "source": [
    "### What is 1D-CNN?\n",
    "\n",
    "Convolutional Neural Networks apply filters to detect patterns in data. For time series, 1D-CNN uses sliding windows to extract:\n",
    "- **Seasonal patterns** (e.g., rainy vs dry seasons)\n",
    "- **Local trends** (e.g., temperature peaks during growing season)\n",
    "- **Multi-scale features** through multiple conv layers\n",
    "\n",
    "**Why CNN for crop yield?**\n",
    "- Efficient at capturing temporal patterns (monthly sequences)\n",
    "- Fewer parameters than recurrent networks\n",
    "- Can detect seasonal signatures that indicate yield outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d4bfbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PART 1: CNN MODEL (1D CONVOLUTIONS)\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Loading CNN data...\n",
      "  Train: (5184, 35)\n",
      "  Val:   (864, 35)\n",
      "  Test:  (864, 35)\n",
      "\n",
      "âœ“ Encoded categorical variables\n",
      "  Total features (including encodings): 28\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART 1: CNN MODEL (1D CONVOLUTIONS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load CNN data\n",
    "print(\"\\nğŸ“Š Loading CNN data...\")\n",
    "cnn_train = pd.read_csv(splits_path / 'cnn' / 'train.csv')\n",
    "cnn_val = pd.read_csv(splits_path / 'cnn' / 'val.csv')\n",
    "cnn_test = pd.read_csv(splits_path / 'cnn' / 'test.csv')\n",
    "\n",
    "print(f\"  Train: {cnn_train.shape}\")\n",
    "print(f\"  Val:   {cnn_val.shape}\")\n",
    "print(f\"  Test:  {cnn_test.shape}\")\n",
    "\n",
    "# Remove missing yields\n",
    "cnn_train = cnn_train.dropna(subset=[target_col])\n",
    "cnn_val = cnn_val.dropna(subset=[target_col])\n",
    "cnn_test = cnn_test.dropna(subset=[target_col])\n",
    "\n",
    "# Encode categorical variables\n",
    "crop_encoder = LabelEncoder()\n",
    "region_encoder = LabelEncoder()\n",
    "\n",
    "all_crops = pd.concat([cnn_train['Crop'], cnn_val['Crop'], cnn_test['Crop']])\n",
    "all_regions = pd.concat([cnn_train['Region'], cnn_val['Region'], cnn_test['Region']])\n",
    "\n",
    "crop_encoder.fit(all_crops)\n",
    "region_encoder.fit(all_regions)\n",
    "\n",
    "cnn_train['Crop_encoded'] = crop_encoder.transform(cnn_train['Crop'])\n",
    "cnn_train['Region_encoded'] = region_encoder.transform(cnn_train['Region'])\n",
    "cnn_val['Crop_encoded'] = crop_encoder.transform(cnn_val['Crop'])\n",
    "cnn_val['Region_encoded'] = region_encoder.transform(cnn_val['Region'])\n",
    "cnn_test['Crop_encoded'] = crop_encoder.transform(cnn_test['Crop'])\n",
    "cnn_test['Region_encoded'] = region_encoder.transform(cnn_test['Region'])\n",
    "\n",
    "# Add encoded features to feature list\n",
    "cnn_all_features = cnn_feature_cols + ['Crop_encoded', 'Region_encoded']\n",
    "\n",
    "print(f\"\\nâœ“ Encoded categorical variables\")\n",
    "print(f\"  Total features (including encodings): {len(cnn_all_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0647195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Creating sequences for CNN...\n",
      "\n",
      "  Train sequences: (432, 12, 28)\n",
      "  Val sequences:   (72, 12, 28)\n",
      "  Test sequences:  (72, 12, 28)\n",
      "\n",
      "  Normalizing features...\n",
      "  âœ“ Features normalized\n"
     ]
    }
   ],
   "source": [
    "# Prepare sequences for CNN\n",
    "print(\"\\nğŸ“Š Creating sequences for CNN...\")\n",
    "\n",
    "def create_sequences(df, feature_cols, target_col, sequence_length=12):\n",
    "    \"\"\"Create sliding window sequences from monthly data\"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    # Group by Region, Crop, Year to create annual sequences\n",
    "    for (region, crop, year), group in df.groupby(['Region', 'Crop', 'Year']):\n",
    "        group_sorted = group.sort_values('Month')\n",
    "        \n",
    "        if len(group_sorted) >= sequence_length:\n",
    "            # Take first sequence_length months\n",
    "            seq = group_sorted.iloc[:sequence_length][feature_cols].values\n",
    "            # Target is the annual yield (sum of monthly yields)\n",
    "            target = group_sorted[target_col].sum()\n",
    "            \n",
    "            sequences.append(seq)\n",
    "            targets.append(target)\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "sequence_length = 12  # 12 months\n",
    "X_cnn_train, y_cnn_train = create_sequences(cnn_train, cnn_all_features, target_col, sequence_length)\n",
    "X_cnn_val, y_cnn_val = create_sequences(cnn_val, cnn_all_features, target_col, sequence_length)\n",
    "X_cnn_test, y_cnn_test = create_sequences(cnn_test, cnn_all_features, target_col, sequence_length)\n",
    "\n",
    "print(f\"\\n  Train sequences: {X_cnn_train.shape}\")\n",
    "print(f\"  Val sequences:   {X_cnn_val.shape}\")\n",
    "print(f\"  Test sequences:  {X_cnn_test.shape}\")\n",
    "\n",
    "# Normalize features\n",
    "print(\"\\n  Normalizing features...\")\n",
    "scaler_cnn = StandardScaler()\n",
    "\n",
    "# Reshape for scaling\n",
    "X_cnn_train_reshaped = X_cnn_train.reshape(-1, X_cnn_train.shape[2])\n",
    "scaler_cnn.fit(X_cnn_train_reshaped)\n",
    "\n",
    "X_cnn_train_scaled = scaler_cnn.transform(X_cnn_train.reshape(-1, X_cnn_train.shape[2])).reshape(X_cnn_train.shape)\n",
    "X_cnn_val_scaled = scaler_cnn.transform(X_cnn_val.reshape(-1, X_cnn_val.shape[2])).reshape(X_cnn_val.shape)\n",
    "X_cnn_test_scaled = scaler_cnn.transform(X_cnn_test.reshape(-1, X_cnn_test.shape[2])).reshape(X_cnn_test.shape)\n",
    "\n",
    "print(\"  âœ“ Features normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640fccd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Categorizing yields for classification...\n",
      "\n",
      "Category thresholds (kg/ha):\n",
      "  Low:    < 1.95\n",
      "  Medium: 1.95 - 9.61\n",
      "  High:   > 9.61\n",
      "\n",
      "Class distribution (Train):\n",
      "  Class 0: 144 samples (33.3%)\n",
      "  Class 1: 144 samples (33.3%)\n",
      "  Class 2: 144 samples (33.3%)\n",
      "\n",
      "âœ“ Targets encoded as one-hot vectors\n"
     ]
    }
   ],
   "source": [
    "# Categorize yields\n",
    "print(\"\\nğŸ“Š Categorizing yields for classification...\")\n",
    "\n",
    "y_cnn_train_cat, cnn_percentiles = categorize_yield_balanced(y_cnn_train, method='percentile')\n",
    "y_cnn_val_cat, _ = categorize_yield_balanced(y_cnn_val, method='percentile')\n",
    "y_cnn_test_cat, _ = categorize_yield_balanced(y_cnn_test, method='percentile')\n",
    "\n",
    "print(f\"\\nCategory thresholds (kg/ha):\")\n",
    "print(f\"  Low:    < {cnn_percentiles[0]:.2f}\")\n",
    "print(f\"  Medium: {cnn_percentiles[0]:.2f} - {cnn_percentiles[1]:.2f}\")\n",
    "print(f\"  High:   > {cnn_percentiles[1]:.2f}\")\n",
    "\n",
    "print(f\"\\nClass distribution (Train):\")\n",
    "unique, counts = np.unique(y_cnn_train_cat, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"  Class {cls}: {count} samples ({count/len(y_cnn_train_cat)*100:.1f}%)\")\n",
    "\n",
    "# One-hot encode\n",
    "y_cnn_train_onehot = to_categorical(y_cnn_train_cat, num_classes=3)\n",
    "y_cnn_val_onehot = to_categorical(y_cnn_val_cat, num_classes=3)\n",
    "y_cnn_test_onehot = to_categorical(y_cnn_test_cat, num_classes=3)\n",
    "\n",
    "print(f\"\\nâœ“ Targets encoded as one-hot vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69fd8be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ APPLYING DATA AUGMENTATION...\n",
      "  Original CNN training size: 432 samples\n",
      "  Augmented CNN training size: 1728 samples\n",
      "  Augmentation ratio: 4.0x\n",
      "\n",
      "âš–ï¸  CNN Class weights:\n",
      "   Class 0: weight=1.000 (n=576 samples)\n",
      "   Class 1: weight=1.000 (n=576 samples)\n",
      "   Class 2: weight=1.000 (n=576 samples)\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation for CNN\n",
    "print(\"\\nğŸ”„ APPLYING DATA AUGMENTATION...\")\n",
    "\n",
    "print(f\"  Original CNN training size: {X_cnn_train_scaled.shape[0]} samples\")\n",
    "X_cnn_train_aug, y_cnn_train_aug = augment_time_series(\n",
    "    X_cnn_train_scaled,\n",
    "    y_cnn_train_onehot,\n",
    "    num_augmented=3,  # Increased from 1 to 3 for more training data\n",
    "    noise_level=0.02  # Reduced from 0.03 to 0.02 for better quality\n",
    ")\n",
    "\n",
    "print(f\"  Augmented CNN training size: {X_cnn_train_aug.shape[0]} samples\")\n",
    "print(f\"  Augmentation ratio: {X_cnn_train_aug.shape[0] / X_cnn_train_scaled.shape[0]:.1f}x\")\n",
    "\n",
    "# Shuffle\n",
    "indices = np.random.permutation(X_cnn_train_aug.shape[0])\n",
    "X_cnn_train_aug = X_cnn_train_aug[indices]\n",
    "y_cnn_train_aug = y_cnn_train_aug[indices]\n",
    "\n",
    "# Compute class weights\n",
    "y_cnn_train_labels = np.argmax(y_cnn_train_aug, axis=1)\n",
    "cnn_class_weights_array = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_cnn_train_labels),\n",
    "    y=y_cnn_train_labels\n",
    ")\n",
    "cnn_class_weight_dict = dict(enumerate(cnn_class_weights_array))\n",
    "\n",
    "print(f\"\\nâš–ï¸  CNN Class weights:\")\n",
    "for cls, weight in cnn_class_weight_dict.items():\n",
    "    count = np.sum(y_cnn_train_labels == cls)\n",
    "    print(f\"   Class {cls}: weight={weight:.3f} (n={count} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68213d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,440</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_max_pooling1d            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_4           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚         \u001b[38;5;34m5,440\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)         â”‚        \u001b[38;5;34m98,560\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)         â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_max_pooling1d            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m32,896\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_4           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚            \u001b[38;5;34m99\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">174,595</span> (682.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m174,595\u001b[0m (682.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">173,315</span> (677.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m173,315\u001b[0m (677.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Focal Loss for handling class imbalance\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weight = alpha * y_true * tf.pow((1 - y_pred), gamma)\n",
    "        loss = weight * cross_entropy\n",
    "        return tf.reduce_mean(tf.reduce_sum(loss, axis=1))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "# Build CNN model with Attention\n",
    "def build_cnn_model(sequence_length, n_features, learning_rate=0.0003):\n",
    "    \"\"\"\n",
    "    Build 1D-CNN model with attention for time-series classification.\n",
    "    \n",
    "    Architecture:\n",
    "    - Conv1D layers extract temporal patterns\n",
    "    - Attention mechanism focuses on important patterns\n",
    "    - Dense layers for classification\n",
    "    - Enhanced regularization to prevent overfitting\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(sequence_length, n_features)),\n",
    "        \n",
    "        # First conv block\n",
    "        layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same',\n",
    "                     kernel_regularizer=regularizers.l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Second conv block\n",
    "        layers.Conv1D(filters=128, kernel_size=3, activation='relu', padding='same',\n",
    "                     kernel_regularizer=regularizers.l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Third conv block for deeper features\n",
    "        layers.Conv1D(filters=256, kernel_size=3, activation='relu', padding='same',\n",
    "                     kernel_regularizer=regularizers.l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Global pooling\n",
    "        layers.GlobalMaxPooling1D(),\n",
    "        \n",
    "        # Dense layers with stronger regularization\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Output layer\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate, clipnorm=1.0)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=focal_loss(gamma=2.0, alpha=0.25),\n",
    "        metrics=['accuracy',\n",
    "                 tf.keras.metrics.Precision(name='precision'),\n",
    "                 tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "cnn_model = build_cnn_model(\n",
    "    sequence_length=sequence_length,\n",
    "    n_features=X_cnn_train_aug.shape[2],\n",
    "    learning_rate=0.0003\n",
    ")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ac9470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training CNN model...\n",
      "Epoch 1/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3398 - loss: 1.4709 - precision: 0.3460 - recall: 0.2980\n",
      "Epoch 1: val_loss improved from None to 1.26418, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 1: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 37ms/step - accuracy: 0.3530 - loss: 1.4476 - precision: 0.3607 - recall: 0.3021 - val_accuracy: 0.3333 - val_loss: 1.2642 - val_precision: 0.2222 - val_recall: 0.0278 - learning_rate: 3.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m50/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.3635 - loss: 1.3863 - precision: 0.3752 - recall: 0.3053\n",
      "Epoch 2: val_loss improved from 1.26418 to 1.26001, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 2: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.3906 - loss: 1.3717 - precision: 0.4022 - recall: 0.3247 - val_accuracy: 0.3333 - val_loss: 1.2600 - val_precision: 0.3953 - val_recall: 0.2361 - learning_rate: 3.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.4220 - loss: 1.3465 - precision: 0.4399 - recall: 0.3573\n",
      "Epoch 3: val_loss improved from 1.26001 to 1.24633, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 3: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.4363 - loss: 1.3248 - precision: 0.4601 - recall: 0.3675 - val_accuracy: 0.3333 - val_loss: 1.2463 - val_precision: 0.3934 - val_recall: 0.3333 - learning_rate: 3.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.4756 - loss: 1.2745 - precision: 0.5062 - recall: 0.3974\n",
      "Epoch 4: val_loss improved from 1.24633 to 1.22084, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 4: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.4983 - loss: 1.2610 - precision: 0.5226 - recall: 0.4074 - val_accuracy: 0.3472 - val_loss: 1.2208 - val_precision: 0.4138 - val_recall: 0.3333 - learning_rate: 3.0000e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5094 - loss: 1.2473 - precision: 0.5480 - recall: 0.4277\n",
      "Epoch 5: val_loss improved from 1.22084 to 1.19103, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 5: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.5266 - loss: 1.2390 - precision: 0.5618 - recall: 0.4421 - val_accuracy: 0.3472 - val_loss: 1.1910 - val_precision: 0.4444 - val_recall: 0.3333 - learning_rate: 3.0000e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.5527 - loss: 1.1969 - precision: 0.5971 - recall: 0.4690\n",
      "Epoch 6: val_loss improved from 1.19103 to 1.16464, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 6: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5561 - loss: 1.1848 - precision: 0.6103 - recall: 0.4803 - val_accuracy: 0.3750 - val_loss: 1.1646 - val_precision: 0.4364 - val_recall: 0.3333 - learning_rate: 3.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.5609 - loss: 1.1582 - precision: 0.6029 - recall: 0.4672\n",
      "Epoch 7: val_loss improved from 1.16464 to 1.13771, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 7: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5845 - loss: 1.1501 - precision: 0.6273 - recall: 0.4919 - val_accuracy: 0.4028 - val_loss: 1.1377 - val_precision: 0.4898 - val_recall: 0.3333 - learning_rate: 3.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6153 - loss: 1.1241 - precision: 0.6618 - recall: 0.5215\n",
      "Epoch 8: val_loss improved from 1.13771 to 1.09872, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 8: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6181 - loss: 1.1158 - precision: 0.6565 - recall: 0.5220 - val_accuracy: 0.4444 - val_loss: 1.0987 - val_precision: 0.5610 - val_recall: 0.3194 - learning_rate: 3.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6074 - loss: 1.0892 - precision: 0.6450 - recall: 0.5260\n",
      "Epoch 9: val_loss improved from 1.09872 to 1.06852, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 9: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6250 - loss: 1.0771 - precision: 0.6596 - recall: 0.5405 - val_accuracy: 0.4722 - val_loss: 1.0685 - val_precision: 0.5909 - val_recall: 0.3611 - learning_rate: 3.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.6472 - loss: 1.0550 - precision: 0.6860 - recall: 0.5486\n",
      "Epoch 10: val_loss improved from 1.06852 to 1.04408, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 10: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.6499 - loss: 1.0461 - precision: 0.6837 - recall: 0.5503 - val_accuracy: 0.5278 - val_loss: 1.0441 - val_precision: 0.5897 - val_recall: 0.3194 - learning_rate: 3.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6891 - loss: 1.0212 - precision: 0.7188 - recall: 0.6097\n",
      "Epoch 11: val_loss improved from 1.04408 to 1.02109, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 11: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.6933 - loss: 1.0105 - precision: 0.7288 - recall: 0.6157 - val_accuracy: 0.4306 - val_loss: 1.0211 - val_precision: 0.5556 - val_recall: 0.2778 - learning_rate: 3.0000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.6493 - loss: 0.9947 - precision: 0.6941 - recall: 0.5616\n",
      "Epoch 12: val_loss improved from 1.02109 to 0.99412, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 12: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.6447 - loss: 0.9895 - precision: 0.6804 - recall: 0.5631 - val_accuracy: 0.5000 - val_loss: 0.9941 - val_precision: 0.5263 - val_recall: 0.2778 - learning_rate: 3.0000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m50/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7134 - loss: 0.9546 - precision: 0.7484 - recall: 0.6350\n",
      "Epoch 13: val_loss improved from 0.99412 to 0.97166, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 13: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7049 - loss: 0.9473 - precision: 0.7337 - recall: 0.6314 - val_accuracy: 0.5278 - val_loss: 0.9717 - val_precision: 0.5581 - val_recall: 0.3333 - learning_rate: 3.0000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7026 - loss: 0.9315 - precision: 0.7415 - recall: 0.6187\n",
      "Epoch 14: val_loss improved from 0.97166 to 0.94692, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 14: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7078 - loss: 0.9253 - precision: 0.7447 - recall: 0.6244 - val_accuracy: 0.4583 - val_loss: 0.9469 - val_precision: 0.4894 - val_recall: 0.3194 - learning_rate: 3.0000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7089 - loss: 0.8993 - precision: 0.7340 - recall: 0.6399\n",
      "Epoch 15: val_loss improved from 0.94692 to 0.92451, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 15: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7124 - loss: 0.8915 - precision: 0.7418 - recall: 0.6400 - val_accuracy: 0.4583 - val_loss: 0.9245 - val_precision: 0.4898 - val_recall: 0.3333 - learning_rate: 3.0000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7145 - loss: 0.8673 - precision: 0.7596 - recall: 0.6599\n",
      "Epoch 16: val_loss improved from 0.92451 to 0.89511, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 16: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7153 - loss: 0.8650 - precision: 0.7508 - recall: 0.6522 - val_accuracy: 0.5139 - val_loss: 0.8951 - val_precision: 0.4694 - val_recall: 0.3194 - learning_rate: 3.0000e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7241 - loss: 0.8431 - precision: 0.7685 - recall: 0.6612\n",
      "Epoch 17: val_loss improved from 0.89511 to 0.87329, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 17: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7361 - loss: 0.8349 - precision: 0.7722 - recall: 0.6806 - val_accuracy: 0.4861 - val_loss: 0.8733 - val_precision: 0.4792 - val_recall: 0.3194 - learning_rate: 3.0000e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7576 - loss: 0.8121 - precision: 0.7866 - recall: 0.6942\n",
      "Epoch 18: val_loss improved from 0.87329 to 0.84697, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 18: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7431 - loss: 0.8057 - precision: 0.7733 - recall: 0.6829 - val_accuracy: 0.5000 - val_loss: 0.8470 - val_precision: 0.4706 - val_recall: 0.3333 - learning_rate: 3.0000e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7521 - loss: 0.7846 - precision: 0.7837 - recall: 0.6749\n",
      "Epoch 19: val_loss improved from 0.84697 to 0.81853, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 19: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7598 - loss: 0.7763 - precision: 0.7927 - recall: 0.6927 - val_accuracy: 0.4722 - val_loss: 0.8185 - val_precision: 0.5172 - val_recall: 0.4167 - learning_rate: 3.0000e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7592 - loss: 0.7587 - precision: 0.7843 - recall: 0.7055\n",
      "Epoch 20: val_loss improved from 0.81853 to 0.79935, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 20: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.7402 - loss: 0.7549 - precision: 0.7716 - recall: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.7993 - val_precision: 0.5246 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.7835 - loss: 0.7285 - precision: 0.8025 - recall: 0.7278\n",
      "Epoch 21: val_loss improved from 0.79935 to 0.77121, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 21: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7899 - loss: 0.7229 - precision: 0.8091 - recall: 0.7332 - val_accuracy: 0.4583 - val_loss: 0.7712 - val_precision: 0.4688 - val_recall: 0.4167 - learning_rate: 3.0000e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.7909 - loss: 0.7037 - precision: 0.8159 - recall: 0.7380\n",
      "Epoch 22: val_loss improved from 0.77121 to 0.75227, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 22: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.7847 - loss: 0.6978 - precision: 0.8095 - recall: 0.7402 - val_accuracy: 0.4444 - val_loss: 0.7523 - val_precision: 0.4754 - val_recall: 0.4028 - learning_rate: 3.0000e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7809 - loss: 0.6814 - precision: 0.8070 - recall: 0.7341\n",
      "Epoch 23: val_loss improved from 0.75227 to 0.72586, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 23: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.7928 - loss: 0.6728 - precision: 0.8159 - recall: 0.7465 - val_accuracy: 0.4722 - val_loss: 0.7259 - val_precision: 0.5082 - val_recall: 0.4306 - learning_rate: 3.0000e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7999 - loss: 0.6543 - precision: 0.8148 - recall: 0.7525\n",
      "Epoch 24: val_loss improved from 0.72586 to 0.69728, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 24: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.7957 - loss: 0.6489 - precision: 0.8135 - recall: 0.7523 - val_accuracy: 0.4861 - val_loss: 0.6973 - val_precision: 0.5273 - val_recall: 0.4028 - learning_rate: 3.0000e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8220 - loss: 0.6295 - precision: 0.8432 - recall: 0.7745\n",
      "Epoch 25: val_loss improved from 0.69728 to 0.67245, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 25: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.8131 - loss: 0.6233 - precision: 0.8345 - recall: 0.7703 - val_accuracy: 0.4861 - val_loss: 0.6725 - val_precision: 0.5238 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8169 - loss: 0.6065 - precision: 0.8326 - recall: 0.7583\n",
      "Epoch 26: val_loss improved from 0.67245 to 0.65411, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 26: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8137 - loss: 0.6014 - precision: 0.8308 - recall: 0.7703 - val_accuracy: 0.5278 - val_loss: 0.6541 - val_precision: 0.5469 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8243 - loss: 0.5827 - precision: 0.8437 - recall: 0.7862\n",
      "Epoch 27: val_loss improved from 0.65411 to 0.63232, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 27: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8194 - loss: 0.5777 - precision: 0.8402 - recall: 0.7853 - val_accuracy: 0.4583 - val_loss: 0.6323 - val_precision: 0.4706 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8178 - loss: 0.5570 - precision: 0.8457 - recall: 0.7788\n",
      "Epoch 28: val_loss improved from 0.63232 to 0.61216, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 28: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8206 - loss: 0.5525 - precision: 0.8444 - recall: 0.7853 - val_accuracy: 0.5000 - val_loss: 0.6122 - val_precision: 0.4848 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8242 - loss: 0.5376 - precision: 0.8429 - recall: 0.7847\n",
      "Epoch 29: val_loss improved from 0.61216 to 0.59460, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 29: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8299 - loss: 0.5305 - precision: 0.8474 - recall: 0.7940 - val_accuracy: 0.5000 - val_loss: 0.5946 - val_precision: 0.4853 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8323 - loss: 0.5154 - precision: 0.8471 - recall: 0.7926\n",
      "Epoch 30: val_loss improved from 0.59460 to 0.58074, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 30: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.8351 - loss: 0.5083 - precision: 0.8505 - recall: 0.7934 - val_accuracy: 0.4444 - val_loss: 0.5807 - val_precision: 0.4507 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8269 - loss: 0.4939 - precision: 0.8458 - recall: 0.8015\n",
      "Epoch 31: val_loss improved from 0.58074 to 0.55143, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 31: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8351 - loss: 0.4892 - precision: 0.8541 - recall: 0.8096 - val_accuracy: 0.5000 - val_loss: 0.5514 - val_precision: 0.5147 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8536 - loss: 0.4729 - precision: 0.8693 - recall: 0.8260\n",
      "Epoch 32: val_loss improved from 0.55143 to 0.54273, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 32: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8397 - loss: 0.4687 - precision: 0.8532 - recall: 0.8171 - val_accuracy: 0.4306 - val_loss: 0.5427 - val_precision: 0.4545 - val_recall: 0.4167 - learning_rate: 3.0000e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8296 - loss: 0.4521 - precision: 0.8500 - recall: 0.7940\n",
      "Epoch 33: val_loss improved from 0.54273 to 0.52050, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 33: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8403 - loss: 0.4472 - precision: 0.8562 - recall: 0.8096 - val_accuracy: 0.5139 - val_loss: 0.5205 - val_precision: 0.5000 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m50/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8518 - loss: 0.4313 - precision: 0.8632 - recall: 0.8173\n",
      "Epoch 34: val_loss improved from 0.52050 to 0.51181, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 34: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8472 - loss: 0.4286 - precision: 0.8618 - recall: 0.8189 - val_accuracy: 0.5139 - val_loss: 0.5118 - val_precision: 0.5143 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8509 - loss: 0.4130 - precision: 0.8663 - recall: 0.8210\n",
      "Epoch 35: val_loss improved from 0.51181 to 0.50033, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 35: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.8536 - loss: 0.4087 - precision: 0.8694 - recall: 0.8281 - val_accuracy: 0.4861 - val_loss: 0.5003 - val_precision: 0.4925 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8656 - loss: 0.3941 - precision: 0.8791 - recall: 0.8423\n",
      "Epoch 36: val_loss improved from 0.50033 to 0.48826, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 36: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8652 - loss: 0.3887 - precision: 0.8783 - recall: 0.8397 - val_accuracy: 0.5000 - val_loss: 0.4883 - val_precision: 0.4857 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.8671 - loss: 0.3761 - precision: 0.8846 - recall: 0.8533\n",
      "Epoch 37: val_loss improved from 0.48826 to 0.46940, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 37: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.8675 - loss: 0.3726 - precision: 0.8827 - recall: 0.8495 - val_accuracy: 0.5000 - val_loss: 0.4694 - val_precision: 0.4928 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.8669 - loss: 0.3585 - precision: 0.8779 - recall: 0.8526\n",
      "Epoch 38: val_loss improved from 0.46940 to 0.46368, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 38: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.8756 - loss: 0.3550 - precision: 0.8867 - recall: 0.8559 - val_accuracy: 0.4861 - val_loss: 0.4637 - val_precision: 0.4857 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8805 - loss: 0.3436 - precision: 0.8921 - recall: 0.8585\n",
      "Epoch 39: val_loss improved from 0.46368 to 0.44929, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 39: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8738 - loss: 0.3391 - precision: 0.8867 - recall: 0.8559 - val_accuracy: 0.4583 - val_loss: 0.4493 - val_precision: 0.4648 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8881 - loss: 0.3282 - precision: 0.8954 - recall: 0.8748\n",
      "Epoch 40: val_loss improved from 0.44929 to 0.43498, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 40: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 24ms/step - accuracy: 0.8877 - loss: 0.3229 - precision: 0.8966 - recall: 0.8727 - val_accuracy: 0.5139 - val_loss: 0.4350 - val_precision: 0.5072 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8880 - loss: 0.3131 - precision: 0.9059 - recall: 0.8576\n",
      "Epoch 41: val_loss improved from 0.43498 to 0.41951, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 41: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8900 - loss: 0.3080 - precision: 0.8994 - recall: 0.8640 - val_accuracy: 0.4861 - val_loss: 0.4195 - val_precision: 0.4861 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8705 - loss: 0.2963 - precision: 0.8807 - recall: 0.8467\n",
      "Epoch 42: val_loss improved from 0.41951 to 0.41243, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 42: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8709 - loss: 0.2929 - precision: 0.8833 - recall: 0.8495 - val_accuracy: 0.5139 - val_loss: 0.4124 - val_precision: 0.5000 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m50/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8857 - loss: 0.2833 - precision: 0.8972 - recall: 0.8740\n",
      "Epoch 43: val_loss improved from 0.41243 to 0.40475, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 43: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.8912 - loss: 0.2797 - precision: 0.9027 - recall: 0.8756 - val_accuracy: 0.4583 - val_loss: 0.4048 - val_precision: 0.4571 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8927 - loss: 0.2689 - precision: 0.8969 - recall: 0.8675\n",
      "Epoch 44: val_loss did not improve from 0.40475\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.8924 - loss: 0.2650 - precision: 0.8996 - recall: 0.8715 - val_accuracy: 0.4722 - val_loss: 0.4056 - val_precision: 0.4783 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m50/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8838 - loss: 0.2553 - precision: 0.8976 - recall: 0.8703\n",
      "Epoch 45: val_loss improved from 0.40475 to 0.40257, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 45: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8877 - loss: 0.2519 - precision: 0.8977 - recall: 0.8733 - val_accuracy: 0.4167 - val_loss: 0.4026 - val_precision: 0.4058 - val_recall: 0.3889 - learning_rate: 3.0000e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9140 - loss: 0.2433 - precision: 0.9188 - recall: 0.8908\n",
      "Epoch 46: val_loss improved from 0.40257 to 0.39215, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 46: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9022 - loss: 0.2403 - precision: 0.9095 - recall: 0.8843 - val_accuracy: 0.5000 - val_loss: 0.3922 - val_precision: 0.4857 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8975 - loss: 0.2319 - precision: 0.9036 - recall: 0.8928\n",
      "Epoch 47: val_loss improved from 0.39215 to 0.38778, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 47: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.8935 - loss: 0.2293 - precision: 0.8995 - recall: 0.8860 - val_accuracy: 0.5000 - val_loss: 0.3878 - val_precision: 0.5000 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.8983 - loss: 0.2197 - precision: 0.9072 - recall: 0.8853\n",
      "Epoch 48: val_loss improved from 0.38778 to 0.37768, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 48: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9045 - loss: 0.2168 - precision: 0.9112 - recall: 0.8906 - val_accuracy: 0.5000 - val_loss: 0.3777 - val_precision: 0.5000 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9168 - loss: 0.2082 - precision: 0.9311 - recall: 0.9045\n",
      "Epoch 49: val_loss did not improve from 0.37768\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9115 - loss: 0.2072 - precision: 0.9222 - recall: 0.8981 - val_accuracy: 0.4444 - val_loss: 0.4047 - val_precision: 0.4444 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9263 - loss: 0.1974 - precision: 0.9326 - recall: 0.9046\n",
      "Epoch 50: val_loss improved from 0.37768 to 0.34401, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 50: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9144 - loss: 0.1962 - precision: 0.9220 - recall: 0.8964 - val_accuracy: 0.4722 - val_loss: 0.3440 - val_precision: 0.4722 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9164 - loss: 0.1876 - precision: 0.9201 - recall: 0.9053\n",
      "Epoch 51: val_loss improved from 0.34401 to 0.34048, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 51: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9097 - loss: 0.1866 - precision: 0.9156 - recall: 0.8976 - val_accuracy: 0.5278 - val_loss: 0.3405 - val_precision: 0.5143 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9149 - loss: 0.1784 - precision: 0.9195 - recall: 0.9061\n",
      "Epoch 52: val_loss did not improve from 0.34048\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9120 - loss: 0.1765 - precision: 0.9192 - recall: 0.9016 - val_accuracy: 0.4444 - val_loss: 0.3434 - val_precision: 0.4444 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9164 - loss: 0.1703 - precision: 0.9187 - recall: 0.9021\n",
      "Epoch 53: val_loss improved from 0.34048 to 0.31870, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 53: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9225 - loss: 0.1676 - precision: 0.9260 - recall: 0.9126 - val_accuracy: 0.5417 - val_loss: 0.3187 - val_precision: 0.5294 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9082 - loss: 0.1633 - precision: 0.9188 - recall: 0.9001\n",
      "Epoch 54: val_loss improved from 0.31870 to 0.27202, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 54: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9097 - loss: 0.1619 - precision: 0.9179 - recall: 0.8993 - val_accuracy: 0.6111 - val_loss: 0.2720 - val_precision: 0.6111 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9139 - loss: 0.1559 - precision: 0.9210 - recall: 0.9038\n",
      "Epoch 55: val_loss did not improve from 0.27202\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9155 - loss: 0.1529 - precision: 0.9202 - recall: 0.9010 - val_accuracy: 0.5417 - val_loss: 0.2850 - val_precision: 0.5352 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9283 - loss: 0.1467 - precision: 0.9306 - recall: 0.9239\n",
      "Epoch 56: val_loss did not improve from 0.27202\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9236 - loss: 0.1451 - precision: 0.9274 - recall: 0.9172 - val_accuracy: 0.4722 - val_loss: 0.3256 - val_precision: 0.4722 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9160 - loss: 0.1406 - precision: 0.9259 - recall: 0.9026\n",
      "Epoch 57: val_loss did not improve from 0.27202\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9190 - loss: 0.1393 - precision: 0.9269 - recall: 0.9097 - val_accuracy: 0.5139 - val_loss: 0.3195 - val_precision: 0.5139 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9162 - loss: 0.1332 - precision: 0.9251 - recall: 0.9121\n",
      "Epoch 58: val_loss did not improve from 0.27202\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9236 - loss: 0.1323 - precision: 0.9313 - recall: 0.9184 - val_accuracy: 0.4722 - val_loss: 0.3204 - val_precision: 0.4722 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m50/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9227 - loss: 0.1262 - precision: 0.9259 - recall: 0.9052\n",
      "Epoch 59: val_loss did not improve from 0.27202\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9225 - loss: 0.1256 - precision: 0.9269 - recall: 0.9103 - val_accuracy: 0.5000 - val_loss: 0.3208 - val_precision: 0.5000 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9231 - loss: 0.1214 - precision: 0.9263 - recall: 0.9149\n",
      "Epoch 60: val_loss did not improve from 0.27202\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9259 - loss: 0.1202 - precision: 0.9298 - recall: 0.9201 - val_accuracy: 0.5000 - val_loss: 0.2990 - val_precision: 0.4930 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9310 - loss: 0.1152 - precision: 0.9417 - recall: 0.9212\n",
      "Epoch 61: val_loss did not improve from 0.27202\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9259 - loss: 0.1141 - precision: 0.9344 - recall: 0.9155 - val_accuracy: 0.5139 - val_loss: 0.2751 - val_precision: 0.5139 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m49/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9240 - loss: 0.1099 - precision: 0.9291 - recall: 0.9213\n",
      "Epoch 62: val_loss did not improve from 0.27202\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9277 - loss: 0.1088 - precision: 0.9333 - recall: 0.9236 - val_accuracy: 0.4861 - val_loss: 0.3005 - val_precision: 0.4857 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9345 - loss: 0.1040 - precision: 0.9362 - recall: 0.9206\n",
      "Epoch 63: val_loss did not improve from 0.27202\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9317 - loss: 0.1039 - precision: 0.9356 - recall: 0.9242 - val_accuracy: 0.5000 - val_loss: 0.2927 - val_precision: 0.5000 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9185 - loss: 0.1012 - precision: 0.9213 - recall: 0.9140\n",
      "Epoch 64: val_loss did not improve from 0.27202\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9253 - loss: 0.1004 - precision: 0.9298 - recall: 0.9201 - val_accuracy: 0.5000 - val_loss: 0.2929 - val_precision: 0.4930 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9334 - loss: 0.0948 - precision: 0.9425 - recall: 0.9231\n",
      "Epoch 65: val_loss did not improve from 0.27202\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9421 - loss: 0.0941 - precision: 0.9492 - recall: 0.9306 - val_accuracy: 0.4583 - val_loss: 0.2829 - val_precision: 0.4714 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9305 - loss: 0.0925 - precision: 0.9371 - recall: 0.9254\n",
      "Epoch 66: val_loss improved from 0.27202 to 0.24291, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 66: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9300 - loss: 0.0910 - precision: 0.9365 - recall: 0.9219 - val_accuracy: 0.5139 - val_loss: 0.2429 - val_precision: 0.5070 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9381 - loss: 0.0857 - precision: 0.9441 - recall: 0.9306\n",
      "Epoch 67: val_loss did not improve from 0.24291\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9392 - loss: 0.0851 - precision: 0.9450 - recall: 0.9340 - val_accuracy: 0.4583 - val_loss: 0.2911 - val_precision: 0.4583 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9439 - loss: 0.0821 - precision: 0.9452 - recall: 0.9417\n",
      "Epoch 68: val_loss did not improve from 0.24291\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9375 - loss: 0.0825 - precision: 0.9395 - recall: 0.9346 - val_accuracy: 0.5000 - val_loss: 0.2857 - val_precision: 0.5000 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m50/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9395 - loss: 0.0820 - precision: 0.9411 - recall: 0.9302\n",
      "Epoch 69: val_loss did not improve from 0.24291\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9352 - loss: 0.0815 - precision: 0.9379 - recall: 0.9265 - val_accuracy: 0.5278 - val_loss: 0.2642 - val_precision: 0.5278 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9409 - loss: 0.0760 - precision: 0.9476 - recall: 0.9338\n",
      "Epoch 70: val_loss did not improve from 0.24291\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9450 - loss: 0.0760 - precision: 0.9480 - recall: 0.9381 - val_accuracy: 0.5000 - val_loss: 0.2680 - val_precision: 0.4930 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m49/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9457 - loss: 0.0742 - precision: 0.9490 - recall: 0.9358\n",
      "Epoch 71: val_loss improved from 0.24291 to 0.21582, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 71: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9334 - loss: 0.0747 - precision: 0.9357 - recall: 0.9271 - val_accuracy: 0.5556 - val_loss: 0.2158 - val_precision: 0.5556 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9347 - loss: 0.0733 - precision: 0.9428 - recall: 0.9277\n",
      "Epoch 72: val_loss did not improve from 0.21582\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9340 - loss: 0.0719 - precision: 0.9414 - recall: 0.9294 - val_accuracy: 0.5278 - val_loss: 0.2225 - val_precision: 0.5211 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m50/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9503 - loss: 0.0683 - precision: 0.9534 - recall: 0.9459\n",
      "Epoch 73: val_loss did not improve from 0.21582\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9450 - loss: 0.0682 - precision: 0.9485 - recall: 0.9387 - val_accuracy: 0.5417 - val_loss: 0.2288 - val_precision: 0.5493 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9521 - loss: 0.0650 - precision: 0.9570 - recall: 0.9424\n",
      "Epoch 74: val_loss did not improve from 0.21582\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9462 - loss: 0.0653 - precision: 0.9524 - recall: 0.9369 - val_accuracy: 0.5139 - val_loss: 0.2420 - val_precision: 0.5070 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9488 - loss: 0.0628 - precision: 0.9529 - recall: 0.9402\n",
      "Epoch 75: val_loss did not improve from 0.21582\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9450 - loss: 0.0641 - precision: 0.9496 - recall: 0.9369 - val_accuracy: 0.4722 - val_loss: 0.2725 - val_precision: 0.4789 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9273 - loss: 0.0635 - precision: 0.9319 - recall: 0.9145\n",
      "Epoch 76: val_loss did not improve from 0.21582\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9375 - loss: 0.0625 - precision: 0.9402 - recall: 0.9277 - val_accuracy: 0.5278 - val_loss: 0.2162 - val_precision: 0.5352 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9394 - loss: 0.0605 - precision: 0.9429 - recall: 0.9340\n",
      "Epoch 77: val_loss did not improve from 0.21582\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9427 - loss: 0.0601 - precision: 0.9473 - recall: 0.9369 - val_accuracy: 0.5000 - val_loss: 0.2405 - val_precision: 0.5000 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m49/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9533 - loss: 0.0577 - precision: 0.9572 - recall: 0.9489\n",
      "Epoch 78: val_loss did not improve from 0.21582\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9514 - loss: 0.0571 - precision: 0.9562 - recall: 0.9479 - val_accuracy: 0.5139 - val_loss: 0.2579 - val_precision: 0.5070 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9582 - loss: 0.0543 - precision: 0.9607 - recall: 0.9496\n",
      "Epoch 79: val_loss did not improve from 0.21582\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9537 - loss: 0.0549 - precision: 0.9562 - recall: 0.9479 - val_accuracy: 0.4722 - val_loss: 0.2647 - val_precision: 0.4857 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9504 - loss: 0.0549 - precision: 0.9505 - recall: 0.9436\n",
      "Epoch 80: val_loss did not improve from 0.21582\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9525 - loss: 0.0533 - precision: 0.9534 - recall: 0.9479 - val_accuracy: 0.5417 - val_loss: 0.2276 - val_precision: 0.5352 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9596 - loss: 0.0498 - precision: 0.9643 - recall: 0.9557\n",
      "Epoch 81: val_loss did not improve from 0.21582\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9606 - loss: 0.0495 - precision: 0.9656 - recall: 0.9589 - val_accuracy: 0.5833 - val_loss: 0.2501 - val_precision: 0.5775 - val_recall: 0.5694 - learning_rate: 3.0000e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9555 - loss: 0.0486 - precision: 0.9625 - recall: 0.9501\n",
      "Epoch 82: val_loss did not improve from 0.21582\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9560 - loss: 0.0492 - precision: 0.9613 - recall: 0.9491 - val_accuracy: 0.5417 - val_loss: 0.2784 - val_precision: 0.5352 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9541 - loss: 0.0481 - precision: 0.9559 - recall: 0.9515\n",
      "Epoch 83: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\n",
      "Epoch 83: val_loss did not improve from 0.21582\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9525 - loss: 0.0492 - precision: 0.9551 - recall: 0.9473 - val_accuracy: 0.5278 - val_loss: 0.2469 - val_precision: 0.5278 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9547 - loss: 0.0473 - precision: 0.9547 - recall: 0.9497\n",
      "Epoch 84: val_loss improved from 0.21582 to 0.20827, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 84: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9578 - loss: 0.0472 - precision: 0.9586 - recall: 0.9520 - val_accuracy: 0.5417 - val_loss: 0.2083 - val_precision: 0.5352 - val_recall: 0.5278 - learning_rate: 1.5000e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9664 - loss: 0.0440 - precision: 0.9713 - recall: 0.9594\n",
      "Epoch 85: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 22ms/step - accuracy: 0.9676 - loss: 0.0436 - precision: 0.9708 - recall: 0.9618 - val_accuracy: 0.5556 - val_loss: 0.2295 - val_precision: 0.5429 - val_recall: 0.5278 - learning_rate: 1.5000e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9632 - loss: 0.0436 - precision: 0.9688 - recall: 0.9629\n",
      "Epoch 86: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9641 - loss: 0.0436 - precision: 0.9669 - recall: 0.9630 - val_accuracy: 0.5278 - val_loss: 0.2286 - val_precision: 0.5278 - val_recall: 0.5278 - learning_rate: 1.5000e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9716 - loss: 0.0418 - precision: 0.9760 - recall: 0.9716\n",
      "Epoch 87: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9693 - loss: 0.0419 - precision: 0.9721 - recall: 0.9682 - val_accuracy: 0.5417 - val_loss: 0.2458 - val_precision: 0.5417 - val_recall: 0.5417 - learning_rate: 1.5000e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9655 - loss: 0.0419 - precision: 0.9663 - recall: 0.9598\n",
      "Epoch 88: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9618 - loss: 0.0418 - precision: 0.9627 - recall: 0.9566 - val_accuracy: 0.5139 - val_loss: 0.2855 - val_precision: 0.5211 - val_recall: 0.5139 - learning_rate: 1.5000e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9743 - loss: 0.0396 - precision: 0.9754 - recall: 0.9671\n",
      "Epoch 89: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9740 - loss: 0.0395 - precision: 0.9761 - recall: 0.9711 - val_accuracy: 0.5556 - val_loss: 0.3129 - val_precision: 0.5556 - val_recall: 0.5556 - learning_rate: 1.5000e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9750 - loss: 0.0388 - precision: 0.9756 - recall: 0.9739\n",
      "Epoch 90: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9751 - loss: 0.0389 - precision: 0.9756 - recall: 0.9734 - val_accuracy: 0.5417 - val_loss: 0.3092 - val_precision: 0.5417 - val_recall: 0.5417 - learning_rate: 1.5000e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9726 - loss: 0.0393 - precision: 0.9764 - recall: 0.9691\n",
      "Epoch 91: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9693 - loss: 0.0394 - precision: 0.9726 - recall: 0.9659 - val_accuracy: 0.5556 - val_loss: 0.2529 - val_precision: 0.5556 - val_recall: 0.5556 - learning_rate: 1.5000e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9708 - loss: 0.0395 - precision: 0.9729 - recall: 0.9627\n",
      "Epoch 92: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9705 - loss: 0.0392 - precision: 0.9737 - recall: 0.9647 - val_accuracy: 0.5556 - val_loss: 0.3012 - val_precision: 0.5556 - val_recall: 0.5556 - learning_rate: 1.5000e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9788 - loss: 0.0368 - precision: 0.9792 - recall: 0.9743\n",
      "Epoch 93: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9734 - loss: 0.0370 - precision: 0.9744 - recall: 0.9688 - val_accuracy: 0.5556 - val_loss: 0.2928 - val_precision: 0.5556 - val_recall: 0.5556 - learning_rate: 1.5000e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9782 - loss: 0.0363 - precision: 0.9795 - recall: 0.9745\n",
      "Epoch 94: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9705 - loss: 0.0373 - precision: 0.9721 - recall: 0.9676 - val_accuracy: 0.5694 - val_loss: 0.2724 - val_precision: 0.5634 - val_recall: 0.5556 - learning_rate: 1.5000e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9706 - loss: 0.0365 - precision: 0.9719 - recall: 0.9678\n",
      "Epoch 95: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9705 - loss: 0.0362 - precision: 0.9715 - recall: 0.9676 - val_accuracy: 0.5556 - val_loss: 0.2630 - val_precision: 0.5556 - val_recall: 0.5556 - learning_rate: 1.5000e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9712 - loss: 0.0343 - precision: 0.9724 - recall: 0.9708\n",
      "Epoch 96: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\n",
      "Epoch 96: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9734 - loss: 0.0345 - precision: 0.9745 - recall: 0.9728 - val_accuracy: 0.5694 - val_loss: 0.2959 - val_precision: 0.5634 - val_recall: 0.5556 - learning_rate: 1.5000e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9821 - loss: 0.0340 - precision: 0.9861 - recall: 0.9807\n",
      "Epoch 97: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9763 - loss: 0.0352 - precision: 0.9791 - recall: 0.9745 - val_accuracy: 0.5278 - val_loss: 0.3064 - val_precision: 0.5278 - val_recall: 0.5278 - learning_rate: 7.5000e-05\n",
      "Epoch 98/300\n",
      "\u001b[1m50/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9793 - loss: 0.0326 - precision: 0.9813 - recall: 0.9742\n",
      "Epoch 98: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9769 - loss: 0.0325 - precision: 0.9785 - recall: 0.9734 - val_accuracy: 0.5694 - val_loss: 0.2722 - val_precision: 0.5775 - val_recall: 0.5694 - learning_rate: 7.5000e-05\n",
      "Epoch 99/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9796 - loss: 0.0325 - precision: 0.9809 - recall: 0.9771\n",
      "Epoch 99: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9809 - loss: 0.0323 - precision: 0.9826 - recall: 0.9786 - val_accuracy: 0.5417 - val_loss: 0.2778 - val_precision: 0.5417 - val_recall: 0.5417 - learning_rate: 7.5000e-05\n",
      "Epoch 100/300\n",
      "\u001b[1m51/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9814 - loss: 0.0321 - precision: 0.9832 - recall: 0.9738\n",
      "Epoch 100: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9815 - loss: 0.0322 - precision: 0.9825 - recall: 0.9757 - val_accuracy: 0.5833 - val_loss: 0.2709 - val_precision: 0.5775 - val_recall: 0.5694 - learning_rate: 7.5000e-05\n",
      "Epoch 101/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9761 - loss: 0.0318 - precision: 0.9838 - recall: 0.9732\n",
      "Epoch 101: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9815 - loss: 0.0310 - precision: 0.9843 - recall: 0.9797 - val_accuracy: 0.5417 - val_loss: 0.2972 - val_precision: 0.5417 - val_recall: 0.5417 - learning_rate: 7.5000e-05\n",
      "Epoch 102/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9755 - loss: 0.0315 - precision: 0.9758 - recall: 0.9743\n",
      "Epoch 102: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9763 - loss: 0.0318 - precision: 0.9768 - recall: 0.9740 - val_accuracy: 0.6111 - val_loss: 0.2659 - val_precision: 0.6111 - val_recall: 0.6111 - learning_rate: 7.5000e-05\n",
      "Epoch 103/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9821 - loss: 0.0305 - precision: 0.9833 - recall: 0.9796\n",
      "Epoch 103: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9855 - loss: 0.0307 - precision: 0.9867 - recall: 0.9838 - val_accuracy: 0.5694 - val_loss: 0.2525 - val_precision: 0.5694 - val_recall: 0.5694 - learning_rate: 7.5000e-05\n",
      "Epoch 104/300\n",
      "\u001b[1m50/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9779 - loss: 0.0313 - precision: 0.9804 - recall: 0.9757\n",
      "Epoch 104: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 12ms/step - accuracy: 0.9792 - loss: 0.0313 - precision: 0.9803 - recall: 0.9774 - val_accuracy: 0.6111 - val_loss: 0.2455 - val_precision: 0.6111 - val_recall: 0.6111 - learning_rate: 7.5000e-05\n",
      "Epoch 105/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 9ms/step - accuracy: 0.9863 - loss: 0.0296 - precision: 0.9863 - recall: 0.9848 \n",
      "Epoch 105: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 11ms/step - accuracy: 0.9861 - loss: 0.0296 - precision: 0.9861 - recall: 0.9844 - val_accuracy: 0.5833 - val_loss: 0.2522 - val_precision: 0.5833 - val_recall: 0.5833 - learning_rate: 7.5000e-05\n",
      "Epoch 106/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9807 - loss: 0.0302 - precision: 0.9807 - recall: 0.9807\n",
      "Epoch 106: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9826 - loss: 0.0295 - precision: 0.9832 - recall: 0.9826 - val_accuracy: 0.5972 - val_loss: 0.2814 - val_precision: 0.5972 - val_recall: 0.5972 - learning_rate: 7.5000e-05\n",
      "Epoch 107/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9846 - loss: 0.0290 - precision: 0.9859 - recall: 0.9816\n",
      "Epoch 107: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9855 - loss: 0.0291 - precision: 0.9861 - recall: 0.9826 - val_accuracy: 0.6111 - val_loss: 0.2726 - val_precision: 0.6056 - val_recall: 0.5972 - learning_rate: 7.5000e-05\n",
      "Epoch 108/300\n",
      "\u001b[1m50/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9793 - loss: 0.0285 - precision: 0.9853 - recall: 0.9790\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 30ms/step - accuracy: 0.9832 - loss: 0.0287 - precision: 0.9855 - recall: 0.9815 - val_accuracy: 0.5694 - val_loss: 0.2687 - val_precision: 0.5694 - val_recall: 0.5694 - learning_rate: 7.5000e-05\n",
      "Epoch 109/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9880 - loss: 0.0279 - precision: 0.9897 - recall: 0.9873\n",
      "Epoch 109: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 27ms/step - accuracy: 0.9873 - loss: 0.0278 - precision: 0.9884 - recall: 0.9861 - val_accuracy: 0.5833 - val_loss: 0.2663 - val_precision: 0.5833 - val_recall: 0.5833 - learning_rate: 3.7500e-05\n",
      "Epoch 110/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9786 - loss: 0.0293 - precision: 0.9792 - recall: 0.9719\n",
      "Epoch 110: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9815 - loss: 0.0288 - precision: 0.9831 - recall: 0.9769 - val_accuracy: 0.5972 - val_loss: 0.2846 - val_precision: 0.5972 - val_recall: 0.5972 - learning_rate: 3.7500e-05\n",
      "Epoch 111/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9872 - loss: 0.0275 - precision: 0.9889 - recall: 0.9839\n",
      "Epoch 111: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9878 - loss: 0.0271 - precision: 0.9895 - recall: 0.9855 - val_accuracy: 0.5694 - val_loss: 0.2906 - val_precision: 0.5694 - val_recall: 0.5694 - learning_rate: 3.7500e-05\n",
      "Epoch 112/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9807 - loss: 0.0281 - precision: 0.9819 - recall: 0.9774\n",
      "Epoch 112: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 19ms/step - accuracy: 0.9826 - loss: 0.0283 - precision: 0.9832 - recall: 0.9809 - val_accuracy: 0.5694 - val_loss: 0.2836 - val_precision: 0.5694 - val_recall: 0.5694 - learning_rate: 3.7500e-05\n",
      "Epoch 113/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0268 - precision: 0.9897 - recall: 0.9877\n",
      "Epoch 113: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9890 - loss: 0.0270 - precision: 0.9901 - recall: 0.9878 - val_accuracy: 0.5833 - val_loss: 0.2782 - val_precision: 0.5833 - val_recall: 0.5833 - learning_rate: 3.7500e-05\n",
      "Epoch 114/300\n",
      "\u001b[1m50/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9889 - loss: 0.0270 - precision: 0.9889 - recall: 0.9868\n",
      "Epoch 114: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9896 - loss: 0.0273 - precision: 0.9896 - recall: 0.9878 - val_accuracy: 0.5556 - val_loss: 0.2870 - val_precision: 0.5556 - val_recall: 0.5556 - learning_rate: 3.7500e-05\n",
      "Epoch 115/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9866 - loss: 0.0278 - precision: 0.9874 - recall: 0.9836\n",
      "Epoch 115: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9884 - loss: 0.0270 - precision: 0.9890 - recall: 0.9873 - val_accuracy: 0.5833 - val_loss: 0.2790 - val_precision: 0.5775 - val_recall: 0.5694 - learning_rate: 3.7500e-05\n",
      "Epoch 116/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9875 - loss: 0.0261 - precision: 0.9882 - recall: 0.9841\n",
      "Epoch 116: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9890 - loss: 0.0262 - precision: 0.9895 - recall: 0.9855 - val_accuracy: 0.5972 - val_loss: 0.2796 - val_precision: 0.5972 - val_recall: 0.5972 - learning_rate: 3.7500e-05\n",
      "Epoch 117/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9913 - loss: 0.0259 - precision: 0.9915 - recall: 0.9887\n",
      "Epoch 117: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9890 - loss: 0.0262 - precision: 0.9896 - recall: 0.9867 - val_accuracy: 0.5833 - val_loss: 0.2552 - val_precision: 0.5833 - val_recall: 0.5833 - learning_rate: 3.7500e-05\n",
      "Epoch 118/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9890 - loss: 0.0261 - precision: 0.9892 - recall: 0.9889\n",
      "Epoch 118: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9861 - loss: 0.0260 - precision: 0.9872 - recall: 0.9855 - val_accuracy: 0.5694 - val_loss: 0.2978 - val_precision: 0.5694 - val_recall: 0.5694 - learning_rate: 3.7500e-05\n",
      "Epoch 119/300\n",
      "\u001b[1m52/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 0.9947 - loss: 0.0251 - precision: 0.9958 - recall: 0.9927\n",
      "Epoch 119: val_loss did not improve from 0.20827\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9925 - loss: 0.0253 - precision: 0.9936 - recall: 0.9907 - val_accuracy: 0.5833 - val_loss: 0.2553 - val_precision: 0.5833 - val_recall: 0.5833 - learning_rate: 3.7500e-05\n",
      "Epoch 119: early stopping\n",
      "Restoring model weights from the end of the best epoch: 84.\n",
      "\n",
      "âœ“ CNN model training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train CNN model\n",
    "print(\"\\nğŸš€ Training CNN model...\")\n",
    "\n",
    "Path('models').mkdir(exist_ok=True)\n",
    "\n",
    "cnn_callbacks = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=35,  # Increased patience for 300 epochs\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=12,  # Increased patience\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath='models/cnn_best.weights.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_cnn = cnn_model.fit(\n",
    "    X_cnn_train_aug, y_cnn_train_aug,\n",
    "    validation_data=(X_cnn_val_scaled, y_cnn_val_onehot),\n",
    "    epochs=300,  # Increased from 150 to 300\n",
    "    batch_size=32,\n",
    "    class_weight=cnn_class_weight_dict,\n",
    "    callbacks=cnn_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ CNN model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9f59ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Evaluating CNN model...\n",
      "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step\n",
      "\n",
      "================================================================================\n",
      "CNN MODEL RESULTS\n",
      "================================================================================\n",
      "\n",
      "Train Set:\n",
      "  Accuracy:  0.9884\n",
      "  Precision: 0.9884\n",
      "  Recall:    0.9884\n",
      "  F1-Score:  0.9884\n",
      "\n",
      "Validation Set:\n",
      "  Accuracy:  0.5417\n",
      "  Precision: 0.7505\n",
      "  Recall:    0.5417\n",
      "  F1-Score:  0.5147\n",
      "\n",
      "Test Set:\n",
      "  Accuracy:  0.5694\n",
      "  Precision: 0.7734\n",
      "  Recall:    0.5694\n",
      "  F1-Score:  0.5236\n",
      "\n",
      "\n",
      "Test Set Confusion Matrix:\n",
      "[[ 3 21  0]\n",
      " [ 0 22  2]\n",
      " [ 0  8 16]]\n",
      "\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       1.00      0.12      0.22        24\n",
      "      Medium       0.43      0.92      0.59        24\n",
      "        High       0.89      0.67      0.76        24\n",
      "\n",
      "    accuracy                           0.57        72\n",
      "   macro avg       0.77      0.57      0.52        72\n",
      "weighted avg       0.77      0.57      0.52        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate CNN model\n",
    "print(\"\\nğŸ“Š Evaluating CNN model...\")\n",
    "\n",
    "y_cnn_pred_train_probs = cnn_model.predict(X_cnn_train_scaled)\n",
    "y_cnn_pred_val_probs = cnn_model.predict(X_cnn_val_scaled)\n",
    "y_cnn_pred_test_probs = cnn_model.predict(X_cnn_test_scaled)\n",
    "\n",
    "y_cnn_pred_train = np.argmax(y_cnn_pred_train_probs, axis=1)\n",
    "y_cnn_pred_val = np.argmax(y_cnn_pred_val_probs, axis=1)\n",
    "y_cnn_pred_test = np.argmax(y_cnn_pred_test_probs, axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CNN MODEL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for split_name, y_true, y_pred in [\n",
    "    ('Train', y_cnn_train_cat, y_cnn_pred_train),\n",
    "    ('Validation', y_cnn_val_cat, y_cnn_pred_val),\n",
    "    ('Test', y_cnn_test_cat, y_cnn_pred_test)\n",
    "]:\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{split_name} Set:\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(\"\\n\\nTest Set Confusion Matrix:\")\n",
    "print(confusion_matrix(y_cnn_test_cat, y_cnn_pred_test))\n",
    "\n",
    "print(\"\\n\\nTest Set Classification Report:\")\n",
    "print(classification_report(y_cnn_test_cat, y_cnn_pred_test, \n",
    "                          target_names=['Low', 'Medium', 'High']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b0b024",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: GRU Model (Gated Recurrent Unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81959e86",
   "metadata": {},
   "source": [
    "### What is GRU?\n",
    "\n",
    "GRU is a recurrent neural network (RNN) variant that maintains hidden state across time steps. Compared to LSTM:\n",
    "- **Fewer parameters** (2 gates vs 3 in LSTM)\n",
    "- **Faster training**\n",
    "- **Better for smaller datasets**\n",
    "- **Less prone to overfitting**\n",
    "\n",
    "**Why GRU for crop yield?**\n",
    "- Captures sequential dependencies (how previous months affect current growth)\n",
    "- Lighter than LSTM, better suited for 576 training samples\n",
    "- Bidirectional GRU sees both past and future context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d7c9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PART 2: GRU MODEL\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Loading GRU data...\n",
      "  Total GRU features: 28\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART 2: GRU MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load GRU data (same as CNN)\n",
    "print(\"\\nğŸ“Š Loading GRU data...\")\n",
    "gru_train = pd.read_csv(splits_path / 'gru' / 'train.csv')\n",
    "gru_val = pd.read_csv(splits_path / 'gru' / 'val.csv')\n",
    "gru_test = pd.read_csv(splits_path / 'gru' / 'test.csv')\n",
    "\n",
    "# Remove missing yields\n",
    "gru_train = gru_train.dropna(subset=[target_col])\n",
    "gru_val = gru_val.dropna(subset=[target_col])\n",
    "gru_test = gru_test.dropna(subset=[target_col])\n",
    "\n",
    "# Encode categorical\n",
    "gru_train['Crop_encoded'] = crop_encoder.transform(gru_train['Crop'])\n",
    "gru_train['Region_encoded'] = region_encoder.transform(gru_train['Region'])\n",
    "gru_val['Crop_encoded'] = crop_encoder.transform(gru_val['Crop'])\n",
    "gru_val['Region_encoded'] = region_encoder.transform(gru_val['Region'])\n",
    "gru_test['Crop_encoded'] = crop_encoder.transform(gru_test['Crop'])\n",
    "gru_test['Region_encoded'] = region_encoder.transform(gru_test['Region'])\n",
    "\n",
    "gru_all_features = gru_feature_cols + ['Crop_encoded', 'Region_encoded']\n",
    "\n",
    "print(f\"  Total GRU features: {len(gru_all_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f96d5686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Creating sequences for GRU...\n",
      "\n",
      "  Train sequences: (432, 12, 28)\n",
      "  Val sequences:   (72, 12, 28)\n",
      "  Test sequences:  (72, 12, 28)\n",
      "  âœ“ Features normalized\n"
     ]
    }
   ],
   "source": [
    "# Create sequences for GRU\n",
    "print(\"\\nğŸ“Š Creating sequences for GRU...\")\n",
    "\n",
    "X_gru_train, y_gru_train = create_sequences(gru_train, gru_all_features, target_col, sequence_length)\n",
    "X_gru_val, y_gru_val = create_sequences(gru_val, gru_all_features, target_col, sequence_length)\n",
    "X_gru_test, y_gru_test = create_sequences(gru_test, gru_all_features, target_col, sequence_length)\n",
    "\n",
    "print(f\"\\n  Train sequences: {X_gru_train.shape}\")\n",
    "print(f\"  Val sequences:   {X_gru_val.shape}\")\n",
    "print(f\"  Test sequences:  {X_gru_test.shape}\")\n",
    "\n",
    "# Normalize\n",
    "scaler_gru = StandardScaler()\n",
    "X_gru_train_reshaped = X_gru_train.reshape(-1, X_gru_train.shape[2])\n",
    "scaler_gru.fit(X_gru_train_reshaped)\n",
    "\n",
    "X_gru_train_scaled = scaler_gru.transform(X_gru_train.reshape(-1, X_gru_train.shape[2])).reshape(X_gru_train.shape)\n",
    "X_gru_val_scaled = scaler_gru.transform(X_gru_val.reshape(-1, X_gru_val.shape[2])).reshape(X_gru_val.shape)\n",
    "X_gru_test_scaled = scaler_gru.transform(X_gru_test.reshape(-1, X_gru_test.shape[2])).reshape(X_gru_test.shape)\n",
    "\n",
    "print(\"  âœ“ Features normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e8ce819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Categorizing yields for GRU...\n",
      "\n",
      "Class distribution (GRU Train):\n",
      "  Class 0: 144 samples (33.3%)\n",
      "  Class 1: 144 samples (33.3%)\n",
      "  Class 2: 144 samples (33.3%)\n"
     ]
    }
   ],
   "source": [
    "# Categorize yields\n",
    "print(\"\\nğŸ“Š Categorizing yields for GRU...\")\n",
    "\n",
    "y_gru_train_cat, gru_percentiles = categorize_yield_balanced(y_gru_train, method='percentile')\n",
    "y_gru_val_cat, _ = categorize_yield_balanced(y_gru_val, method='percentile')\n",
    "y_gru_test_cat, _ = categorize_yield_balanced(y_gru_test, method='percentile')\n",
    "\n",
    "print(f\"\\nClass distribution (GRU Train):\")\n",
    "unique, counts = np.unique(y_gru_train_cat, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"  Class {cls}: {count} samples ({count/len(y_gru_train_cat)*100:.1f}%)\")\n",
    "\n",
    "y_gru_train_onehot = to_categorical(y_gru_train_cat, num_classes=3)\n",
    "y_gru_val_onehot = to_categorical(y_gru_val_cat, num_classes=3)\n",
    "y_gru_test_onehot = to_categorical(y_gru_test_cat, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3443627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ APPLYING DATA AUGMENTATION (GRU)...\n",
      "  Augmented GRU training size: 1728 samples\n",
      "\n",
      "âš–ï¸  GRU Class weights:\n",
      "   Class 0: weight=1.000 (n=576 samples)\n",
      "   Class 1: weight=1.000 (n=576 samples)\n",
      "   Class 2: weight=1.000 (n=576 samples)\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation for GRU\n",
    "print(\"\\nğŸ”„ APPLYING DATA AUGMENTATION (GRU)...\")\n",
    "\n",
    "X_gru_train_aug, y_gru_train_aug = augment_time_series(\n",
    "    X_gru_train_scaled,\n",
    "    y_gru_train_onehot,\n",
    "    num_augmented=3,  # Increased from 1 to 3\n",
    "    noise_level=0.02  # Reduced noise for quality\n",
    ")\n",
    "\n",
    "print(f\"  Augmented GRU training size: {X_gru_train_aug.shape[0]} samples\")\n",
    "\n",
    "# Shuffle\n",
    "indices = np.random.permutation(X_gru_train_aug.shape[0])\n",
    "X_gru_train_aug = X_gru_train_aug[indices]\n",
    "y_gru_train_aug = y_gru_train_aug[indices]\n",
    "\n",
    "# Class weights\n",
    "y_gru_train_labels = np.argmax(y_gru_train_aug, axis=1)\n",
    "gru_class_weights_array = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_gru_train_labels),\n",
    "    y=y_gru_train_labels\n",
    ")\n",
    "gru_class_weight_dict = dict(enumerate(gru_class_weights_array))\n",
    "\n",
    "print(f\"\\nâš–ï¸  GRU Class weights:\")\n",
    "for cls, weight in gru_class_weight_dict.items():\n",
    "    count = np.sum(y_gru_train_labels == cls)\n",
    "    print(f\"   Class {cls}: weight={weight:.3f} (n={count} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bad9815c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">72,576</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_5           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_6           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">31,104</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_7           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_8           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m192\u001b[0m)        â”‚        \u001b[38;5;34m72,576\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_5           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m192\u001b[0m)        â”‚           \u001b[38;5;34m768\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m192\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m99,072\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_6           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m31,104\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_7           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_8           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚            \u001b[38;5;34m99\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">210,883</span> (823.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m210,883\u001b[0m (823.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">209,987</span> (820.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m209,987\u001b[0m (820.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build GRU model with Attention\n",
    "def build_gru_model(sequence_length, n_features, learning_rate=0.0003):\n",
    "    \"\"\"\n",
    "    Build Bidirectional GRU model with attention.\n",
    "    \n",
    "    Architecture:\n",
    "    - Bidirectional GRU layers capture forward and backward patterns\n",
    "    - Attention mechanism for focusing on key time steps\n",
    "    - Enhanced regularization to prevent overfitting\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(sequence_length, n_features)),\n",
    "        \n",
    "        # First Bidirectional GRU layer\n",
    "        layers.Bidirectional(layers.GRU(96, return_sequences=True,\n",
    "                                       kernel_regularizer=regularizers.l2(0.003),\n",
    "                                       recurrent_regularizer=regularizers.l2(0.003),\n",
    "                                       dropout=0.3,\n",
    "                                       recurrent_dropout=0.3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Second Bidirectional GRU layer\n",
    "        layers.Bidirectional(layers.GRU(64, return_sequences=True,\n",
    "                                       kernel_regularizer=regularizers.l2(0.003),\n",
    "                                       recurrent_regularizer=regularizers.l2(0.003),\n",
    "                                       dropout=0.3,\n",
    "                                       recurrent_dropout=0.3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Third GRU layer\n",
    "        layers.Bidirectional(layers.GRU(32, return_sequences=False,\n",
    "                                       kernel_regularizer=regularizers.l2(0.002),\n",
    "                                       recurrent_regularizer=regularizers.l2(0.002),\n",
    "                                       dropout=0.2,\n",
    "                                       recurrent_dropout=0.2)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Output layer\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate, clipnorm=1.0)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=focal_loss(gamma=2.0, alpha=0.25),\n",
    "        metrics=['accuracy',\n",
    "                 tf.keras.metrics.Precision(name='precision'),\n",
    "                 tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "gru_model = build_gru_model(\n",
    "    sequence_length=sequence_length,\n",
    "    n_features=X_gru_train_aug.shape[2],\n",
    "    learning_rate=0.0003\n",
    ")\n",
    "gru_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44a8c1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training GRU model...\n",
      "Epoch 1/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.3341 - loss: 3.3793 - precision: 0.3406 - recall: 0.2807\n",
      "Epoch 1: val_loss improved from None to 2.93914, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 1: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m40s\u001b[0m 204ms/step - accuracy: 0.3628 - loss: 3.2838 - precision: 0.3744 - recall: 0.3061 - val_accuracy: 0.5417 - val_loss: 2.9391 - val_precision: 1.0000 - val_recall: 0.0833 - learning_rate: 3.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4219 - loss: 3.0137 - precision: 0.4411 - recall: 0.3567\n",
      "Epoch 2: val_loss improved from 2.93914 to 2.63644, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 2: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m13s\u001b[0m 52ms/step - accuracy: 0.4253 - loss: 2.9400 - precision: 0.4442 - recall: 0.3594 - val_accuracy: 0.5972 - val_loss: 2.6364 - val_precision: 0.6316 - val_recall: 0.3333 - learning_rate: 3.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4704 - loss: 2.7046 - precision: 0.4877 - recall: 0.3974\n",
      "Epoch 3: val_loss improved from 2.63644 to 2.38042, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 3: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.4786 - loss: 2.6374 - precision: 0.5014 - recall: 0.4068 - val_accuracy: 0.6111 - val_loss: 2.3804 - val_precision: 0.6727 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.4879 - loss: 2.4394 - precision: 0.5134 - recall: 0.4185\n",
      "Epoch 4: val_loss improved from 2.38042 to 2.17322, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 4: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.4994 - loss: 2.3881 - precision: 0.5214 - recall: 0.4230 - val_accuracy: 0.6389 - val_loss: 2.1732 - val_precision: 0.6406 - val_recall: 0.5694 - learning_rate: 3.0000e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.5236 - loss: 2.2043 - precision: 0.5639 - recall: 0.4550\n",
      "Epoch 5: val_loss improved from 2.17322 to 1.99825, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 5: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.5411 - loss: 2.1612 - precision: 0.5754 - recall: 0.4659 - val_accuracy: 0.6389 - val_loss: 1.9982 - val_precision: 0.6667 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.5434 - loss: 2.0259 - precision: 0.5835 - recall: 0.4752\n",
      "Epoch 6: val_loss improved from 1.99825 to 1.84276, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 6: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 82ms/step - accuracy: 0.5469 - loss: 1.9876 - precision: 0.5779 - recall: 0.4763 - val_accuracy: 0.6389 - val_loss: 1.8428 - val_precision: 0.6522 - val_recall: 0.6250 - learning_rate: 3.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.5721 - loss: 1.8653 - precision: 0.6046 - recall: 0.4942\n",
      "Epoch 7: val_loss improved from 1.84276 to 1.71318, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 7: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.5775 - loss: 1.8273 - precision: 0.6082 - recall: 0.4994 - val_accuracy: 0.6528 - val_loss: 1.7132 - val_precision: 0.6522 - val_recall: 0.6250 - learning_rate: 3.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5991 - loss: 1.7218 - precision: 0.6269 - recall: 0.5165\n",
      "Epoch 8: val_loss improved from 1.71318 to 1.59619, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 8: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.5793 - loss: 1.6918 - precision: 0.6071 - recall: 0.5017 - val_accuracy: 0.6806 - val_loss: 1.5962 - val_precision: 0.6812 - val_recall: 0.6528 - learning_rate: 3.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.5886 - loss: 1.5956 - precision: 0.6135 - recall: 0.5132\n",
      "Epoch 9: val_loss improved from 1.59619 to 1.48964, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 9: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.5914 - loss: 1.5708 - precision: 0.6154 - recall: 0.5168 - val_accuracy: 0.7361 - val_loss: 1.4896 - val_precision: 0.7353 - val_recall: 0.6944 - learning_rate: 3.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5705 - loss: 1.4980 - precision: 0.5957 - recall: 0.4974\n",
      "Epoch 10: val_loss improved from 1.48964 to 1.40252, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 10: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 58ms/step - accuracy: 0.5833 - loss: 1.4746 - precision: 0.6054 - recall: 0.5017 - val_accuracy: 0.6667 - val_loss: 1.4025 - val_precision: 0.6765 - val_recall: 0.6389 - learning_rate: 3.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.5939 - loss: 1.3930 - precision: 0.6254 - recall: 0.5232\n",
      "Epoch 11: val_loss improved from 1.40252 to 1.32211, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 11: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.5914 - loss: 1.3735 - precision: 0.6281 - recall: 0.5179 - val_accuracy: 0.6667 - val_loss: 1.3221 - val_precision: 0.6912 - val_recall: 0.6528 - learning_rate: 3.0000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6186 - loss: 1.3066 - precision: 0.6478 - recall: 0.5362\n",
      "Epoch 12: val_loss improved from 1.32211 to 1.24435, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 12: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.6111 - loss: 1.2874 - precision: 0.6446 - recall: 0.5301 - val_accuracy: 0.6667 - val_loss: 1.2444 - val_precision: 0.6812 - val_recall: 0.6528 - learning_rate: 3.0000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6191 - loss: 1.2311 - precision: 0.6494 - recall: 0.5417\n",
      "Epoch 13: val_loss improved from 1.24435 to 1.17379, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 13: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.6105 - loss: 1.2129 - precision: 0.6328 - recall: 0.5365 - val_accuracy: 0.6667 - val_loss: 1.1738 - val_precision: 0.6761 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6049 - loss: 1.1614 - precision: 0.6420 - recall: 0.5395\n",
      "Epoch 14: val_loss improved from 1.17379 to 1.10948, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 14: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.6117 - loss: 1.1425 - precision: 0.6508 - recall: 0.5521 - val_accuracy: 0.6944 - val_loss: 1.1095 - val_precision: 0.6944 - val_recall: 0.6944 - learning_rate: 3.0000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.6242 - loss: 1.0949 - precision: 0.6507 - recall: 0.5557\n",
      "Epoch 15: val_loss improved from 1.10948 to 1.05035, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 15: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.6227 - loss: 1.0809 - precision: 0.6523 - recall: 0.5515 - val_accuracy: 0.6806 - val_loss: 1.0504 - val_precision: 0.6806 - val_recall: 0.6806 - learning_rate: 3.0000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6444 - loss: 1.0337 - precision: 0.6678 - recall: 0.5665\n",
      "Epoch 16: val_loss improved from 1.05035 to 0.99693, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 16: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.6377 - loss: 1.0206 - precision: 0.6551 - recall: 0.5550 - val_accuracy: 0.6944 - val_loss: 0.9969 - val_precision: 0.6944 - val_recall: 0.6944 - learning_rate: 3.0000e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6202 - loss: 0.9806 - precision: 0.6425 - recall: 0.5539\n",
      "Epoch 17: val_loss improved from 0.99693 to 0.94798, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 17: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.6209 - loss: 0.9666 - precision: 0.6449 - recall: 0.5486 - val_accuracy: 0.6944 - val_loss: 0.9480 - val_precision: 0.7042 - val_recall: 0.6944 - learning_rate: 3.0000e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6316 - loss: 0.9294 - precision: 0.6536 - recall: 0.5648\n",
      "Epoch 18: val_loss improved from 0.94798 to 0.90188, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 18: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.6331 - loss: 0.9127 - precision: 0.6523 - recall: 0.5625 - val_accuracy: 0.6806 - val_loss: 0.9019 - val_precision: 0.6761 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6323 - loss: 0.8795 - precision: 0.6590 - recall: 0.5660\n",
      "Epoch 19: val_loss improved from 0.90188 to 0.85879, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 19: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.6302 - loss: 0.8664 - precision: 0.6567 - recall: 0.5613 - val_accuracy: 0.7083 - val_loss: 0.8588 - val_precision: 0.7000 - val_recall: 0.6806 - learning_rate: 3.0000e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6696 - loss: 0.8300 - precision: 0.7029 - recall: 0.6056\n",
      "Epoch 20: val_loss improved from 0.85879 to 0.81382, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 20: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.6782 - loss: 0.8167 - precision: 0.7079 - recall: 0.6088 - val_accuracy: 0.6944 - val_loss: 0.8138 - val_precision: 0.6944 - val_recall: 0.6944 - learning_rate: 3.0000e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.6424 - loss: 0.7867 - precision: 0.6839 - recall: 0.5713\n",
      "Epoch 21: val_loss improved from 0.81382 to 0.77541, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 21: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.6464 - loss: 0.7779 - precision: 0.6810 - recall: 0.5781 - val_accuracy: 0.7083 - val_loss: 0.7754 - val_precision: 0.7183 - val_recall: 0.7083 - learning_rate: 3.0000e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.6308 - loss: 0.7500 - precision: 0.6584 - recall: 0.5740\n",
      "Epoch 22: val_loss improved from 0.77541 to 0.73493, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 22: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.6308 - loss: 0.7391 - precision: 0.6552 - recall: 0.5631 - val_accuracy: 0.6944 - val_loss: 0.7349 - val_precision: 0.7042 - val_recall: 0.6944 - learning_rate: 3.0000e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.6628 - loss: 0.7066 - precision: 0.6935 - recall: 0.5836\n",
      "Epoch 23: val_loss improved from 0.73493 to 0.70523, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 23: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.6701 - loss: 0.6977 - precision: 0.7014 - recall: 0.5955 - val_accuracy: 0.6667 - val_loss: 0.7052 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.6615 - loss: 0.6735 - precision: 0.6839 - recall: 0.5883\n",
      "Epoch 24: val_loss improved from 0.70523 to 0.67061, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 24: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.6811 - loss: 0.6623 - precision: 0.7049 - recall: 0.6123 - val_accuracy: 0.6667 - val_loss: 0.6706 - val_precision: 0.6620 - val_recall: 0.6528 - learning_rate: 3.0000e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6810 - loss: 0.6391 - precision: 0.7075 - recall: 0.6091\n",
      "Epoch 25: val_loss improved from 0.67061 to 0.63847, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 25: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.6858 - loss: 0.6297 - precision: 0.7052 - recall: 0.6076 - val_accuracy: 0.6528 - val_loss: 0.6385 - val_precision: 0.6812 - val_recall: 0.6528 - learning_rate: 3.0000e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6458 - loss: 0.6064 - precision: 0.6647 - recall: 0.5688\n",
      "Epoch 26: val_loss improved from 0.63847 to 0.61359, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 26: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.6499 - loss: 0.5987 - precision: 0.6773 - recall: 0.5758 - val_accuracy: 0.6528 - val_loss: 0.6136 - val_precision: 0.6377 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6705 - loss: 0.5735 - precision: 0.6961 - recall: 0.6090\n",
      "Epoch 27: val_loss improved from 0.61359 to 0.58627, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 27: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.6962 - loss: 0.5655 - precision: 0.7169 - recall: 0.6169 - val_accuracy: 0.6528 - val_loss: 0.5863 - val_precision: 0.6522 - val_recall: 0.6250 - learning_rate: 3.0000e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.6758 - loss: 0.5449 - precision: 0.7151 - recall: 0.6017\n",
      "Epoch 28: val_loss improved from 0.58627 to 0.55962, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 28: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6939 - loss: 0.5401 - precision: 0.7246 - recall: 0.6152 - val_accuracy: 0.6806 - val_loss: 0.5596 - val_precision: 0.6714 - val_recall: 0.6528 - learning_rate: 3.0000e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.6938 - loss: 0.5205 - precision: 0.7174 - recall: 0.6206\n",
      "Epoch 29: val_loss improved from 0.55962 to 0.53121, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 29: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 99ms/step - accuracy: 0.7014 - loss: 0.5136 - precision: 0.7250 - recall: 0.6256 - val_accuracy: 0.6528 - val_loss: 0.5312 - val_precision: 0.6567 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.6800 - loss: 0.4957 - precision: 0.7018 - recall: 0.6064\n",
      "Epoch 30: val_loss improved from 0.53121 to 0.50918, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 30: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 54ms/step - accuracy: 0.6933 - loss: 0.4881 - precision: 0.7198 - recall: 0.6198 - val_accuracy: 0.6111 - val_loss: 0.5092 - val_precision: 0.6029 - val_recall: 0.5694 - learning_rate: 3.0000e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.6862 - loss: 0.4688 - precision: 0.7161 - recall: 0.6177\n",
      "Epoch 31: val_loss improved from 0.50918 to 0.48648, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 31: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.6997 - loss: 0.4639 - precision: 0.7271 - recall: 0.6337 - val_accuracy: 0.6250 - val_loss: 0.4865 - val_precision: 0.6232 - val_recall: 0.5972 - learning_rate: 3.0000e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6840 - loss: 0.4465 - precision: 0.7092 - recall: 0.6158\n",
      "Epoch 32: val_loss improved from 0.48648 to 0.46501, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 32: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6858 - loss: 0.4415 - precision: 0.7134 - recall: 0.6181 - val_accuracy: 0.6528 - val_loss: 0.4650 - val_precision: 0.6479 - val_recall: 0.6389 - learning_rate: 3.0000e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.6947 - loss: 0.4274 - precision: 0.7186 - recall: 0.6256\n",
      "Epoch 33: val_loss improved from 0.46501 to 0.44466, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 33: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.6973 - loss: 0.4230 - precision: 0.7186 - recall: 0.6267 - val_accuracy: 0.6389 - val_loss: 0.4447 - val_precision: 0.6377 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7056 - loss: 0.4043 - precision: 0.7217 - recall: 0.6366\n",
      "Epoch 34: val_loss improved from 0.44466 to 0.42960, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 34: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.6887 - loss: 0.4016 - precision: 0.7102 - recall: 0.6227 - val_accuracy: 0.6250 - val_loss: 0.4296 - val_precision: 0.6176 - val_recall: 0.5833 - learning_rate: 3.0000e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.6840 - loss: 0.3912 - precision: 0.7090 - recall: 0.6016\n",
      "Epoch 35: val_loss improved from 0.42960 to 0.41302, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 35: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.6973 - loss: 0.3830 - precision: 0.7218 - recall: 0.6215 - val_accuracy: 0.6389 - val_loss: 0.4130 - val_precision: 0.6471 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7130 - loss: 0.3689 - precision: 0.7388 - recall: 0.6456\n",
      "Epoch 36: val_loss improved from 0.41302 to 0.38994, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 36: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - accuracy: 0.7014 - loss: 0.3664 - precision: 0.7293 - recall: 0.6267 - val_accuracy: 0.6528 - val_loss: 0.3899 - val_precision: 0.6418 - val_recall: 0.5972 - learning_rate: 3.0000e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6890 - loss: 0.3504 - precision: 0.7148 - recall: 0.6102\n",
      "Epoch 37: val_loss improved from 0.38994 to 0.37611, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 37: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7124 - loss: 0.3452 - precision: 0.7375 - recall: 0.6325 - val_accuracy: 0.6389 - val_loss: 0.3761 - val_precision: 0.6515 - val_recall: 0.5972 - learning_rate: 3.0000e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7125 - loss: 0.3345 - precision: 0.7390 - recall: 0.6337\n",
      "Epoch 38: val_loss improved from 0.37611 to 0.35374, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 38: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.7043 - loss: 0.3310 - precision: 0.7340 - recall: 0.6325 - val_accuracy: 0.6111 - val_loss: 0.3537 - val_precision: 0.6094 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7309 - loss: 0.3164 - precision: 0.7550 - recall: 0.6609\n",
      "Epoch 39: val_loss improved from 0.35374 to 0.34498, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 39: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.7245 - loss: 0.3133 - precision: 0.7548 - recall: 0.6557 - val_accuracy: 0.5694 - val_loss: 0.3450 - val_precision: 0.5588 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7085 - loss: 0.3054 - precision: 0.7506 - recall: 0.6475\n",
      "Epoch 40: val_loss improved from 0.34498 to 0.32769, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 40: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.7083 - loss: 0.3009 - precision: 0.7420 - recall: 0.6441 - val_accuracy: 0.6111 - val_loss: 0.3277 - val_precision: 0.6119 - val_recall: 0.5694 - learning_rate: 3.0000e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7117 - loss: 0.2905 - precision: 0.7346 - recall: 0.6412\n",
      "Epoch 41: val_loss improved from 0.32769 to 0.31429, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 41: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.7193 - loss: 0.2870 - precision: 0.7407 - recall: 0.6429 - val_accuracy: 0.5833 - val_loss: 0.3143 - val_precision: 0.5846 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7307 - loss: 0.2757 - precision: 0.7533 - recall: 0.6493\n",
      "Epoch 42: val_loss improved from 0.31429 to 0.29953, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 42: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7378 - loss: 0.2718 - precision: 0.7646 - recall: 0.6580 - val_accuracy: 0.6250 - val_loss: 0.2995 - val_precision: 0.6143 - val_recall: 0.5972 - learning_rate: 3.0000e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7170 - loss: 0.2663 - precision: 0.7443 - recall: 0.6425\n",
      "Epoch 43: val_loss improved from 0.29953 to 0.28189, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 43: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.7269 - loss: 0.2602 - precision: 0.7542 - recall: 0.6534 - val_accuracy: 0.6250 - val_loss: 0.2819 - val_precision: 0.6232 - val_recall: 0.5972 - learning_rate: 3.0000e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7293 - loss: 0.2495 - precision: 0.7529 - recall: 0.6616\n",
      "Epoch 44: val_loss improved from 0.28189 to 0.27942, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 44: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.7176 - loss: 0.2470 - precision: 0.7417 - recall: 0.6481 - val_accuracy: 0.5694 - val_loss: 0.2794 - val_precision: 0.5797 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7223 - loss: 0.2389 - precision: 0.7498 - recall: 0.6564\n",
      "Epoch 45: val_loss improved from 0.27942 to 0.27119, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 45: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 0.7280 - loss: 0.2356 - precision: 0.7581 - recall: 0.6638 - val_accuracy: 0.5556 - val_loss: 0.2712 - val_precision: 0.5714 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7484 - loss: 0.2294 - precision: 0.7710 - recall: 0.6709\n",
      "Epoch 46: val_loss improved from 0.27119 to 0.25417, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 46: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.7436 - loss: 0.2268 - precision: 0.7698 - recall: 0.6696 - val_accuracy: 0.5833 - val_loss: 0.2542 - val_precision: 0.5714 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.7420 - loss: 0.2182 - precision: 0.7676 - recall: 0.6739\n",
      "Epoch 47: val_loss improved from 0.25417 to 0.24277, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 47: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.7321 - loss: 0.2171 - precision: 0.7706 - recall: 0.6649 - val_accuracy: 0.5972 - val_loss: 0.2428 - val_precision: 0.5942 - val_recall: 0.5694 - learning_rate: 3.0000e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7444 - loss: 0.2086 - precision: 0.7835 - recall: 0.6689\n",
      "Epoch 48: val_loss improved from 0.24277 to 0.22869, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 48: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 91ms/step - accuracy: 0.7361 - loss: 0.2073 - precision: 0.7718 - recall: 0.6713 - val_accuracy: 0.6111 - val_loss: 0.2287 - val_precision: 0.6143 - val_recall: 0.5972 - learning_rate: 3.0000e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7233 - loss: 0.2010 - precision: 0.7536 - recall: 0.6640\n",
      "Epoch 49: val_loss improved from 0.22869 to 0.21771, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 49: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.7315 - loss: 0.1991 - precision: 0.7584 - recall: 0.6649 - val_accuracy: 0.5833 - val_loss: 0.2177 - val_precision: 0.5588 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7229 - loss: 0.1921 - precision: 0.7454 - recall: 0.6468\n",
      "Epoch 50: val_loss did not improve from 0.21771\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.7442 - loss: 0.1895 - precision: 0.7698 - recall: 0.6597 - val_accuracy: 0.5833 - val_loss: 0.2246 - val_precision: 0.5915 - val_recall: 0.5833 - learning_rate: 3.0000e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.7354 - loss: 0.1854 - precision: 0.7720 - recall: 0.6643\n",
      "Epoch 51: val_loss improved from 0.21771 to 0.21324, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 51: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.7384 - loss: 0.1821 - precision: 0.7685 - recall: 0.6626 - val_accuracy: 0.6250 - val_loss: 0.2132 - val_precision: 0.6143 - val_recall: 0.5972 - learning_rate: 3.0000e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7116 - loss: 0.1766 - precision: 0.7473 - recall: 0.6370\n",
      "Epoch 52: val_loss improved from 0.21324 to 0.20822, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 52: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7205 - loss: 0.1756 - precision: 0.7582 - recall: 0.6516 - val_accuracy: 0.6389 - val_loss: 0.2082 - val_precision: 0.6286 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.7427 - loss: 0.1668 - precision: 0.7798 - recall: 0.6825\n",
      "Epoch 53: val_loss improved from 0.20822 to 0.20026, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 53: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.7350 - loss: 0.1652 - precision: 0.7749 - recall: 0.6696 - val_accuracy: 0.5833 - val_loss: 0.2003 - val_precision: 0.5833 - val_recall: 0.5833 - learning_rate: 3.0000e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7395 - loss: 0.1616 - precision: 0.7670 - recall: 0.6662\n",
      "Epoch 54: val_loss improved from 0.20026 to 0.18944, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 54: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7350 - loss: 0.1592 - precision: 0.7645 - recall: 0.6632 - val_accuracy: 0.5000 - val_loss: 0.1894 - val_precision: 0.5070 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7559 - loss: 0.1549 - precision: 0.7807 - recall: 0.6781\n",
      "Epoch 55: val_loss improved from 0.18944 to 0.18345, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 55: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7564 - loss: 0.1524 - precision: 0.7805 - recall: 0.6748 - val_accuracy: 0.5833 - val_loss: 0.1835 - val_precision: 0.5857 - val_recall: 0.5694 - learning_rate: 3.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7487 - loss: 0.1482 - precision: 0.7746 - recall: 0.6808\n",
      "Epoch 56: val_loss improved from 0.18345 to 0.17343, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 56: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.7488 - loss: 0.1461 - precision: 0.7804 - recall: 0.6829 - val_accuracy: 0.5833 - val_loss: 0.1734 - val_precision: 0.5915 - val_recall: 0.5833 - learning_rate: 3.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.7401 - loss: 0.1423 - precision: 0.7731 - recall: 0.6751\n",
      "Epoch 57: val_loss did not improve from 0.17343\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7326 - loss: 0.1412 - precision: 0.7637 - recall: 0.6620 - val_accuracy: 0.5278 - val_loss: 0.1769 - val_precision: 0.5429 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7590 - loss: 0.1343 - precision: 0.7928 - recall: 0.6918\n",
      "Epoch 58: val_loss improved from 0.17343 to 0.15513, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 58: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.7610 - loss: 0.1338 - precision: 0.7903 - recall: 0.6892 - val_accuracy: 0.6667 - val_loss: 0.1551 - val_precision: 0.6620 - val_recall: 0.6528 - learning_rate: 3.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7814 - loss: 0.1294 - precision: 0.7980 - recall: 0.6991\n",
      "Epoch 59: val_loss did not improve from 0.15513\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.7807 - loss: 0.1278 - precision: 0.8024 - recall: 0.6979 - val_accuracy: 0.5556 - val_loss: 0.1590 - val_precision: 0.5571 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.7586 - loss: 0.1263 - precision: 0.7839 - recall: 0.6913\n",
      "Epoch 60: val_loss did not improve from 0.15513\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.7523 - loss: 0.1244 - precision: 0.7819 - recall: 0.6869 - val_accuracy: 0.5972 - val_loss: 0.1568 - val_precision: 0.6176 - val_recall: 0.5833 - learning_rate: 3.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7764 - loss: 0.1180 - precision: 0.8072 - recall: 0.7167\n",
      "Epoch 61: val_loss improved from 0.15513 to 0.14458, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 61: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.7731 - loss: 0.1178 - precision: 0.8086 - recall: 0.7112 - val_accuracy: 0.5694 - val_loss: 0.1446 - val_precision: 0.5857 - val_recall: 0.5694 - learning_rate: 3.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7402 - loss: 0.1158 - precision: 0.7737 - recall: 0.6940\n",
      "Epoch 62: val_loss improved from 0.14458 to 0.14103, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 62: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.7448 - loss: 0.1146 - precision: 0.7763 - recall: 0.6910 - val_accuracy: 0.5278 - val_loss: 0.1410 - val_precision: 0.5441 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.7591 - loss: 0.1111 - precision: 0.7868 - recall: 0.7148\n",
      "Epoch 63: val_loss improved from 0.14103 to 0.13773, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 63: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 52ms/step - accuracy: 0.7598 - loss: 0.1105 - precision: 0.7863 - recall: 0.7112 - val_accuracy: 0.5278 - val_loss: 0.1377 - val_precision: 0.5429 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7600 - loss: 0.1092 - precision: 0.7995 - recall: 0.7104\n",
      "Epoch 64: val_loss did not improve from 0.13773\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.7604 - loss: 0.1075 - precision: 0.7942 - recall: 0.7078 - val_accuracy: 0.5417 - val_loss: 0.1484 - val_precision: 0.5507 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7606 - loss: 0.1043 - precision: 0.7810 - recall: 0.6957\n",
      "Epoch 65: val_loss improved from 0.13773 to 0.13062, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 65: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.7622 - loss: 0.1033 - precision: 0.7858 - recall: 0.7025 - val_accuracy: 0.5833 - val_loss: 0.1306 - val_precision: 0.6087 - val_recall: 0.5833 - learning_rate: 3.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7695 - loss: 0.1019 - precision: 0.7945 - recall: 0.7106\n",
      "Epoch 66: val_loss improved from 0.13062 to 0.11727, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 66: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.7662 - loss: 0.0990 - precision: 0.7927 - recall: 0.7147 - val_accuracy: 0.5417 - val_loss: 0.1173 - val_precision: 0.5652 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7704 - loss: 0.0956 - precision: 0.7968 - recall: 0.7198\n",
      "Epoch 67: val_loss improved from 0.11727 to 0.11384, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 67: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 44ms/step - accuracy: 0.7587 - loss: 0.0952 - precision: 0.7836 - recall: 0.7083 - val_accuracy: 0.5833 - val_loss: 0.1138 - val_precision: 0.5797 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7609 - loss: 0.0954 - precision: 0.7830 - recall: 0.7017\n",
      "Epoch 68: val_loss improved from 0.11384 to 0.11050, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 68: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.7587 - loss: 0.0941 - precision: 0.7851 - recall: 0.6997 - val_accuracy: 0.5417 - val_loss: 0.1105 - val_precision: 0.5507 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.7470 - loss: 0.0944 - precision: 0.7835 - recall: 0.6955\n",
      "Epoch 69: val_loss did not improve from 0.11050\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 93ms/step - accuracy: 0.7552 - loss: 0.0923 - precision: 0.7837 - recall: 0.6962 - val_accuracy: 0.5278 - val_loss: 0.1248 - val_precision: 0.5286 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.7667 - loss: 0.0892 - precision: 0.7946 - recall: 0.7160\n",
      "Epoch 70: val_loss did not improve from 0.11050\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.7784 - loss: 0.0878 - precision: 0.8049 - recall: 0.7234 - val_accuracy: 0.6250 - val_loss: 0.1107 - val_precision: 0.6429 - val_recall: 0.6250 - learning_rate: 3.0000e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7667 - loss: 0.0863 - precision: 0.7939 - recall: 0.7039\n",
      "Epoch 71: val_loss did not improve from 0.11050\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7679 - loss: 0.0842 - precision: 0.7921 - recall: 0.7164 - val_accuracy: 0.5556 - val_loss: 0.1156 - val_precision: 0.5493 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7662 - loss: 0.0852 - precision: 0.7927 - recall: 0.7125\n",
      "Epoch 72: val_loss improved from 0.11050 to 0.10406, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 72: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 81ms/step - accuracy: 0.7737 - loss: 0.0834 - precision: 0.7918 - recall: 0.7176 - val_accuracy: 0.6111 - val_loss: 0.1041 - val_precision: 0.6029 - val_recall: 0.5694 - learning_rate: 3.0000e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7774 - loss: 0.0802 - precision: 0.8056 - recall: 0.7156\n",
      "Epoch 73: val_loss did not improve from 0.10406\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.7697 - loss: 0.0798 - precision: 0.7943 - recall: 0.7106 - val_accuracy: 0.5833 - val_loss: 0.1044 - val_precision: 0.5915 - val_recall: 0.5833 - learning_rate: 3.0000e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7681 - loss: 0.0775 - precision: 0.7820 - recall: 0.7190\n",
      "Epoch 74: val_loss did not improve from 0.10406\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.7691 - loss: 0.0768 - precision: 0.7878 - recall: 0.7176 - val_accuracy: 0.5972 - val_loss: 0.1125 - val_precision: 0.5857 - val_recall: 0.5694 - learning_rate: 3.0000e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7722 - loss: 0.0757 - precision: 0.7931 - recall: 0.7206\n",
      "Epoch 75: val_loss improved from 0.10406 to 0.10380, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 75: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.7778 - loss: 0.0756 - precision: 0.7960 - recall: 0.7182 - val_accuracy: 0.4722 - val_loss: 0.1038 - val_precision: 0.4714 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7679 - loss: 0.0739 - precision: 0.7853 - recall: 0.7160\n",
      "Epoch 76: val_loss did not improve from 0.10380\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.7726 - loss: 0.0736 - precision: 0.7924 - recall: 0.7222 - val_accuracy: 0.4861 - val_loss: 0.1078 - val_precision: 0.5000 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7739 - loss: 0.0737 - precision: 0.7985 - recall: 0.7349\n",
      "Epoch 77: val_loss improved from 0.10380 to 0.10126, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 77: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - accuracy: 0.7841 - loss: 0.0717 - precision: 0.8105 - recall: 0.7402 - val_accuracy: 0.5278 - val_loss: 0.1013 - val_precision: 0.5286 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.7874 - loss: 0.0707 - precision: 0.8096 - recall: 0.7411\n",
      "Epoch 78: val_loss improved from 0.10126 to 0.09115, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 78: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.7853 - loss: 0.0699 - precision: 0.8028 - recall: 0.7326 - val_accuracy: 0.6250 - val_loss: 0.0911 - val_precision: 0.6429 - val_recall: 0.6250 - learning_rate: 3.0000e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7843 - loss: 0.0675 - precision: 0.8086 - recall: 0.7365\n",
      "Epoch 79: val_loss did not improve from 0.09115\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.7841 - loss: 0.0696 - precision: 0.8040 - recall: 0.7286 - val_accuracy: 0.4861 - val_loss: 0.1241 - val_precision: 0.5072 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.7839 - loss: 0.0673 - precision: 0.7994 - recall: 0.7355\n",
      "Epoch 80: val_loss did not improve from 0.09115\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.7778 - loss: 0.0680 - precision: 0.7944 - recall: 0.7245 - val_accuracy: 0.5417 - val_loss: 0.1163 - val_precision: 0.5507 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.7879 - loss: 0.0648 - precision: 0.8054 - recall: 0.7343\n",
      "Epoch 81: val_loss did not improve from 0.09115\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.7865 - loss: 0.0649 - precision: 0.8009 - recall: 0.7332 - val_accuracy: 0.5833 - val_loss: 0.0929 - val_precision: 0.5833 - val_recall: 0.5833 - learning_rate: 3.0000e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7592 - loss: 0.0664 - precision: 0.7801 - recall: 0.7181\n",
      "Epoch 82: val_loss did not improve from 0.09115\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.7616 - loss: 0.0660 - precision: 0.7813 - recall: 0.7176 - val_accuracy: 0.6111 - val_loss: 0.1009 - val_precision: 0.6087 - val_recall: 0.5833 - learning_rate: 3.0000e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7810 - loss: 0.0641 - precision: 0.8142 - recall: 0.7435\n",
      "Epoch 83: val_loss did not improve from 0.09115\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.7789 - loss: 0.0645 - precision: 0.8035 - recall: 0.7384 - val_accuracy: 0.5556 - val_loss: 0.0994 - val_precision: 0.5652 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7640 - loss: 0.0682 - precision: 0.7882 - recall: 0.7162\n",
      "Epoch 84: val_loss did not improve from 0.09115\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.7645 - loss: 0.0658 - precision: 0.7910 - recall: 0.7095 - val_accuracy: 0.5417 - val_loss: 0.0968 - val_precision: 0.5417 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7890 - loss: 0.0605 - precision: 0.8041 - recall: 0.7301\n",
      "Epoch 85: val_loss improved from 0.09115 to 0.08854, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 85: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.7807 - loss: 0.0614 - precision: 0.7978 - recall: 0.7216 - val_accuracy: 0.5278 - val_loss: 0.0885 - val_precision: 0.5278 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7575 - loss: 0.0624 - precision: 0.7822 - recall: 0.7052\n",
      "Epoch 86: val_loss did not improve from 0.08854\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.7708 - loss: 0.0612 - precision: 0.7954 - recall: 0.7176 - val_accuracy: 0.5417 - val_loss: 0.1017 - val_precision: 0.5493 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7784 - loss: 0.0576 - precision: 0.8036 - recall: 0.7369\n",
      "Epoch 87: val_loss did not improve from 0.08854\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.7801 - loss: 0.0605 - precision: 0.8032 - recall: 0.7367 - val_accuracy: 0.5417 - val_loss: 0.1025 - val_precision: 0.5571 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7976 - loss: 0.0569 - precision: 0.8224 - recall: 0.7475\n",
      "Epoch 88: val_loss did not improve from 0.08854\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 0.8044 - loss: 0.0568 - precision: 0.8253 - recall: 0.7488 - val_accuracy: 0.5694 - val_loss: 0.0914 - val_precision: 0.5775 - val_recall: 0.5694 - learning_rate: 3.0000e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7853 - loss: 0.0568 - precision: 0.8098 - recall: 0.7277\n",
      "Epoch 89: val_loss did not improve from 0.08854\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 59ms/step - accuracy: 0.7818 - loss: 0.0569 - precision: 0.8042 - recall: 0.7274 - val_accuracy: 0.5556 - val_loss: 0.0913 - val_precision: 0.5634 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7602 - loss: 0.0597 - precision: 0.7753 - recall: 0.7187\n",
      "Epoch 90: val_loss did not improve from 0.08854\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.7691 - loss: 0.0579 - precision: 0.7857 - recall: 0.7234 - val_accuracy: 0.5556 - val_loss: 0.0899 - val_precision: 0.5556 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7737 - loss: 0.0567 - precision: 0.7959 - recall: 0.7359\n",
      "Epoch 91: val_loss did not improve from 0.08854\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.7859 - loss: 0.0558 - precision: 0.8030 - recall: 0.7431 - val_accuracy: 0.6111 - val_loss: 0.0956 - val_precision: 0.6232 - val_recall: 0.5972 - learning_rate: 3.0000e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7641 - loss: 0.0564 - precision: 0.7895 - recall: 0.7231\n",
      "Epoch 92: val_loss did not improve from 0.08854\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.7662 - loss: 0.0568 - precision: 0.7878 - recall: 0.7240 - val_accuracy: 0.5833 - val_loss: 0.1151 - val_precision: 0.5942 - val_recall: 0.5694 - learning_rate: 3.0000e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7635 - loss: 0.0552 - precision: 0.7875 - recall: 0.7156\n",
      "Epoch 93: val_loss improved from 0.08854 to 0.08376, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 93: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.7656 - loss: 0.0557 - precision: 0.7903 - recall: 0.7176 - val_accuracy: 0.5556 - val_loss: 0.0838 - val_precision: 0.5652 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7469 - loss: 0.0586 - precision: 0.7619 - recall: 0.7035\n",
      "Epoch 94: val_loss improved from 0.08376 to 0.08106, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 94: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.7633 - loss: 0.0561 - precision: 0.7801 - recall: 0.7205 - val_accuracy: 0.5556 - val_loss: 0.0811 - val_precision: 0.5882 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7709 - loss: 0.0541 - precision: 0.7943 - recall: 0.7245\n",
      "Epoch 95: val_loss improved from 0.08106 to 0.07653, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 95: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 97ms/step - accuracy: 0.7726 - loss: 0.0547 - precision: 0.7924 - recall: 0.7269 - val_accuracy: 0.5694 - val_loss: 0.0765 - val_precision: 0.5797 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.7823 - loss: 0.0532 - precision: 0.8118 - recall: 0.7394\n",
      "Epoch 96: val_loss improved from 0.07653 to 0.07166, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 96: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 140ms/step - accuracy: 0.7784 - loss: 0.0545 - precision: 0.8036 - recall: 0.7315 - val_accuracy: 0.5833 - val_loss: 0.0717 - val_precision: 0.5833 - val_recall: 0.5833 - learning_rate: 3.0000e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7997 - loss: 0.0537 - precision: 0.8179 - recall: 0.7592\n",
      "Epoch 97: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 67ms/step - accuracy: 0.7946 - loss: 0.0519 - precision: 0.8140 - recall: 0.7494 - val_accuracy: 0.5833 - val_loss: 0.0807 - val_precision: 0.5857 - val_recall: 0.5694 - learning_rate: 3.0000e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7956 - loss: 0.0553 - precision: 0.8180 - recall: 0.7456\n",
      "Epoch 98: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.7917 - loss: 0.0529 - precision: 0.8179 - recall: 0.7407 - val_accuracy: 0.6111 - val_loss: 0.0856 - val_precision: 0.6143 - val_recall: 0.5972 - learning_rate: 3.0000e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8018 - loss: 0.0510 - precision: 0.8145 - recall: 0.7484\n",
      "Epoch 99: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.7888 - loss: 0.0515 - precision: 0.8033 - recall: 0.7396 - val_accuracy: 0.5417 - val_loss: 0.0780 - val_precision: 0.5493 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7910 - loss: 0.0531 - precision: 0.8083 - recall: 0.7547\n",
      "Epoch 100: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.7870 - loss: 0.0519 - precision: 0.8025 - recall: 0.7500 - val_accuracy: 0.5556 - val_loss: 0.0818 - val_precision: 0.5634 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7884 - loss: 0.0503 - precision: 0.8104 - recall: 0.7477\n",
      "Epoch 101: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.7899 - loss: 0.0507 - precision: 0.8109 - recall: 0.7471 - val_accuracy: 0.6250 - val_loss: 0.0738 - val_precision: 0.6197 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.8109 - loss: 0.0486 - precision: 0.8239 - recall: 0.7750\n",
      "Epoch 102: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.7980 - loss: 0.0480 - precision: 0.8135 - recall: 0.7598 - val_accuracy: 0.6250 - val_loss: 0.0884 - val_precision: 0.6286 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8104 - loss: 0.0511 - precision: 0.8240 - recall: 0.7629\n",
      "Epoch 103: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 78ms/step - accuracy: 0.7980 - loss: 0.0498 - precision: 0.8109 - recall: 0.7569 - val_accuracy: 0.5278 - val_loss: 0.0835 - val_precision: 0.5429 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.7941 - loss: 0.0488 - precision: 0.8040 - recall: 0.7422\n",
      "Epoch 104: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 105ms/step - accuracy: 0.7928 - loss: 0.0490 - precision: 0.8052 - recall: 0.7488 - val_accuracy: 0.5556 - val_loss: 0.0994 - val_precision: 0.5571 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7822 - loss: 0.0500 - precision: 0.8017 - recall: 0.7427\n",
      "Epoch 105: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.7847 - loss: 0.0507 - precision: 0.8039 - recall: 0.7471 - val_accuracy: 0.5417 - val_loss: 0.0903 - val_precision: 0.5588 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.8015 - loss: 0.0459 - precision: 0.8210 - recall: 0.7672\n",
      "Epoch 106: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.7928 - loss: 0.0464 - precision: 0.8142 - recall: 0.7558 - val_accuracy: 0.6250 - val_loss: 0.0828 - val_precision: 0.6250 - val_recall: 0.6250 - learning_rate: 3.0000e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7923 - loss: 0.0472 - precision: 0.8072 - recall: 0.7494\n",
      "Epoch 107: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.7894 - loss: 0.0478 - precision: 0.8052 - recall: 0.7465 - val_accuracy: 0.6111 - val_loss: 0.0743 - val_precision: 0.6377 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.7910 - loss: 0.0464 - precision: 0.8097 - recall: 0.7610\n",
      "Epoch 108: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\n",
      "Epoch 108: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.7940 - loss: 0.0460 - precision: 0.8134 - recall: 0.7645 - val_accuracy: 0.6389 - val_loss: 0.0754 - val_precision: 0.6571 - val_recall: 0.6389 - learning_rate: 3.0000e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.7764 - loss: 0.0462 - precision: 0.8014 - recall: 0.7551\n",
      "Epoch 109: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.7928 - loss: 0.0452 - precision: 0.8154 - recall: 0.7645 - val_accuracy: 0.6111 - val_loss: 0.0727 - val_precision: 0.6111 - val_recall: 0.6111 - learning_rate: 1.5000e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.7916 - loss: 0.0482 - precision: 0.8097 - recall: 0.7563\n",
      "Epoch 110: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.7824 - loss: 0.0471 - precision: 0.8006 - recall: 0.7506 - val_accuracy: 0.5972 - val_loss: 0.0839 - val_precision: 0.5972 - val_recall: 0.5972 - learning_rate: 1.5000e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7772 - loss: 0.0471 - precision: 0.7963 - recall: 0.7444\n",
      "Epoch 111: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.7818 - loss: 0.0466 - precision: 0.7994 - recall: 0.7402 - val_accuracy: 0.6250 - val_loss: 0.0883 - val_precision: 0.6250 - val_recall: 0.6250 - learning_rate: 1.5000e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7806 - loss: 0.0433 - precision: 0.7942 - recall: 0.7536\n",
      "Epoch 112: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.7905 - loss: 0.0441 - precision: 0.8028 - recall: 0.7587 - val_accuracy: 0.6111 - val_loss: 0.0877 - val_precision: 0.6143 - val_recall: 0.5972 - learning_rate: 1.5000e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7892 - loss: 0.0451 - precision: 0.8106 - recall: 0.7633\n",
      "Epoch 113: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.7899 - loss: 0.0451 - precision: 0.8098 - recall: 0.7616 - val_accuracy: 0.6250 - val_loss: 0.0860 - val_precision: 0.6429 - val_recall: 0.6250 - learning_rate: 1.5000e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7924 - loss: 0.0452 - precision: 0.7974 - recall: 0.7612\n",
      "Epoch 114: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.7911 - loss: 0.0439 - precision: 0.8010 - recall: 0.7569 - val_accuracy: 0.6111 - val_loss: 0.0727 - val_precision: 0.6197 - val_recall: 0.6111 - learning_rate: 1.5000e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.8068 - loss: 0.0434 - precision: 0.8226 - recall: 0.7689\n",
      "Epoch 115: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.8003 - loss: 0.0437 - precision: 0.8205 - recall: 0.7645 - val_accuracy: 0.5417 - val_loss: 0.0862 - val_precision: 0.5417 - val_recall: 0.5417 - learning_rate: 1.5000e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.8158 - loss: 0.0436 - precision: 0.8271 - recall: 0.7745\n",
      "Epoch 116: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.8067 - loss: 0.0440 - precision: 0.8209 - recall: 0.7720 - val_accuracy: 0.5694 - val_loss: 0.0859 - val_precision: 0.5882 - val_recall: 0.5556 - learning_rate: 1.5000e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8052 - loss: 0.0451 - precision: 0.8136 - recall: 0.7662\n",
      "Epoch 117: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.7899 - loss: 0.0465 - precision: 0.8059 - recall: 0.7546 - val_accuracy: 0.5694 - val_loss: 0.0781 - val_precision: 0.5857 - val_recall: 0.5694 - learning_rate: 1.5000e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8097 - loss: 0.0422 - precision: 0.8209 - recall: 0.7781\n",
      "Epoch 118: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.7986 - loss: 0.0431 - precision: 0.8133 - recall: 0.7662 - val_accuracy: 0.6250 - val_loss: 0.0720 - val_precision: 0.6250 - val_recall: 0.6250 - learning_rate: 1.5000e-04\n",
      "Epoch 119/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.7938 - loss: 0.0432 - precision: 0.8096 - recall: 0.7661\n",
      "Epoch 119: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.7986 - loss: 0.0427 - precision: 0.8150 - recall: 0.7697 - val_accuracy: 0.5694 - val_loss: 0.0782 - val_precision: 0.5714 - val_recall: 0.5556 - learning_rate: 1.5000e-04\n",
      "Epoch 120/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8050 - loss: 0.0418 - precision: 0.8200 - recall: 0.7777\n",
      "Epoch 120: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\n",
      "Epoch 120: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.8102 - loss: 0.0416 - precision: 0.8246 - recall: 0.7807 - val_accuracy: 0.5972 - val_loss: 0.0808 - val_precision: 0.5797 - val_recall: 0.5556 - learning_rate: 1.5000e-04\n",
      "Epoch 121/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8122 - loss: 0.0425 - precision: 0.8291 - recall: 0.7809\n",
      "Epoch 121: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8027 - loss: 0.0421 - precision: 0.8229 - recall: 0.7691 - val_accuracy: 0.6111 - val_loss: 0.0781 - val_precision: 0.6286 - val_recall: 0.6111 - learning_rate: 7.5000e-05\n",
      "Epoch 122/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.8127 - loss: 0.0432 - precision: 0.8286 - recall: 0.7768\n",
      "Epoch 122: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 80ms/step - accuracy: 0.8096 - loss: 0.0444 - precision: 0.8257 - recall: 0.7760 - val_accuracy: 0.6111 - val_loss: 0.0808 - val_precision: 0.6000 - val_recall: 0.5833 - learning_rate: 7.5000e-05\n",
      "Epoch 123/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8035 - loss: 0.0445 - precision: 0.8150 - recall: 0.7725\n",
      "Epoch 123: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8015 - loss: 0.0437 - precision: 0.8186 - recall: 0.7731 - val_accuracy: 0.5833 - val_loss: 0.0802 - val_precision: 0.5857 - val_recall: 0.5694 - learning_rate: 7.5000e-05\n",
      "Epoch 124/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.7824 - loss: 0.0445 - precision: 0.7941 - recall: 0.7485\n",
      "Epoch 124: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.7917 - loss: 0.0432 - precision: 0.8053 - recall: 0.7564 - val_accuracy: 0.6111 - val_loss: 0.0849 - val_precision: 0.6197 - val_recall: 0.6111 - learning_rate: 7.5000e-05\n",
      "Epoch 125/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8260 - loss: 0.0392 - precision: 0.8351 - recall: 0.7896\n",
      "Epoch 125: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 84ms/step - accuracy: 0.8160 - loss: 0.0405 - precision: 0.8283 - recall: 0.7847 - val_accuracy: 0.5556 - val_loss: 0.0873 - val_precision: 0.5634 - val_recall: 0.5556 - learning_rate: 7.5000e-05\n",
      "Epoch 126/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8008 - loss: 0.0407 - precision: 0.8155 - recall: 0.7682\n",
      "Epoch 126: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.8090 - loss: 0.0413 - precision: 0.8240 - recall: 0.7749 - val_accuracy: 0.5556 - val_loss: 0.0833 - val_precision: 0.5588 - val_recall: 0.5278 - learning_rate: 7.5000e-05\n",
      "Epoch 127/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7965 - loss: 0.0443 - precision: 0.8082 - recall: 0.7741\n",
      "Epoch 127: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.8079 - loss: 0.0441 - precision: 0.8175 - recall: 0.7749 - val_accuracy: 0.5694 - val_loss: 0.0830 - val_precision: 0.5694 - val_recall: 0.5694 - learning_rate: 7.5000e-05\n",
      "Epoch 128/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8251 - loss: 0.0399 - precision: 0.8381 - recall: 0.8004\n",
      "Epoch 128: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.8084 - loss: 0.0407 - precision: 0.8224 - recall: 0.7853 - val_accuracy: 0.5833 - val_loss: 0.0805 - val_precision: 0.5775 - val_recall: 0.5694 - learning_rate: 7.5000e-05\n",
      "Epoch 129/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8178 - loss: 0.0429 - precision: 0.8319 - recall: 0.7819\n",
      "Epoch 129: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 94ms/step - accuracy: 0.7980 - loss: 0.0431 - precision: 0.8149 - recall: 0.7668 - val_accuracy: 0.5556 - val_loss: 0.0799 - val_precision: 0.5634 - val_recall: 0.5556 - learning_rate: 7.5000e-05\n",
      "Epoch 130/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8136 - loss: 0.0434 - precision: 0.8298 - recall: 0.7832\n",
      "Epoch 130: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 121ms/step - accuracy: 0.8056 - loss: 0.0418 - precision: 0.8206 - recall: 0.7755 - val_accuracy: 0.5694 - val_loss: 0.0897 - val_precision: 0.5942 - val_recall: 0.5694 - learning_rate: 7.5000e-05\n",
      "Epoch 131/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8052 - loss: 0.0420 - precision: 0.8161 - recall: 0.7762\n",
      "Epoch 131: val_loss did not improve from 0.07166\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 52ms/step - accuracy: 0.8102 - loss: 0.0410 - precision: 0.8245 - recall: 0.7801 - val_accuracy: 0.5556 - val_loss: 0.0862 - val_precision: 0.5634 - val_recall: 0.5556 - learning_rate: 7.5000e-05\n",
      "Epoch 131: early stopping\n",
      "Restoring model weights from the end of the best epoch: 96.\n",
      "\n",
      "âœ“ GRU model training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train GRU model\n",
    "print(\"\\nğŸš€ Training GRU model...\")\n",
    "\n",
    "gru_callbacks = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=35,  # Increased patience\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=12,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath='models/gru_best.weights.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_gru = gru_model.fit(\n",
    "    X_gru_train_aug, y_gru_train_aug,\n",
    "    validation_data=(X_gru_val_scaled, y_gru_val_onehot),\n",
    "    epochs=300,  # Increased from 150 to 300\n",
    "    batch_size=32,\n",
    "    class_weight=gru_class_weight_dict,\n",
    "    callbacks=gru_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ GRU model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9563a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Evaluating GRU model...\n",
      "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 246ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step\n",
      "\n",
      "================================================================================\n",
      "GRU MODEL RESULTS\n",
      "================================================================================\n",
      "\n",
      "Train Set:\n",
      "  Accuracy:  0.8727\n",
      "  Precision: 0.8784\n",
      "  Recall:    0.8727\n",
      "  F1-Score:  0.8696\n",
      "\n",
      "Validation Set:\n",
      "  Accuracy:  0.5833\n",
      "  Precision: 0.7090\n",
      "  Recall:    0.5833\n",
      "  F1-Score:  0.5869\n",
      "\n",
      "Test Set:\n",
      "  Accuracy:  0.5556\n",
      "  Precision: 0.6956\n",
      "  Recall:    0.5556\n",
      "  F1-Score:  0.5446\n",
      "\n",
      "\n",
      "Test Set Confusion Matrix:\n",
      "[[ 6 18  0]\n",
      " [ 3 21  0]\n",
      " [ 0 11 13]]\n",
      "\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       0.67      0.25      0.36        24\n",
      "      Medium       0.42      0.88      0.57        24\n",
      "        High       1.00      0.54      0.70        24\n",
      "\n",
      "    accuracy                           0.56        72\n",
      "   macro avg       0.70      0.56      0.54        72\n",
      "weighted avg       0.70      0.56      0.54        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate GRU model\n",
    "print(\"\\nğŸ“Š Evaluating GRU model...\")\n",
    "\n",
    "y_gru_pred_train_probs = gru_model.predict(X_gru_train_scaled)\n",
    "y_gru_pred_val_probs = gru_model.predict(X_gru_val_scaled)\n",
    "y_gru_pred_test_probs = gru_model.predict(X_gru_test_scaled)\n",
    "\n",
    "y_gru_pred_train = np.argmax(y_gru_pred_train_probs, axis=1)\n",
    "y_gru_pred_val = np.argmax(y_gru_pred_val_probs, axis=1)\n",
    "y_gru_pred_test = np.argmax(y_gru_pred_test_probs, axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GRU MODEL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for split_name, y_true, y_pred in [\n",
    "    ('Train', y_gru_train_cat, y_gru_pred_train),\n",
    "    ('Validation', y_gru_val_cat, y_gru_pred_val),\n",
    "    ('Test', y_gru_test_cat, y_gru_pred_test)\n",
    "]:\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{split_name} Set:\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(\"\\n\\nTest Set Confusion Matrix:\")\n",
    "print(confusion_matrix(y_gru_test_cat, y_gru_pred_test))\n",
    "\n",
    "print(\"\\n\\nTest Set Classification Report:\")\n",
    "print(classification_report(y_gru_test_cat, y_gru_pred_test,\n",
    "                          target_names=['Low', 'Medium', 'High']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62010648",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Hybrid CNN-GRU Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438dcdf",
   "metadata": {},
   "source": [
    "### What is Hybrid CNN-GRU?\n",
    "\n",
    "Combines the strengths of both architectures:\n",
    "\n",
    "**CNN Branch (Temporal):**\n",
    "- Extracts local patterns from monthly sequences\n",
    "- Captures seasonal signatures, growth patterns\n",
    "\n",
    "**GRU Branch (Sequential):**\n",
    "- Models temporal dependencies from CNN features\n",
    "- Captures how patterns evolve across growing season\n",
    "\n",
    "**Static Branch:**\n",
    "- Processes soil properties and lag features\n",
    "- Non-temporal but crucial predictors\n",
    "\n",
    "**Fusion:**\n",
    "- Concatenates temporal and static representations\n",
    "- Dense layers learn optimal combination\n",
    "- Most powerful of the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2965e281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PART 3: HYBRID CNN-GRU MODEL\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Loading Hybrid data...\n",
      "  Temporal features: 17\n",
      "  Static features: 15\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART 3: HYBRID CNN-GRU MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load Hybrid data\n",
    "print(\"\\nğŸ“Š Loading Hybrid data...\")\n",
    "hybrid_train = pd.read_csv(splits_path / 'hybrid' / 'train.csv')\n",
    "hybrid_val = pd.read_csv(splits_path / 'hybrid' / 'val.csv')\n",
    "hybrid_test = pd.read_csv(splits_path / 'hybrid' / 'test.csv')\n",
    "\n",
    "# Remove missing yields\n",
    "hybrid_train = hybrid_train.dropna(subset=[target_col])\n",
    "hybrid_val = hybrid_val.dropna(subset=[target_col])\n",
    "hybrid_test = hybrid_test.dropna(subset=[target_col])\n",
    "\n",
    "# Encode categorical\n",
    "hybrid_train['Crop_encoded'] = crop_encoder.transform(hybrid_train['Crop'])\n",
    "hybrid_train['Region_encoded'] = region_encoder.transform(hybrid_train['Region'])\n",
    "hybrid_val['Crop_encoded'] = crop_encoder.transform(hybrid_val['Crop'])\n",
    "hybrid_val['Region_encoded'] = region_encoder.transform(hybrid_val['Region'])\n",
    "hybrid_test['Crop_encoded'] = crop_encoder.transform(hybrid_test['Crop'])\n",
    "hybrid_test['Region_encoded'] = region_encoder.transform(hybrid_test['Region'])\n",
    "\n",
    "# Add encodings to static features\n",
    "hybrid_static_cols_full = hybrid_static_cols + ['Crop_encoded', 'Region_encoded']\n",
    "\n",
    "print(f\"  Temporal features: {len(hybrid_temporal_cols)}\")\n",
    "print(f\"  Static features: {len(hybrid_static_cols_full)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed942a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Creating Hybrid sequences...\n",
      "\n",
      "  Train temporal: (432, 12, 17)\n",
      "  Train static:   (432, 15)\n",
      "  Val temporal:   (72, 12, 17)\n",
      "  Test temporal:  (72, 12, 17)\n"
     ]
    }
   ],
   "source": [
    "# Prepare Hybrid sequences\n",
    "print(\"\\nğŸ“Š Creating Hybrid sequences...\")\n",
    "\n",
    "def create_hybrid_sequences(df, temporal_cols, static_cols, target_col, sequence_length=12):\n",
    "    \"\"\"Create sequences with separate temporal and static components\"\"\"\n",
    "    temporal_sequences = []\n",
    "    static_features = []\n",
    "    targets = []\n",
    "    \n",
    "    for (region, crop, year), group in df.groupby(['Region', 'Crop', 'Year']):\n",
    "        group_sorted = group.sort_values('Month')\n",
    "        \n",
    "        if len(group_sorted) >= sequence_length:\n",
    "            # Temporal sequence (first 12 months)\n",
    "            temporal_seq = group_sorted.iloc[:sequence_length][temporal_cols].values\n",
    "            \n",
    "            # Static features (same across all months, take first)\n",
    "            static_feat = group_sorted.iloc[0][static_cols].values\n",
    "            \n",
    "            # Target (annual yield)\n",
    "            target = group_sorted[target_col].sum()\n",
    "            \n",
    "            temporal_sequences.append(temporal_seq)\n",
    "            static_features.append(static_feat)\n",
    "            targets.append(target)\n",
    "    \n",
    "    return np.array(temporal_sequences), np.array(static_features), np.array(targets)\n",
    "\n",
    "X_hybrid_temp_train, X_hybrid_stat_train, y_hybrid_train = create_hybrid_sequences(\n",
    "    hybrid_train, hybrid_temporal_cols, hybrid_static_cols_full, target_col, sequence_length\n",
    ")\n",
    "X_hybrid_temp_val, X_hybrid_stat_val, y_hybrid_val = create_hybrid_sequences(\n",
    "    hybrid_val, hybrid_temporal_cols, hybrid_static_cols_full, target_col, sequence_length\n",
    ")\n",
    "X_hybrid_temp_test, X_hybrid_stat_test, y_hybrid_test = create_hybrid_sequences(\n",
    "    hybrid_test, hybrid_temporal_cols, hybrid_static_cols_full, target_col, sequence_length\n",
    ")\n",
    "\n",
    "print(f\"\\n  Train temporal: {X_hybrid_temp_train.shape}\")\n",
    "print(f\"  Train static:   {X_hybrid_stat_train.shape}\")\n",
    "print(f\"  Val temporal:   {X_hybrid_temp_val.shape}\")\n",
    "print(f\"  Test temporal:  {X_hybrid_temp_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47d07bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Normalizing Hybrid features...\n",
      "  âœ“ Features normalized\n"
     ]
    }
   ],
   "source": [
    "# Normalize Hybrid features\n",
    "print(\"\\n  Normalizing Hybrid features...\")\n",
    "\n",
    "# Temporal features\n",
    "scaler_hybrid_temp = StandardScaler()\n",
    "X_hybrid_temp_train_reshaped = X_hybrid_temp_train.reshape(-1, X_hybrid_temp_train.shape[2])\n",
    "scaler_hybrid_temp.fit(X_hybrid_temp_train_reshaped)\n",
    "\n",
    "X_hybrid_temp_train_scaled = scaler_hybrid_temp.transform(\n",
    "    X_hybrid_temp_train.reshape(-1, X_hybrid_temp_train.shape[2])\n",
    ").reshape(X_hybrid_temp_train.shape)\n",
    "X_hybrid_temp_val_scaled = scaler_hybrid_temp.transform(\n",
    "    X_hybrid_temp_val.reshape(-1, X_hybrid_temp_val.shape[2])\n",
    ").reshape(X_hybrid_temp_val.shape)\n",
    "X_hybrid_temp_test_scaled = scaler_hybrid_temp.transform(\n",
    "    X_hybrid_temp_test.reshape(-1, X_hybrid_temp_test.shape[2])\n",
    ").reshape(X_hybrid_temp_test.shape)\n",
    "\n",
    "# Static features\n",
    "scaler_hybrid_stat = StandardScaler()\n",
    "X_hybrid_stat_train_scaled = scaler_hybrid_stat.fit_transform(X_hybrid_stat_train)\n",
    "X_hybrid_stat_val_scaled = scaler_hybrid_stat.transform(X_hybrid_stat_val)\n",
    "X_hybrid_stat_test_scaled = scaler_hybrid_stat.transform(X_hybrid_stat_test)\n",
    "\n",
    "print(\"  âœ“ Features normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "876de97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Categorizing yields for Hybrid...\n",
      "\n",
      "Class distribution (Hybrid Train):\n",
      "  Class 0: 144 samples (33.3%)\n",
      "  Class 1: 144 samples (33.3%)\n",
      "  Class 2: 144 samples (33.3%)\n"
     ]
    }
   ],
   "source": [
    "# Categorize yields for Hybrid\n",
    "print(\"\\nğŸ“Š Categorizing yields for Hybrid...\")\n",
    "\n",
    "y_hybrid_train_cat, hybrid_percentiles = categorize_yield_balanced(y_hybrid_train, method='percentile')\n",
    "y_hybrid_val_cat, _ = categorize_yield_balanced(y_hybrid_val, method='percentile')\n",
    "y_hybrid_test_cat, _ = categorize_yield_balanced(y_hybrid_test, method='percentile')\n",
    "\n",
    "print(f\"\\nClass distribution (Hybrid Train):\")\n",
    "unique, counts = np.unique(y_hybrid_train_cat, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"  Class {cls}: {count} samples ({count/len(y_hybrid_train_cat)*100:.1f}%)\")\n",
    "\n",
    "y_hybrid_train_onehot = to_categorical(y_hybrid_train_cat, num_classes=3)\n",
    "y_hybrid_val_onehot = to_categorical(y_hybrid_val_cat, num_classes=3)\n",
    "y_hybrid_test_onehot = to_categorical(y_hybrid_test_cat, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb434406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ APPLYING DATA AUGMENTATION (Hybrid)...\n",
      "  Augmented Hybrid training size: 1728 samples\n",
      "\n",
      "âš–ï¸  Hybrid Class weights:\n",
      "   Class 0: weight=1.000 (n=576 samples)\n",
      "   Class 1: weight=1.000 (n=576 samples)\n",
      "   Class 2: weight=1.000 (n=576 samples)\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation for Hybrid\n",
    "print(\"\\nğŸ”„ APPLYING DATA AUGMENTATION (Hybrid)...\")\n",
    "\n",
    "X_hybrid_temp_aug, X_hybrid_stat_aug, y_hybrid_train_aug = augment_hybrid_data(\n",
    "    X_hybrid_temp_train_scaled,\n",
    "    X_hybrid_stat_train_scaled,\n",
    "    y_hybrid_train_onehot,\n",
    "    num_augmented=3,  # Increased from 1 to 3\n",
    "    noise_level=0.02  # Reduced noise\n",
    ")\n",
    "\n",
    "print(f\"  Augmented Hybrid training size: {X_hybrid_temp_aug.shape[0]} samples\")\n",
    "\n",
    "# Shuffle\n",
    "indices = np.random.permutation(X_hybrid_temp_aug.shape[0])\n",
    "X_hybrid_temp_aug = X_hybrid_temp_aug[indices]\n",
    "X_hybrid_stat_aug = X_hybrid_stat_aug[indices]\n",
    "y_hybrid_train_aug = y_hybrid_train_aug[indices]\n",
    "\n",
    "# Class weights\n",
    "y_hybrid_train_labels = np.argmax(y_hybrid_train_aug, axis=1)\n",
    "hybrid_class_weights_array = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_hybrid_train_labels),\n",
    "    y=y_hybrid_train_labels\n",
    ")\n",
    "hybrid_class_weight_dict = dict(enumerate(hybrid_class_weights_array))\n",
    "\n",
    "print(f\"\\nâš–ï¸  Hybrid Class weights:\")\n",
    "for cls, weight in hybrid_class_weight_dict.items():\n",
    "    count = np.sum(y_hybrid_train_labels == cls)\n",
    "    print(f\"   Class {cls}: weight={weight:.3f} (n={count} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e919e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ temporal_input      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,328</span> â”‚ temporal_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_2     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_11          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ static_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_12          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,536</span> â”‚ static_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> â”‚ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> â”‚ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_15          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_13          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> â”‚ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_3     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">203,904</span> â”‚ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> â”‚ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_16          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_14          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_4     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> â”‚ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ bidirectional_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_17          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">160</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">20,608</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_18          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚ dropout_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_19          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚ dropout_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span> â”‚ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_20          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> â”‚ dropout_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ temporal_input      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m17\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚      \u001b[38;5;34m3,328\u001b[0m â”‚ temporal_input[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_2     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_11          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚          \u001b[38;5;34m0\u001b[0m â”‚ max_pooling1d_2[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚     \u001b[38;5;34m24,704\u001b[0m â”‚ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ static_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_12          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚      \u001b[38;5;34m1,536\u001b[0m â”‚ static_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚     \u001b[38;5;34m98,560\u001b[0m â”‚ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚        \u001b[38;5;34m384\u001b[0m â”‚ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_15          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_13          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m6,208\u001b[0m â”‚ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_3     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m192\u001b[0m)    â”‚    \u001b[38;5;34m203,904\u001b[0m â”‚ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚ (\u001b[38;5;33mBidirectional\u001b[0m)     â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m192\u001b[0m)    â”‚        \u001b[38;5;34m768\u001b[0m â”‚ bidirectional_3[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_16          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_14          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m192\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_4     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m99,072\u001b[0m â”‚ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚ (\u001b[38;5;33mBidirectional\u001b[0m)     â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m128\u001b[0m â”‚ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ bidirectional_4[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_17          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m160\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m20,608\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_18          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_11 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m8,256\u001b[0m â”‚ dropout_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_19          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_12 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚      \u001b[38;5;34m2,080\u001b[0m â”‚ dropout_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚        \u001b[38;5;34m128\u001b[0m â”‚ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_20          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_13 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â”‚         \u001b[38;5;34m99\u001b[0m â”‚ dropout_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">475,171</span> (1.81 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m475,171\u001b[0m (1.81 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">472,803</span> (1.80 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m472,803\u001b[0m (1.80 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,368</span> (9.25 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,368\u001b[0m (9.25 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build Hybrid CNN-GRU model with Attention\n",
    "def build_hybrid_cnn_gru_model(sequence_length, n_temporal_features, n_static_features, learning_rate=0.0003):\n",
    "    \"\"\"\n",
    "    Build Hybrid CNN-GRU model with dual inputs and attention.\n",
    "    \n",
    "    Temporal Branch:\n",
    "    - CNN extracts patterns from monthly sequences\n",
    "    - GRU models temporal dependencies\n",
    "    - Attention focuses on important time steps\n",
    "    \n",
    "    Static Branch:\n",
    "    - Dense layers for soil and lag features\n",
    "    \n",
    "    Fusion:\n",
    "    - Concatenate both branches\n",
    "    - Dense layers for final classification\n",
    "    - Enhanced regularization to prevent overfitting\n",
    "    \"\"\"\n",
    "    # Temporal input (CNN â†’ GRU)\n",
    "    temporal_input = layers.Input(shape=(sequence_length, n_temporal_features), name='temporal_input')\n",
    "    \n",
    "    # CNN layers for feature extraction\n",
    "    x = layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same',\n",
    "                     kernel_regularizer=regularizers.l2(0.002))(temporal_input)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    x = layers.Conv1D(filters=128, kernel_size=3, activation='relu', padding='same',\n",
    "                     kernel_regularizer=regularizers.l2(0.002))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    \n",
    "    x = layers.Conv1D(filters=256, kernel_size=3, activation='relu', padding='same',\n",
    "                     kernel_regularizer=regularizers.l2(0.002))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    # Bidirectional GRU layers for temporal modeling\n",
    "    x = layers.Bidirectional(layers.GRU(96, return_sequences=True,\n",
    "                                       kernel_regularizer=regularizers.l2(0.003),\n",
    "                                       recurrent_regularizer=regularizers.l2(0.003),\n",
    "                                       dropout=0.3,\n",
    "                                       recurrent_dropout=0.3))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.5)(x)\n",
    "    \n",
    "    x = layers.Bidirectional(layers.GRU(64, return_sequences=False,\n",
    "                                       kernel_regularizer=regularizers.l2(0.003),\n",
    "                                       recurrent_regularizer=regularizers.l2(0.003),\n",
    "                                       dropout=0.3,\n",
    "                                       recurrent_dropout=0.3))(x)\n",
    "    temporal_out = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Static input branch\n",
    "    static_input = layers.Input(shape=(n_static_features,), name='static_input')\n",
    "    y = layers.Dense(96, activation='relu', kernel_regularizer=regularizers.l2(0.003))(static_input)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Dropout(0.5)(y)\n",
    "    y = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.002))(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Dropout(0.4)(y)\n",
    "    y = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001))(y)\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    static_out = layers.Dropout(0.3)(y)\n",
    "    \n",
    "    # Fusion layer with attention-like mechanism\n",
    "    merged = layers.concatenate([temporal_out, static_out])\n",
    "    \n",
    "    z = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.002))(merged)\n",
    "    z = layers.BatchNormalization()(z)\n",
    "    z = layers.Dropout(0.5)(z)\n",
    "    \n",
    "    z = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.002))(z)\n",
    "    z = layers.BatchNormalization()(z)\n",
    "    z = layers.Dropout(0.4)(z)\n",
    "    \n",
    "    z = layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001))(z)\n",
    "    z = layers.BatchNormalization()(z)\n",
    "    z = layers.Dropout(0.3)(z)\n",
    "    \n",
    "    # Output\n",
    "    output = layers.Dense(3, activation='softmax')(z)\n",
    "    \n",
    "    model = models.Model(inputs=[temporal_input, static_input], outputs=output)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate, clipnorm=1.0)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=focal_loss(gamma=2.0, alpha=0.25),\n",
    "        metrics=['accuracy',\n",
    "                 tf.keras.metrics.Precision(name='precision'),\n",
    "                 tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "hybrid_model = build_hybrid_cnn_gru_model(\n",
    "    sequence_length=sequence_length,\n",
    "    n_temporal_features=X_hybrid_temp_aug.shape[2],\n",
    "    n_static_features=X_hybrid_stat_aug.shape[1],\n",
    "    learning_rate=0.0003\n",
    ")\n",
    "hybrid_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "083d407f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training Hybrid CNN-GRU model...\n",
      "Epoch 1/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.3355 - loss: 5.3031 - precision: 0.3394 - recall: 0.2851\n",
      "Epoch 1: val_loss improved from None to 4.84001, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 1: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 155ms/step - accuracy: 0.3455 - loss: 5.1993 - precision: 0.3424 - recall: 0.2841 - val_accuracy: 0.3333 - val_loss: 4.8400 - val_precision: 0.0000e+00 - val_recall: 0.0000e+00 - learning_rate: 3.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.3262 - loss: 4.9200 - precision: 0.3404 - recall: 0.2762\n",
      "Epoch 2: val_loss improved from 4.84001 to 4.52280, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 2: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.3466 - loss: 4.8220 - precision: 0.3535 - recall: 0.2870 - val_accuracy: 0.3472 - val_loss: 4.5228 - val_precision: 0.7500 - val_recall: 0.0833 - learning_rate: 3.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.4066 - loss: 4.5518 - precision: 0.4135 - recall: 0.3354\n",
      "Epoch 3: val_loss improved from 4.52280 to 4.22952, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 3: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.4005 - loss: 4.4782 - precision: 0.4074 - recall: 0.3270 - val_accuracy: 0.2917 - val_loss: 4.2295 - val_precision: 0.5312 - val_recall: 0.2361 - learning_rate: 3.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.4236 - loss: 4.2444 - precision: 0.4363 - recall: 0.3395\n",
      "Epoch 4: val_loss improved from 4.22952 to 3.97638, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 4: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.4219 - loss: 4.1773 - precision: 0.4403 - recall: 0.3455 - val_accuracy: 0.3472 - val_loss: 3.9764 - val_precision: 0.3774 - val_recall: 0.2778 - learning_rate: 3.0000e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.4709 - loss: 3.9791 - precision: 0.4987 - recall: 0.3787\n",
      "Epoch 5: val_loss improved from 3.97638 to 3.75286, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 5: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.4763 - loss: 3.9135 - precision: 0.5027 - recall: 0.3791 - val_accuracy: 0.3750 - val_loss: 3.7529 - val_precision: 0.3714 - val_recall: 0.3611 - learning_rate: 3.0000e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.4695 - loss: 3.7488 - precision: 0.4911 - recall: 0.3869\n",
      "Epoch 6: val_loss improved from 3.75286 to 3.54558, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 6: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.4873 - loss: 3.6871 - precision: 0.5041 - recall: 0.3958 - val_accuracy: 0.3889 - val_loss: 3.5456 - val_precision: 0.4000 - val_recall: 0.3889 - learning_rate: 3.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.5523 - loss: 3.5175 - precision: 0.5755 - recall: 0.4583\n",
      "Epoch 7: val_loss improved from 3.54558 to 3.36020, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 7: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.5405 - loss: 3.4695 - precision: 0.5707 - recall: 0.4531 - val_accuracy: 0.4583 - val_loss: 3.3602 - val_precision: 0.4559 - val_recall: 0.4306 - learning_rate: 3.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.5601 - loss: 3.3252 - precision: 0.5973 - recall: 0.4756\n",
      "Epoch 8: val_loss improved from 3.36020 to 3.17272, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 8: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.5637 - loss: 3.2849 - precision: 0.6041 - recall: 0.4786 - val_accuracy: 0.5556 - val_loss: 3.1727 - val_precision: 0.6034 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5391 - loss: 3.1573 - precision: 0.5838 - recall: 0.4664\n",
      "Epoch 9: val_loss improved from 3.17272 to 3.01991, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 9: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.5550 - loss: 3.1225 - precision: 0.5924 - recall: 0.4769 - val_accuracy: 0.5417 - val_loss: 3.0199 - val_precision: 0.5517 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.5997 - loss: 2.9976 - precision: 0.6339 - recall: 0.5120\n",
      "Epoch 10: val_loss improved from 3.01991 to 2.89385, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 10: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.5990 - loss: 2.9623 - precision: 0.6256 - recall: 0.5058 - val_accuracy: 0.5278 - val_loss: 2.8939 - val_precision: 0.5536 - val_recall: 0.4306 - learning_rate: 3.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.5939 - loss: 2.8661 - precision: 0.6250 - recall: 0.4998\n",
      "Epoch 11: val_loss improved from 2.89385 to 2.76314, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 11: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.5995 - loss: 2.8307 - precision: 0.6373 - recall: 0.5156 - val_accuracy: 0.6528 - val_loss: 2.7631 - val_precision: 0.6667 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.6288 - loss: 2.7234 - precision: 0.6673 - recall: 0.5334\n",
      "Epoch 12: val_loss improved from 2.76314 to 2.63491, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 12: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.6233 - loss: 2.6950 - precision: 0.6619 - recall: 0.5370 - val_accuracy: 0.6806 - val_loss: 2.6349 - val_precision: 0.6981 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.6238 - loss: 2.6048 - precision: 0.6564 - recall: 0.5498\n",
      "Epoch 13: val_loss improved from 2.63491 to 2.55031, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 13: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.6314 - loss: 2.5777 - precision: 0.6674 - recall: 0.5492 - val_accuracy: 0.6389 - val_loss: 2.5503 - val_precision: 0.6393 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6517 - loss: 2.4897 - precision: 0.6729 - recall: 0.5709\n",
      "Epoch 14: val_loss improved from 2.55031 to 2.45463, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 14: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.6424 - loss: 2.4665 - precision: 0.6671 - recall: 0.5637 - val_accuracy: 0.6250 - val_loss: 2.4546 - val_precision: 0.6462 - val_recall: 0.5833 - learning_rate: 3.0000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6185 - loss: 2.3842 - precision: 0.6545 - recall: 0.5587\n",
      "Epoch 15: val_loss improved from 2.45463 to 2.34413, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 15: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 53ms/step - accuracy: 0.6250 - loss: 2.3575 - precision: 0.6633 - recall: 0.5631 - val_accuracy: 0.5833 - val_loss: 2.3441 - val_precision: 0.6167 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.6754 - loss: 2.2698 - precision: 0.7147 - recall: 0.6017\n",
      "Epoch 16: val_loss improved from 2.34413 to 2.24446, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 16: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.6661 - loss: 2.2496 - precision: 0.7037 - recall: 0.5909 - val_accuracy: 0.6389 - val_loss: 2.2445 - val_precision: 0.6721 - val_recall: 0.5694 - learning_rate: 3.0000e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.6754 - loss: 2.1679 - precision: 0.6996 - recall: 0.6003\n",
      "Epoch 17: val_loss improved from 2.24446 to 2.15886, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 17: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - accuracy: 0.6678 - loss: 2.1460 - precision: 0.6958 - recall: 0.5984 - val_accuracy: 0.5694 - val_loss: 2.1589 - val_precision: 0.5625 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.6794 - loss: 2.0672 - precision: 0.7124 - recall: 0.6113\n",
      "Epoch 18: val_loss improved from 2.15886 to 2.07043, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 18: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.6701 - loss: 2.0495 - precision: 0.7015 - recall: 0.5984 - val_accuracy: 0.5694 - val_loss: 2.0704 - val_precision: 0.6230 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.6642 - loss: 1.9790 - precision: 0.6961 - recall: 0.5927\n",
      "Epoch 19: val_loss improved from 2.07043 to 1.98130, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 19: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 63ms/step - accuracy: 0.6568 - loss: 1.9596 - precision: 0.6875 - recall: 0.5932 - val_accuracy: 0.5694 - val_loss: 1.9813 - val_precision: 0.5821 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.6853 - loss: 1.8911 - precision: 0.7155 - recall: 0.6260\n",
      "Epoch 20: val_loss improved from 1.98130 to 1.89871, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 20: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.6950 - loss: 1.8691 - precision: 0.7223 - recall: 0.6262 - val_accuracy: 0.5556 - val_loss: 1.8987 - val_precision: 0.5692 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.6838 - loss: 1.8007 - precision: 0.7152 - recall: 0.6335\n",
      "Epoch 21: val_loss improved from 1.89871 to 1.81357, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 21: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 101ms/step - accuracy: 0.6875 - loss: 1.7827 - precision: 0.7144 - recall: 0.6209 - val_accuracy: 0.5694 - val_loss: 1.8136 - val_precision: 0.5821 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.7035 - loss: 1.7142 - precision: 0.7409 - recall: 0.6487\n",
      "Epoch 22: val_loss improved from 1.81357 to 1.77242, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 22: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 96ms/step - accuracy: 0.6991 - loss: 1.7002 - precision: 0.7303 - recall: 0.6424 - val_accuracy: 0.5139 - val_loss: 1.7724 - val_precision: 0.5000 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7315 - loss: 1.6364 - precision: 0.7586 - recall: 0.6660\n",
      "Epoch 23: val_loss improved from 1.77242 to 1.69406, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 23: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.7141 - loss: 1.6211 - precision: 0.7429 - recall: 0.6539 - val_accuracy: 0.4722 - val_loss: 1.6941 - val_precision: 0.4925 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.6995 - loss: 1.5691 - precision: 0.7295 - recall: 0.6293\n",
      "Epoch 24: val_loss improved from 1.69406 to 1.61011, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 24: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.6997 - loss: 1.5531 - precision: 0.7285 - recall: 0.6319 - val_accuracy: 0.5139 - val_loss: 1.6101 - val_precision: 0.5147 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6999 - loss: 1.4925 - precision: 0.7236 - recall: 0.6348\n",
      "Epoch 25: val_loss improved from 1.61011 to 1.54943, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 25: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 77ms/step - accuracy: 0.6973 - loss: 1.4768 - precision: 0.7214 - recall: 0.6354 - val_accuracy: 0.4861 - val_loss: 1.5494 - val_precision: 0.5000 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7055 - loss: 1.4242 - precision: 0.7284 - recall: 0.6443\n",
      "Epoch 26: val_loss improved from 1.54943 to 1.48814, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 26: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.7014 - loss: 1.4111 - precision: 0.7206 - recall: 0.6389 - val_accuracy: 0.5417 - val_loss: 1.4881 - val_precision: 0.5312 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7020 - loss: 1.3605 - precision: 0.7156 - recall: 0.6429\n",
      "Epoch 27: val_loss improved from 1.48814 to 1.42206, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 27: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.7008 - loss: 1.3444 - precision: 0.7209 - recall: 0.6383 - val_accuracy: 0.5139 - val_loss: 1.4221 - val_precision: 0.5312 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.7269 - loss: 1.2943 - precision: 0.7407 - recall: 0.6761\n",
      "Epoch 28: val_loss improved from 1.42206 to 1.35175, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 28: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.7240 - loss: 1.2799 - precision: 0.7389 - recall: 0.6667 - val_accuracy: 0.5139 - val_loss: 1.3518 - val_precision: 0.5077 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7399 - loss: 1.2280 - precision: 0.7489 - recall: 0.6841\n",
      "Epoch 29: val_loss improved from 1.35175 to 1.29291, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 29: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 0.7315 - loss: 1.2167 - precision: 0.7444 - recall: 0.6742 - val_accuracy: 0.5417 - val_loss: 1.2929 - val_precision: 0.5352 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7357 - loss: 1.1730 - precision: 0.7571 - recall: 0.6819\n",
      "Epoch 30: val_loss improved from 1.29291 to 1.23181, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 30: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.7373 - loss: 1.1608 - precision: 0.7538 - recall: 0.6823 - val_accuracy: 0.5278 - val_loss: 1.2318 - val_precision: 0.5217 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7166 - loss: 1.1147 - precision: 0.7440 - recall: 0.6664\n",
      "Epoch 31: val_loss improved from 1.23181 to 1.18287, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 31: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.7228 - loss: 1.1039 - precision: 0.7447 - recall: 0.6667 - val_accuracy: 0.5139 - val_loss: 1.1829 - val_precision: 0.5072 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.7312 - loss: 1.0613 - precision: 0.7536 - recall: 0.6701\n",
      "Epoch 32: val_loss improved from 1.18287 to 1.13779, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 32: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.7251 - loss: 1.0509 - precision: 0.7503 - recall: 0.6713 - val_accuracy: 0.5139 - val_loss: 1.1378 - val_precision: 0.5224 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.7347 - loss: 1.0070 - precision: 0.7554 - recall: 0.6767\n",
      "Epoch 33: val_loss improved from 1.13779 to 1.07990, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 33: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.7390 - loss: 0.9980 - precision: 0.7616 - recall: 0.6823 - val_accuracy: 0.5278 - val_loss: 1.0799 - val_precision: 0.5217 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7563 - loss: 0.9611 - precision: 0.7757 - recall: 0.7017\n",
      "Epoch 34: val_loss improved from 1.07990 to 1.03202, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 34: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.7477 - loss: 0.9510 - precision: 0.7704 - recall: 0.6950 - val_accuracy: 0.5000 - val_loss: 1.0320 - val_precision: 0.5070 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7539 - loss: 0.9116 - precision: 0.7672 - recall: 0.7014\n",
      "Epoch 35: val_loss improved from 1.03202 to 0.98120, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 35: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.7315 - loss: 0.9049 - precision: 0.7494 - recall: 0.6852 - val_accuracy: 0.5000 - val_loss: 0.9812 - val_precision: 0.5000 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7414 - loss: 0.8665 - precision: 0.7677 - recall: 0.7035\n",
      "Epoch 36: val_loss improved from 0.98120 to 0.92871, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 36: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.7355 - loss: 0.8600 - precision: 0.7604 - recall: 0.6887 - val_accuracy: 0.5000 - val_loss: 0.9287 - val_precision: 0.5070 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7741 - loss: 0.8231 - precision: 0.7863 - recall: 0.7150\n",
      "Epoch 37: val_loss improved from 0.92871 to 0.87879, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 37: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.7610 - loss: 0.8163 - precision: 0.7764 - recall: 0.7112 - val_accuracy: 0.5417 - val_loss: 0.8788 - val_precision: 0.5493 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7493 - loss: 0.7861 - precision: 0.7680 - recall: 0.6982\n",
      "Epoch 38: val_loss improved from 0.87879 to 0.84816, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 38: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 71ms/step - accuracy: 0.7477 - loss: 0.7778 - precision: 0.7704 - recall: 0.7049 - val_accuracy: 0.5139 - val_loss: 0.8482 - val_precision: 0.5294 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7732 - loss: 0.7419 - precision: 0.7887 - recall: 0.7302\n",
      "Epoch 39: val_loss improved from 0.84816 to 0.80906, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 39: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.7662 - loss: 0.7360 - precision: 0.7840 - recall: 0.7309 - val_accuracy: 0.5000 - val_loss: 0.8091 - val_precision: 0.5217 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.7617 - loss: 0.7068 - precision: 0.7756 - recall: 0.7224\n",
      "Epoch 40: val_loss improved from 0.80906 to 0.76523, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 40: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.7604 - loss: 0.7000 - precision: 0.7793 - recall: 0.7234 - val_accuracy: 0.5139 - val_loss: 0.7652 - val_precision: 0.5152 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7629 - loss: 0.6729 - precision: 0.7878 - recall: 0.7207\n",
      "Epoch 41: val_loss improved from 0.76523 to 0.74091, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 41: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.7755 - loss: 0.6654 - precision: 0.7915 - recall: 0.7315 - val_accuracy: 0.5000 - val_loss: 0.7409 - val_precision: 0.4930 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7624 - loss: 0.6374 - precision: 0.7831 - recall: 0.7392\n",
      "Epoch 42: val_loss improved from 0.74091 to 0.71296, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 42: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.7645 - loss: 0.6318 - precision: 0.7824 - recall: 0.7367 - val_accuracy: 0.5000 - val_loss: 0.7130 - val_precision: 0.5000 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.7900 - loss: 0.6047 - precision: 0.8085 - recall: 0.7432\n",
      "Epoch 43: val_loss improved from 0.71296 to 0.67739, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 43: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.7836 - loss: 0.6002 - precision: 0.8052 - recall: 0.7390 - val_accuracy: 0.5139 - val_loss: 0.6774 - val_precision: 0.5000 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.7859 - loss: 0.5738 - precision: 0.8113 - recall: 0.7481\n",
      "Epoch 44: val_loss improved from 0.67739 to 0.63649, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 44: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.7778 - loss: 0.5680 - precision: 0.7964 - recall: 0.7355 - val_accuracy: 0.5417 - val_loss: 0.6365 - val_precision: 0.5373 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7946 - loss: 0.5441 - precision: 0.8063 - recall: 0.7581\n",
      "Epoch 45: val_loss improved from 0.63649 to 0.60826, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 45: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 80ms/step - accuracy: 0.7801 - loss: 0.5393 - precision: 0.7954 - recall: 0.7448 - val_accuracy: 0.5278 - val_loss: 0.6083 - val_precision: 0.5147 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.7916 - loss: 0.5169 - precision: 0.8082 - recall: 0.7561\n",
      "Epoch 46: val_loss improved from 0.60826 to 0.58147, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 46: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 0.7853 - loss: 0.5122 - precision: 0.8004 - recall: 0.7494 - val_accuracy: 0.4444 - val_loss: 0.5815 - val_precision: 0.4462 - val_recall: 0.4028 - learning_rate: 3.0000e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8205 - loss: 0.4896 - precision: 0.8332 - recall: 0.7872\n",
      "Epoch 47: val_loss improved from 0.58147 to 0.56672, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 47: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 0.8073 - loss: 0.4851 - precision: 0.8178 - recall: 0.7766 - val_accuracy: 0.5139 - val_loss: 0.5667 - val_precision: 0.5072 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8047 - loss: 0.4656 - precision: 0.8163 - recall: 0.7679\n",
      "Epoch 48: val_loss improved from 0.56672 to 0.55035, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 48: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 89ms/step - accuracy: 0.7980 - loss: 0.4606 - precision: 0.8083 - recall: 0.7662 - val_accuracy: 0.4722 - val_loss: 0.5503 - val_precision: 0.4627 - val_recall: 0.4306 - learning_rate: 3.0000e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.8162 - loss: 0.4405 - precision: 0.8223 - recall: 0.7834\n",
      "Epoch 49: val_loss improved from 0.55035 to 0.53513, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 49: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.8073 - loss: 0.4368 - precision: 0.8158 - recall: 0.7789 - val_accuracy: 0.5278 - val_loss: 0.5351 - val_precision: 0.5143 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.7968 - loss: 0.4182 - precision: 0.8126 - recall: 0.7753\n",
      "Epoch 50: val_loss improved from 0.53513 to 0.51103, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 50: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.7870 - loss: 0.4151 - precision: 0.8050 - recall: 0.7622 - val_accuracy: 0.5278 - val_loss: 0.5110 - val_precision: 0.5362 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8025 - loss: 0.3957 - precision: 0.8199 - recall: 0.7802\n",
      "Epoch 51: val_loss improved from 0.51103 to 0.47881, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 51: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8096 - loss: 0.3913 - precision: 0.8273 - recall: 0.7818 - val_accuracy: 0.5556 - val_loss: 0.4788 - val_precision: 0.5652 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8145 - loss: 0.3777 - precision: 0.8302 - recall: 0.7874\n",
      "Epoch 52: val_loss improved from 0.47881 to 0.45471, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 52: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.8125 - loss: 0.3737 - precision: 0.8299 - recall: 0.7847 - val_accuracy: 0.5278 - val_loss: 0.4547 - val_precision: 0.5211 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8103 - loss: 0.3584 - precision: 0.8273 - recall: 0.7837\n",
      "Epoch 53: val_loss did not improve from 0.45471\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.8090 - loss: 0.3550 - precision: 0.8266 - recall: 0.7807 - val_accuracy: 0.5000 - val_loss: 0.4620 - val_precision: 0.5075 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8338 - loss: 0.3365 - precision: 0.8506 - recall: 0.8116\n",
      "Epoch 54: val_loss improved from 0.45471 to 0.45003, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 54: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8125 - loss: 0.3366 - precision: 0.8309 - recall: 0.7876 - val_accuracy: 0.5000 - val_loss: 0.4500 - val_precision: 0.4930 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8387 - loss: 0.3215 - precision: 0.8495 - recall: 0.8101\n",
      "Epoch 55: val_loss improved from 0.45003 to 0.39976, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 55: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8194 - loss: 0.3193 - precision: 0.8343 - recall: 0.7957 - val_accuracy: 0.5556 - val_loss: 0.3998 - val_precision: 0.5588 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8314 - loss: 0.3062 - precision: 0.8411 - recall: 0.7952\n",
      "Epoch 56: val_loss did not improve from 0.39976\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8293 - loss: 0.3036 - precision: 0.8421 - recall: 0.7963 - val_accuracy: 0.4306 - val_loss: 0.4161 - val_precision: 0.4286 - val_recall: 0.4167 - learning_rate: 3.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.8341 - loss: 0.2884 - precision: 0.8471 - recall: 0.8113\n",
      "Epoch 57: val_loss improved from 0.39976 to 0.39044, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 57: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.8148 - loss: 0.2877 - precision: 0.8331 - recall: 0.7917 - val_accuracy: 0.4722 - val_loss: 0.3904 - val_precision: 0.4697 - val_recall: 0.4306 - learning_rate: 3.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8459 - loss: 0.2727 - precision: 0.8649 - recall: 0.8263\n",
      "Epoch 58: val_loss improved from 0.39044 to 0.36683, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 58: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.8362 - loss: 0.2719 - precision: 0.8584 - recall: 0.8137 - val_accuracy: 0.4306 - val_loss: 0.3668 - val_precision: 0.4412 - val_recall: 0.4167 - learning_rate: 3.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8466 - loss: 0.2599 - precision: 0.8624 - recall: 0.8276\n",
      "Epoch 59: val_loss did not improve from 0.36683\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8281 - loss: 0.2590 - precision: 0.8422 - recall: 0.8032 - val_accuracy: 0.5139 - val_loss: 0.3886 - val_precision: 0.5143 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8230 - loss: 0.2483 - precision: 0.8352 - recall: 0.8044\n",
      "Epoch 60: val_loss improved from 0.36683 to 0.35842, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 60: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8218 - loss: 0.2465 - precision: 0.8361 - recall: 0.8032 - val_accuracy: 0.5278 - val_loss: 0.3584 - val_precision: 0.5286 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8458 - loss: 0.2340 - precision: 0.8574 - recall: 0.8207\n",
      "Epoch 61: val_loss improved from 0.35842 to 0.32494, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 61: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8472 - loss: 0.2329 - precision: 0.8600 - recall: 0.8177 - val_accuracy: 0.5417 - val_loss: 0.3249 - val_precision: 0.5522 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8463 - loss: 0.2224 - precision: 0.8637 - recall: 0.8301\n",
      "Epoch 62: val_loss did not improve from 0.32494\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8356 - loss: 0.2221 - precision: 0.8526 - recall: 0.8166 - val_accuracy: 0.4306 - val_loss: 0.3527 - val_precision: 0.4225 - val_recall: 0.4167 - learning_rate: 3.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.8615 - loss: 0.2101 - precision: 0.8713 - recall: 0.8437\n",
      "Epoch 63: val_loss improved from 0.32494 to 0.31766, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 63: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8559 - loss: 0.2095 - precision: 0.8680 - recall: 0.8374 - val_accuracy: 0.5417 - val_loss: 0.3177 - val_precision: 0.5417 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8414 - loss: 0.2024 - precision: 0.8607 - recall: 0.8254\n",
      "Epoch 64: val_loss did not improve from 0.31766\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.8420 - loss: 0.2013 - precision: 0.8584 - recall: 0.8212 - val_accuracy: 0.5417 - val_loss: 0.3211 - val_precision: 0.5417 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8636 - loss: 0.1939 - precision: 0.8710 - recall: 0.8437\n",
      "Epoch 65: val_loss improved from 0.31766 to 0.31059, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 65: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8565 - loss: 0.1930 - precision: 0.8665 - recall: 0.8374 - val_accuracy: 0.5556 - val_loss: 0.3106 - val_precision: 0.5571 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8755 - loss: 0.1803 - precision: 0.8820 - recall: 0.8601\n",
      "Epoch 66: val_loss improved from 0.31059 to 0.29936, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 66: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8594 - loss: 0.1808 - precision: 0.8706 - recall: 0.8449 - val_accuracy: 0.5556 - val_loss: 0.2994 - val_precision: 0.5571 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8783 - loss: 0.1741 - precision: 0.8877 - recall: 0.8621\n",
      "Epoch 67: val_loss improved from 0.29936 to 0.27218, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 67: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.8692 - loss: 0.1743 - precision: 0.8774 - recall: 0.8490 - val_accuracy: 0.5417 - val_loss: 0.2722 - val_precision: 0.5571 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8510 - loss: 0.1683 - precision: 0.8685 - recall: 0.8326\n",
      "Epoch 68: val_loss did not improve from 0.27218\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8542 - loss: 0.1666 - precision: 0.8699 - recall: 0.8397 - val_accuracy: 0.4722 - val_loss: 0.3217 - val_precision: 0.4714 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8660 - loss: 0.1602 - precision: 0.8770 - recall: 0.8492\n",
      "Epoch 69: val_loss did not improve from 0.27218\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8646 - loss: 0.1581 - precision: 0.8740 - recall: 0.8466 - val_accuracy: 0.5000 - val_loss: 0.2747 - val_precision: 0.5000 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.8804 - loss: 0.1486 - precision: 0.8900 - recall: 0.8610\n",
      "Epoch 70: val_loss did not improve from 0.27218\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8686 - loss: 0.1492 - precision: 0.8806 - recall: 0.8495 - val_accuracy: 0.5278 - val_loss: 0.2814 - val_precision: 0.5278 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8850 - loss: 0.1419 - precision: 0.8928 - recall: 0.8708\n",
      "Epoch 71: val_loss did not improve from 0.27218\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.8698 - loss: 0.1437 - precision: 0.8810 - recall: 0.8524 - val_accuracy: 0.5000 - val_loss: 0.3121 - val_precision: 0.5070 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8598 - loss: 0.1385 - precision: 0.8673 - recall: 0.8437\n",
      "Epoch 72: val_loss did not improve from 0.27218\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8617 - loss: 0.1377 - precision: 0.8703 - recall: 0.8426 - val_accuracy: 0.4583 - val_loss: 0.2816 - val_precision: 0.4507 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8854 - loss: 0.1305 - precision: 0.8957 - recall: 0.8670\n",
      "Epoch 73: val_loss improved from 0.27218 to 0.26521, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 73: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.8721 - loss: 0.1311 - precision: 0.8836 - recall: 0.8524 - val_accuracy: 0.4861 - val_loss: 0.2652 - val_precision: 0.5072 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8796 - loss: 0.1238 - precision: 0.8920 - recall: 0.8647\n",
      "Epoch 74: val_loss did not improve from 0.26521\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.8785 - loss: 0.1244 - precision: 0.8884 - recall: 0.8663 - val_accuracy: 0.5000 - val_loss: 0.2695 - val_precision: 0.5000 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8681 - loss: 0.1212 - precision: 0.8804 - recall: 0.8553\n",
      "Epoch 75: val_loss did not improve from 0.26521\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.8669 - loss: 0.1231 - precision: 0.8754 - recall: 0.8542 - val_accuracy: 0.4722 - val_loss: 0.2654 - val_precision: 0.4714 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8778 - loss: 0.1165 - precision: 0.8849 - recall: 0.8630\n",
      "Epoch 76: val_loss improved from 0.26521 to 0.25292, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 76: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8762 - loss: 0.1174 - precision: 0.8864 - recall: 0.8628 - val_accuracy: 0.4861 - val_loss: 0.2529 - val_precision: 0.4861 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.8832 - loss: 0.1109 - precision: 0.8860 - recall: 0.8713\n",
      "Epoch 77: val_loss did not improve from 0.25292\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.8762 - loss: 0.1112 - precision: 0.8828 - recall: 0.8628 - val_accuracy: 0.5139 - val_loss: 0.2538 - val_precision: 0.5211 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.8989 - loss: 0.1054 - precision: 0.9059 - recall: 0.8844\n",
      "Epoch 78: val_loss did not improve from 0.25292\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.8900 - loss: 0.1067 - precision: 0.8986 - recall: 0.8773 - val_accuracy: 0.4306 - val_loss: 0.2592 - val_precision: 0.4493 - val_recall: 0.4306 - learning_rate: 3.0000e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8976 - loss: 0.1004 - precision: 0.9063 - recall: 0.8824\n",
      "Epoch 79: val_loss did not improve from 0.25292\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.8924 - loss: 0.1007 - precision: 0.9001 - recall: 0.8808 - val_accuracy: 0.4583 - val_loss: 0.2696 - val_precision: 0.4493 - val_recall: 0.4306 - learning_rate: 3.0000e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8962 - loss: 0.0973 - precision: 0.9014 - recall: 0.8793\n",
      "Epoch 80: val_loss improved from 0.25292 to 0.23031, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 80: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8889 - loss: 0.0978 - precision: 0.8972 - recall: 0.8738 - val_accuracy: 0.5139 - val_loss: 0.2303 - val_precision: 0.5139 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8996 - loss: 0.0933 - precision: 0.9036 - recall: 0.8812\n",
      "Epoch 81: val_loss did not improve from 0.23031\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.8837 - loss: 0.0947 - precision: 0.8894 - recall: 0.8657 - val_accuracy: 0.4028 - val_loss: 0.2900 - val_precision: 0.4085 - val_recall: 0.4028 - learning_rate: 3.0000e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9008 - loss: 0.0906 - precision: 0.9110 - recall: 0.8831\n",
      "Epoch 82: val_loss improved from 0.23031 to 0.22180, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 82: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.8918 - loss: 0.0912 - precision: 0.8996 - recall: 0.8762 - val_accuracy: 0.5417 - val_loss: 0.2218 - val_precision: 0.5417 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9144 - loss: 0.0854 - precision: 0.9217 - recall: 0.9021\n",
      "Epoch 83: val_loss did not improve from 0.22180\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9155 - loss: 0.0852 - precision: 0.9220 - recall: 0.9028 - val_accuracy: 0.4861 - val_loss: 0.2691 - val_precision: 0.4861 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9010 - loss: 0.0830 - precision: 0.9096 - recall: 0.8890\n",
      "Epoch 84: val_loss did not improve from 0.22180\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.8958 - loss: 0.0836 - precision: 0.9009 - recall: 0.8837 - val_accuracy: 0.4306 - val_loss: 0.2964 - val_precision: 0.4286 - val_recall: 0.4167 - learning_rate: 3.0000e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9085 - loss: 0.0798 - precision: 0.9176 - recall: 0.8952\n",
      "Epoch 85: val_loss improved from 0.22180 to 0.21371, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 85: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9062 - loss: 0.0806 - precision: 0.9149 - recall: 0.8958 - val_accuracy: 0.5833 - val_loss: 0.2137 - val_precision: 0.5833 - val_recall: 0.5833 - learning_rate: 3.0000e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9054 - loss: 0.0778 - precision: 0.9099 - recall: 0.8935\n",
      "Epoch 86: val_loss improved from 0.21371 to 0.20935, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 86: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.8941 - loss: 0.0789 - precision: 0.9001 - recall: 0.8860 - val_accuracy: 0.5139 - val_loss: 0.2094 - val_precision: 0.5072 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9029 - loss: 0.0759 - precision: 0.9097 - recall: 0.8935\n",
      "Epoch 87: val_loss did not improve from 0.20935\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9005 - loss: 0.0765 - precision: 0.9056 - recall: 0.8883 - val_accuracy: 0.5278 - val_loss: 0.2524 - val_precision: 0.5278 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9016 - loss: 0.0726 - precision: 0.9120 - recall: 0.8851\n",
      "Epoch 88: val_loss did not improve from 0.20935\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.8964 - loss: 0.0737 - precision: 0.9061 - recall: 0.8825 - val_accuracy: 0.5278 - val_loss: 0.2466 - val_precision: 0.5211 - val_recall: 0.5139 - learning_rate: 3.0000e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9166 - loss: 0.0702 - precision: 0.9240 - recall: 0.9062\n",
      "Epoch 89: val_loss did not improve from 0.20935\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.9138 - loss: 0.0704 - precision: 0.9203 - recall: 0.9016 - val_accuracy: 0.4722 - val_loss: 0.2702 - val_precision: 0.4722 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9241 - loss: 0.0671 - precision: 0.9288 - recall: 0.9165\n",
      "Epoch 90: val_loss did not improve from 0.20935\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9091 - loss: 0.0696 - precision: 0.9127 - recall: 0.9016 - val_accuracy: 0.4306 - val_loss: 0.3036 - val_precision: 0.4286 - val_recall: 0.4167 - learning_rate: 3.0000e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9174 - loss: 0.0658 - precision: 0.9267 - recall: 0.9056\n",
      "Epoch 91: val_loss did not improve from 0.20935\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9057 - loss: 0.0680 - precision: 0.9164 - recall: 0.8941 - val_accuracy: 0.4444 - val_loss: 0.2660 - val_precision: 0.4444 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9130 - loss: 0.0641 - precision: 0.9160 - recall: 0.9074\n",
      "Epoch 92: val_loss did not improve from 0.20935\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8976 - loss: 0.0661 - precision: 0.9037 - recall: 0.8906 - val_accuracy: 0.4306 - val_loss: 0.2699 - val_precision: 0.4306 - val_recall: 0.4306 - learning_rate: 3.0000e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9173 - loss: 0.0626 - precision: 0.9276 - recall: 0.9080\n",
      "Epoch 93: val_loss improved from 0.20935 to 0.18125, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 93: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.9039 - loss: 0.0645 - precision: 0.9121 - recall: 0.8953 - val_accuracy: 0.5556 - val_loss: 0.1813 - val_precision: 0.5571 - val_recall: 0.5417 - learning_rate: 3.0000e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9120 - loss: 0.0611 - precision: 0.9207 - recall: 0.9006\n",
      "Epoch 94: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9080 - loss: 0.0630 - precision: 0.9160 - recall: 0.8964 - val_accuracy: 0.4167 - val_loss: 0.2887 - val_precision: 0.4167 - val_recall: 0.4167 - learning_rate: 3.0000e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9188 - loss: 0.0578 - precision: 0.9265 - recall: 0.9121\n",
      "Epoch 95: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9132 - loss: 0.0597 - precision: 0.9200 - recall: 0.9045 - val_accuracy: 0.4028 - val_loss: 0.3753 - val_precision: 0.4085 - val_recall: 0.4028 - learning_rate: 3.0000e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9346 - loss: 0.0553 - precision: 0.9428 - recall: 0.9221\n",
      "Epoch 96: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9219 - loss: 0.0563 - precision: 0.9298 - recall: 0.9120 - val_accuracy: 0.4167 - val_loss: 0.2655 - val_precision: 0.4167 - val_recall: 0.4167 - learning_rate: 3.0000e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9202 - loss: 0.0552 - precision: 0.9231 - recall: 0.9124\n",
      "Epoch 97: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 78ms/step - accuracy: 0.9161 - loss: 0.0573 - precision: 0.9187 - recall: 0.9086 - val_accuracy: 0.4861 - val_loss: 0.2441 - val_precision: 0.4861 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9181 - loss: 0.0564 - precision: 0.9220 - recall: 0.9081\n",
      "Epoch 98: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.9080 - loss: 0.0576 - precision: 0.9123 - recall: 0.8970 - val_accuracy: 0.4722 - val_loss: 0.2610 - val_precision: 0.4857 - val_recall: 0.4722 - learning_rate: 3.0000e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9152 - loss: 0.0540 - precision: 0.9253 - recall: 0.9091\n",
      "Epoch 99: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.9178 - loss: 0.0541 - precision: 0.9236 - recall: 0.9091 - val_accuracy: 0.4583 - val_loss: 0.2736 - val_precision: 0.4583 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9389 - loss: 0.0511 - precision: 0.9414 - recall: 0.9332\n",
      "Epoch 100: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9178 - loss: 0.0544 - precision: 0.9229 - recall: 0.9080 - val_accuracy: 0.4861 - val_loss: 0.2103 - val_precision: 0.4861 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9148 - loss: 0.0506 - precision: 0.9233 - recall: 0.9059\n",
      "Epoch 101: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.9115 - loss: 0.0521 - precision: 0.9170 - recall: 0.9010 - val_accuracy: 0.4583 - val_loss: 0.2688 - val_precision: 0.4583 - val_recall: 0.4583 - learning_rate: 3.0000e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.9387 - loss: 0.0491 - precision: 0.9423 - recall: 0.9296\n",
      "Epoch 102: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 93ms/step - accuracy: 0.9311 - loss: 0.0497 - precision: 0.9348 - recall: 0.9213 - val_accuracy: 0.4861 - val_loss: 0.2490 - val_precision: 0.4861 - val_recall: 0.4861 - learning_rate: 3.0000e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9225 - loss: 0.0476 - precision: 0.9281 - recall: 0.9138\n",
      "Epoch 103: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9161 - loss: 0.0493 - precision: 0.9207 - recall: 0.9074 - val_accuracy: 0.5417 - val_loss: 0.1901 - val_precision: 0.5507 - val_recall: 0.5278 - learning_rate: 3.0000e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9194 - loss: 0.0476 - precision: 0.9222 - recall: 0.9113\n",
      "Epoch 104: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9196 - loss: 0.0476 - precision: 0.9224 - recall: 0.9149 - val_accuracy: 0.4444 - val_loss: 0.2590 - val_precision: 0.4507 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9171 - loss: 0.0477 - precision: 0.9245 - recall: 0.9108\n",
      "Epoch 105: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\n",
      "Epoch 105: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9144 - loss: 0.0488 - precision: 0.9201 - recall: 0.9068 - val_accuracy: 0.4444 - val_loss: 0.2656 - val_precision: 0.4366 - val_recall: 0.4306 - learning_rate: 3.0000e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9208 - loss: 0.0459 - precision: 0.9249 - recall: 0.9164\n",
      "Epoch 106: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.9213 - loss: 0.0468 - precision: 0.9240 - recall: 0.9149 - val_accuracy: 0.4722 - val_loss: 0.2557 - val_precision: 0.4722 - val_recall: 0.4722 - learning_rate: 1.5000e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9395 - loss: 0.0441 - precision: 0.9451 - recall: 0.9308\n",
      "Epoch 107: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.9317 - loss: 0.0455 - precision: 0.9378 - recall: 0.9242 - val_accuracy: 0.5278 - val_loss: 0.2796 - val_precision: 0.5278 - val_recall: 0.5278 - learning_rate: 1.5000e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9418 - loss: 0.0423 - precision: 0.9457 - recall: 0.9365\n",
      "Epoch 108: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9323 - loss: 0.0433 - precision: 0.9397 - recall: 0.9282 - val_accuracy: 0.4583 - val_loss: 0.2764 - val_precision: 0.4583 - val_recall: 0.4583 - learning_rate: 1.5000e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9355 - loss: 0.0415 - precision: 0.9385 - recall: 0.9291\n",
      "Epoch 109: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.9387 - loss: 0.0420 - precision: 0.9419 - recall: 0.9288 - val_accuracy: 0.4583 - val_loss: 0.2754 - val_precision: 0.4507 - val_recall: 0.4444 - learning_rate: 1.5000e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9360 - loss: 0.0399 - precision: 0.9408 - recall: 0.9315\n",
      "Epoch 110: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 57ms/step - accuracy: 0.9317 - loss: 0.0411 - precision: 0.9397 - recall: 0.9282 - val_accuracy: 0.5000 - val_loss: 0.3036 - val_precision: 0.5000 - val_recall: 0.5000 - learning_rate: 1.5000e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9442 - loss: 0.0401 - precision: 0.9455 - recall: 0.9400\n",
      "Epoch 111: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.9387 - loss: 0.0406 - precision: 0.9422 - recall: 0.9346 - val_accuracy: 0.5139 - val_loss: 0.2526 - val_precision: 0.5211 - val_recall: 0.5139 - learning_rate: 1.5000e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9430 - loss: 0.0406 - precision: 0.9446 - recall: 0.9354\n",
      "Epoch 112: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.9346 - loss: 0.0414 - precision: 0.9384 - recall: 0.9253 - val_accuracy: 0.4722 - val_loss: 0.2994 - val_precision: 0.4722 - val_recall: 0.4722 - learning_rate: 1.5000e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.9484 - loss: 0.0376 - precision: 0.9514 - recall: 0.9420\n",
      "Epoch 113: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9468 - loss: 0.0386 - precision: 0.9492 - recall: 0.9410 - val_accuracy: 0.4722 - val_loss: 0.2479 - val_precision: 0.4789 - val_recall: 0.4722 - learning_rate: 1.5000e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9365 - loss: 0.0377 - precision: 0.9384 - recall: 0.9311\n",
      "Epoch 114: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.9334 - loss: 0.0393 - precision: 0.9369 - recall: 0.9277 - val_accuracy: 0.4722 - val_loss: 0.2774 - val_precision: 0.4648 - val_recall: 0.4583 - learning_rate: 1.5000e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9464 - loss: 0.0354 - precision: 0.9529 - recall: 0.9445\n",
      "Epoch 115: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 85ms/step - accuracy: 0.9416 - loss: 0.0369 - precision: 0.9457 - recall: 0.9381 - val_accuracy: 0.4444 - val_loss: 0.3253 - val_precision: 0.4444 - val_recall: 0.4444 - learning_rate: 1.5000e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9353 - loss: 0.0374 - precision: 0.9387 - recall: 0.9328\n",
      "Epoch 116: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.9358 - loss: 0.0378 - precision: 0.9382 - recall: 0.9311 - val_accuracy: 0.4722 - val_loss: 0.3004 - val_precision: 0.4722 - val_recall: 0.4722 - learning_rate: 1.5000e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9437 - loss: 0.0370 - precision: 0.9491 - recall: 0.9404\n",
      "Epoch 117: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\n",
      "Epoch 117: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9358 - loss: 0.0383 - precision: 0.9409 - recall: 0.9306 - val_accuracy: 0.4444 - val_loss: 0.3197 - val_precision: 0.4507 - val_recall: 0.4444 - learning_rate: 1.5000e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9471 - loss: 0.0350 - precision: 0.9506 - recall: 0.9447\n",
      "Epoch 118: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9468 - loss: 0.0351 - precision: 0.9488 - recall: 0.9439 - val_accuracy: 0.5278 - val_loss: 0.2644 - val_precision: 0.5217 - val_recall: 0.5000 - learning_rate: 7.5000e-05\n",
      "Epoch 119/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9442 - loss: 0.0355 - precision: 0.9471 - recall: 0.9402\n",
      "Epoch 119: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.9416 - loss: 0.0367 - precision: 0.9435 - recall: 0.9369 - val_accuracy: 0.5417 - val_loss: 0.2308 - val_precision: 0.5417 - val_recall: 0.5417 - learning_rate: 7.5000e-05\n",
      "Epoch 120/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9550 - loss: 0.0328 - precision: 0.9611 - recall: 0.9542\n",
      "Epoch 120: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 62ms/step - accuracy: 0.9508 - loss: 0.0343 - precision: 0.9552 - recall: 0.9497 - val_accuracy: 0.5278 - val_loss: 0.2945 - val_precision: 0.5278 - val_recall: 0.5278 - learning_rate: 7.5000e-05\n",
      "Epoch 121/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9420 - loss: 0.0352 - precision: 0.9511 - recall: 0.9392\n",
      "Epoch 121: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.9369 - loss: 0.0359 - precision: 0.9449 - recall: 0.9334 - val_accuracy: 0.5139 - val_loss: 0.2740 - val_precision: 0.5139 - val_recall: 0.5139 - learning_rate: 7.5000e-05\n",
      "Epoch 122/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9578 - loss: 0.0335 - precision: 0.9578 - recall: 0.9471\n",
      "Epoch 122: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.9514 - loss: 0.0346 - precision: 0.9522 - recall: 0.9456 - val_accuracy: 0.5000 - val_loss: 0.2807 - val_precision: 0.5000 - val_recall: 0.5000 - learning_rate: 7.5000e-05\n",
      "Epoch 123/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9460 - loss: 0.0353 - precision: 0.9476 - recall: 0.9404\n",
      "Epoch 123: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.9444 - loss: 0.0352 - precision: 0.9481 - recall: 0.9404 - val_accuracy: 0.5139 - val_loss: 0.2725 - val_precision: 0.5139 - val_recall: 0.5139 - learning_rate: 7.5000e-05\n",
      "Epoch 124/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9525 - loss: 0.0332 - precision: 0.9580 - recall: 0.9477\n",
      "Epoch 124: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9554 - loss: 0.0330 - precision: 0.9585 - recall: 0.9479 - val_accuracy: 0.4861 - val_loss: 0.3069 - val_precision: 0.4930 - val_recall: 0.4861 - learning_rate: 7.5000e-05\n",
      "Epoch 125/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9626 - loss: 0.0313 - precision: 0.9659 - recall: 0.9591\n",
      "Epoch 125: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.9554 - loss: 0.0323 - precision: 0.9603 - recall: 0.9520 - val_accuracy: 0.5139 - val_loss: 0.2671 - val_precision: 0.5211 - val_recall: 0.5139 - learning_rate: 7.5000e-05\n",
      "Epoch 126/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9478 - loss: 0.0326 - precision: 0.9518 - recall: 0.9423\n",
      "Epoch 126: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.9462 - loss: 0.0327 - precision: 0.9499 - recall: 0.9427 - val_accuracy: 0.5000 - val_loss: 0.2714 - val_precision: 0.5000 - val_recall: 0.5000 - learning_rate: 7.5000e-05\n",
      "Epoch 127/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9596 - loss: 0.0308 - precision: 0.9608 - recall: 0.9552\n",
      "Epoch 127: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.9543 - loss: 0.0320 - precision: 0.9557 - recall: 0.9497 - val_accuracy: 0.4583 - val_loss: 0.3061 - val_precision: 0.4583 - val_recall: 0.4583 - learning_rate: 7.5000e-05\n",
      "Epoch 128/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9511 - loss: 0.0305 - precision: 0.9528 - recall: 0.9491\n",
      "Epoch 128: val_loss did not improve from 0.18125\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.9520 - loss: 0.0311 - precision: 0.9545 - recall: 0.9462 - val_accuracy: 0.4861 - val_loss: 0.3085 - val_precision: 0.4861 - val_recall: 0.4861 - learning_rate: 7.5000e-05\n",
      "Epoch 128: early stopping\n",
      "Restoring model weights from the end of the best epoch: 93.\n",
      "\n",
      "âœ“ Hybrid model training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train Hybrid model\n",
    "print(\"\\nğŸš€ Training Hybrid CNN-GRU model...\")\n",
    "\n",
    "hybrid_callbacks = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=35,  # Increased patience\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=12,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath='models/hybrid_best.weights.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_hybrid = hybrid_model.fit(\n",
    "    [X_hybrid_temp_aug, X_hybrid_stat_aug],\n",
    "    y_hybrid_train_aug,\n",
    "    validation_data=([X_hybrid_temp_val_scaled, X_hybrid_stat_val_scaled], y_hybrid_val_onehot),\n",
    "    epochs=300,  # Increased from 150 to 300\n",
    "    batch_size=32,\n",
    "    class_weight=hybrid_class_weight_dict,\n",
    "    callbacks=hybrid_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Hybrid model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7081f994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Evaluating Hybrid model...\n",
      "\u001b[1m14/14\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 300ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\u001b[1m3/3\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 32ms/step\n",
      "\n",
      "================================================================================\n",
      "HYBRID CNN-GRU MODEL RESULTS\n",
      "================================================================================\n",
      "\n",
      "Train Set:\n",
      "  Accuracy:  0.9606\n",
      "  Precision: 0.9640\n",
      "  Recall:    0.9606\n",
      "  F1-Score:  0.9603\n",
      "\n",
      "Validation Set:\n",
      "  Accuracy:  0.5556\n",
      "  Precision: 0.8095\n",
      "  Recall:    0.5556\n",
      "  F1-Score:  0.5324\n",
      "\n",
      "Test Set:\n",
      "  Accuracy:  0.5139\n",
      "  Precision: 0.8023\n",
      "  Recall:    0.5139\n",
      "  F1-Score:  0.4629\n",
      "\n",
      "\n",
      "Test Set Confusion Matrix:\n",
      "[[ 3 21  0]\n",
      " [ 0 24  0]\n",
      " [ 0 14 10]]\n",
      "\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       1.00      0.12      0.22        24\n",
      "      Medium       0.41      1.00      0.58        24\n",
      "        High       1.00      0.42      0.59        24\n",
      "\n",
      "    accuracy                           0.51        72\n",
      "   macro avg       0.80      0.51      0.46        72\n",
      "weighted avg       0.80      0.51      0.46        72\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Hybrid model\n",
    "print(\"\\nğŸ“Š Evaluating Hybrid model...\")\n",
    "\n",
    "y_hybrid_pred_train_probs = hybrid_model.predict([X_hybrid_temp_train_scaled, X_hybrid_stat_train_scaled])\n",
    "y_hybrid_pred_val_probs = hybrid_model.predict([X_hybrid_temp_val_scaled, X_hybrid_stat_val_scaled])\n",
    "y_hybrid_pred_test_probs = hybrid_model.predict([X_hybrid_temp_test_scaled, X_hybrid_stat_test_scaled])\n",
    "\n",
    "y_hybrid_pred_train = np.argmax(y_hybrid_pred_train_probs, axis=1)\n",
    "y_hybrid_pred_val = np.argmax(y_hybrid_pred_val_probs, axis=1)\n",
    "y_hybrid_pred_test = np.argmax(y_hybrid_pred_test_probs, axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYBRID CNN-GRU MODEL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for split_name, y_true, y_pred in [\n",
    "    ('Train', y_hybrid_train_cat, y_hybrid_pred_train),\n",
    "    ('Validation', y_hybrid_val_cat, y_hybrid_pred_val),\n",
    "    ('Test', y_hybrid_test_cat, y_hybrid_pred_test)\n",
    "]:\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{split_name} Set:\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(\"\\n\\nTest Set Confusion Matrix:\")\n",
    "print(confusion_matrix(y_hybrid_test_cat, y_hybrid_pred_test))\n",
    "\n",
    "print(\"\\n\\nTest Set Classification Report:\")\n",
    "print(classification_report(y_hybrid_test_cat, y_hybrid_pred_test,\n",
    "                          target_names=['Low', 'Medium', 'High']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f545db9",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2ceb519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL MODEL COMPARISON (Test Set)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "         Model  Accuracy  Precision  Recall  F1-Score\n",
      "           CNN    0.5694     0.7734  0.5694    0.5236\n",
      "           GRU    0.5556     0.6956  0.5556    0.5446\n",
      "Hybrid CNN-GRU    0.5139     0.8023  0.5139    0.4629\n",
      "\n",
      "\n",
      "Best Model by Metric:\n",
      "  Accuracy: CNN (0.5694)\n",
      "  Precision: Hybrid CNN-GRU (0.8023)\n",
      "  Recall: CNN (0.5694)\n",
      "  F1-Score: GRU (0.5446)\n"
     ]
    }
   ],
   "source": [
    "# Compare all models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL MODEL COMPARISON (Test Set)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = {\n",
    "    'Model': ['CNN', 'GRU', 'Hybrid CNN-GRU'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_cnn_test_cat, y_cnn_pred_test),\n",
    "        accuracy_score(y_gru_test_cat, y_gru_pred_test),\n",
    "        accuracy_score(y_hybrid_test_cat, y_hybrid_pred_test)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_score(y_cnn_test_cat, y_cnn_pred_test, average='weighted', zero_division=0),\n",
    "        precision_score(y_gru_test_cat, y_gru_pred_test, average='weighted', zero_division=0),\n",
    "        precision_score(y_hybrid_test_cat, y_hybrid_pred_test, average='weighted', zero_division=0)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_cnn_test_cat, y_cnn_pred_test, average='weighted', zero_division=0),\n",
    "        recall_score(y_gru_test_cat, y_gru_pred_test, average='weighted', zero_division=0),\n",
    "        recall_score(y_hybrid_test_cat, y_hybrid_pred_test, average='weighted', zero_division=0)\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_score(y_cnn_test_cat, y_cnn_pred_test, average='weighted', zero_division=0),\n",
    "        f1_score(y_gru_test_cat, y_gru_pred_test, average='weighted', zero_division=0),\n",
    "        f1_score(y_hybrid_test_cat, y_hybrid_pred_test, average='weighted', zero_division=0)\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.round(4)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nBest Model by Metric:\")\n",
    "for metric in ['Accuracy', 'Precision', 'Recall', 'F1-Score']:\n",
    "    best_idx = comparison_df[metric].idxmax()\n",
    "    best_model = comparison_df.loc[best_idx, 'Model']\n",
    "    best_score = comparison_df.loc[best_idx, metric]\n",
    "    print(f\"  {metric}: {best_model} ({best_score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bbdb0b",
   "metadata": {},
   "source": [
    "---\n",
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b9dc176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ Saving models...\n",
      "âœ“ Models saved:\n",
      "  - models/cnn_model.keras\n",
      "  - models/gru_model.keras\n",
      "  - models/hybrid_model.keras\n",
      "  - models/cnn_best.weights.h5\n",
      "  - models/gru_best.weights.h5\n",
      "  - models/hybrid_best.weights.h5\n",
      "\n",
      "ğŸ’¾ Saving scalers...\n",
      "âœ“ Scalers saved:\n",
      "  - models/cnn_scaler.pkl\n",
      "  - models/gru_scaler.pkl\n",
      "  - models/hybrid_temp_scaler.pkl\n",
      "  - models/hybrid_stat_scaler.pkl\n",
      "\n",
      "ğŸ’¾ Saving encoders...\n",
      "âœ“ Encoders saved:\n",
      "  - models/crop_encoder.pkl\n",
      "  - models/region_encoder.pkl\n",
      "\n",
      "âœ… All models, scalers, and encoders saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save complete models\n",
    "print(\"\\nğŸ’¾ Saving models...\")\n",
    "\n",
    "cnn_model.save('models/cnn_model.keras')\n",
    "gru_model.save('models/gru_model.keras')\n",
    "hybrid_model.save('models/hybrid_model.keras')\n",
    "\n",
    "print(\"âœ“ Models saved:\")\n",
    "print(\"  - models/cnn_model.keras\")\n",
    "print(\"  - models/gru_model.keras\")\n",
    "print(\"  - models/hybrid_model.keras\")\n",
    "print(\"  - models/cnn_best.weights.h5\")\n",
    "print(\"  - models/gru_best.weights.h5\")\n",
    "print(\"  - models/hybrid_best.weights.h5\")\n",
    "\n",
    "# Save scalers and encoders\n",
    "import joblib\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving scalers...\")\n",
    "joblib.dump(scaler_cnn, 'models/cnn_scaler.pkl')\n",
    "joblib.dump(scaler_gru, 'models/gru_scaler.pkl')\n",
    "joblib.dump(scaler_hybrid_temp, 'models/hybrid_temp_scaler.pkl')\n",
    "joblib.dump(scaler_hybrid_stat, 'models/hybrid_stat_scaler.pkl')\n",
    "\n",
    "print(\"âœ“ Scalers saved:\")\n",
    "print(\"  - models/cnn_scaler.pkl\")\n",
    "print(\"  - models/gru_scaler.pkl\")\n",
    "print(\"  - models/hybrid_temp_scaler.pkl\")\n",
    "print(\"  - models/hybrid_stat_scaler.pkl\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving encoders...\")\n",
    "joblib.dump(crop_encoder, 'models/crop_encoder.pkl')\n",
    "joblib.dump(region_encoder, 'models/region_encoder.pkl')\n",
    "\n",
    "print(\"âœ“ Encoders saved:\")\n",
    "print(\"  - models/crop_encoder.pkl\")\n",
    "print(\"  - models/region_encoder.pkl\")\n",
    "\n",
    "print(\"\\nâœ… All models, scalers, and encoders saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f9796c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAVING TRAINED MODELS\n",
      "================================================================================\n",
      "\n",
      "âœ“ Models directory created/verified\n",
      "\n",
      "ğŸ“Š Models in memory:\n",
      "  CNN model: Sequential\n",
      "  GRU model: Sequential\n",
      "  Hybrid model: Functional\n",
      "\n",
      "ğŸ’¾ Saving models...\n",
      "  âœ“ models/cnn_model.keras\n",
      "  âœ“ models/gru_model.keras\n",
      "  âœ“ models/hybrid_model.keras\n",
      "\n",
      "ğŸ’¾ Saving scalers...\n",
      "  âœ“ All 4 scalers saved\n",
      "\n",
      "ğŸ’¾ Saving encoders...\n",
      "  âœ“ All 2 encoders saved\n",
      "\n",
      "ğŸ“ Verifying files...\n",
      "  cnn_best.weights.h5                     2.07 MB\n",
      "  cnn_model.keras                         2.08 MB\n",
      "  cnn_scaler.pkl                          0.00 MB\n",
      "  crop_encoder.pkl                        0.00 MB\n",
      "  gru_best.weights.h5                     2.50 MB\n",
      "  gru_model.keras                         2.52 MB\n",
      "  gru_scaler.pkl                          0.00 MB\n",
      "  hybrid_best.weights.h5                  5.58 MB\n",
      "  hybrid_model.keras                      5.61 MB\n",
      "  hybrid_stat_scaler.pkl                  0.00 MB\n",
      "  hybrid_temp_scaler.pkl                  0.00 MB\n",
      "  region_encoder.pkl                      0.00 MB\n",
      "\n",
      "================================================================================\n",
      "âœ… ALL MODELS, SCALERS, AND ENCODERS SAVED SUCCESSFULLY!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# VERIFY AND SAVE MODELS\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING TRAINED MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Ensure models directory exists\n",
    "Path('models').mkdir(exist_ok=True)\n",
    "print(\"\\nâœ“ Models directory created/verified\")\n",
    "\n",
    "# Check models are in memory\n",
    "print(\"\\nğŸ“Š Models in memory:\")\n",
    "print(f\"  CNN model: {type(cnn_model).__name__}\")\n",
    "print(f\"  GRU model: {type(gru_model).__name__}\")\n",
    "print(f\"  Hybrid model: {type(hybrid_model).__name__}\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving models...\")\n",
    "cnn_model.save('models/cnn_model.keras')\n",
    "print(\"  âœ“ models/cnn_model.keras\")\n",
    "\n",
    "gru_model.save('models/gru_model.keras')\n",
    "print(\"  âœ“ models/gru_model.keras\")\n",
    "\n",
    "hybrid_model.save('models/hybrid_model.keras')\n",
    "print(\"  âœ“ models/hybrid_model.keras\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving scalers...\")\n",
    "joblib.dump(scaler_cnn, 'models/cnn_scaler.pkl')\n",
    "joblib.dump(scaler_gru, 'models/gru_scaler.pkl')\n",
    "joblib.dump(scaler_hybrid_temp, 'models/hybrid_temp_scaler.pkl')\n",
    "joblib.dump(scaler_hybrid_stat, 'models/hybrid_stat_scaler.pkl')\n",
    "print(\"  âœ“ All 4 scalers saved\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving encoders...\")\n",
    "joblib.dump(crop_encoder, 'models/crop_encoder.pkl')\n",
    "joblib.dump(region_encoder, 'models/region_encoder.pkl')\n",
    "print(\"  âœ“ All 2 encoders saved\")\n",
    "\n",
    "print(\"\\nğŸ“ Verifying files...\")\n",
    "files = sorted(os.listdir('models'))\n",
    "for f in files:\n",
    "    size = os.path.getsize(f'models/{f}') / (1024*1024)\n",
    "    print(f\"  {f:<35} {size:>8.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ALL MODELS, SCALERS, AND ENCODERS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce09ce4f",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "âœ… **Three models trained successfully:**\n",
    "- **CNN**: 1D convolutions for temporal pattern extraction\n",
    "- **GRU**: Bidirectional recurrent network for sequence modeling\n",
    "- **Hybrid CNN-GRU**: Combined architecture with CNNâ†’GRU pipeline + static features\n",
    "\n",
    "âœ… **Improvements implemented:**\n",
    "- Lag features (previous 1-3 years' yields)\n",
    "- Data augmentation (2x training data)\n",
    "- Class weights for balanced learning\n",
    "- Bidirectional processing for temporal context\n",
    "\n",
    "âœ… **Next Steps:**\n",
    "Proceed to phase4_validation.ipynb for detailed analysis and ensemble modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7709ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAVING MODELS\n",
      "================================================================================\n",
      "\n",
      "ğŸ’¾ Saving CNN model...\n",
      "  âœ“ models/cnn_model.keras\n",
      "\n",
      "ğŸ’¾ Saving GRU model...\n",
      "  âœ“ models/gru_model.keras\n",
      "\n",
      "ğŸ’¾ Saving Hybrid model...\n",
      "  âœ“ models/hybrid_model.keras\n",
      "\n",
      "ğŸ’¾ Saving scalers...\n",
      "  âœ“ All scalers saved\n",
      "\n",
      "ğŸ’¾ Saving encoders...\n",
      "  âœ“ All encoders saved\n",
      "\n",
      "ğŸ“ Files created:\n",
      "  cnn_best.weights.h5                     2.07 MB\n",
      "  cnn_model.keras                         2.08 MB\n",
      "  cnn_scaler.pkl                          0.00 MB\n",
      "  crop_encoder.pkl                        0.00 MB\n",
      "  gru_best.weights.h5                     2.50 MB\n",
      "  gru_model.keras                         2.52 MB\n",
      "  gru_scaler.pkl                          0.00 MB\n",
      "  hybrid_best.weights.h5                  5.58 MB\n",
      "  hybrid_model.keras                      5.61 MB\n",
      "  hybrid_stat_scaler.pkl                  0.00 MB\n",
      "  hybrid_temp_scaler.pkl                  0.00 MB\n",
      "  region_encoder.pkl                      0.00 MB\n",
      "\n",
      "================================================================================\n",
      "âœ… ALL FILES SAVED!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SAVE MODELS FROM KERNEL\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "Path('models').mkdir(exist_ok=True)\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving CNN model...\")\n",
    "cnn_model.save('models/cnn_model.keras')\n",
    "print(\"  âœ“ models/cnn_model.keras\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving GRU model...\")\n",
    "gru_model.save('models/gru_model.keras')\n",
    "print(\"  âœ“ models/gru_model.keras\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving Hybrid model...\")\n",
    "hybrid_model.save('models/hybrid_model.keras')\n",
    "print(\"  âœ“ models/hybrid_model.keras\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving scalers...\")\n",
    "joblib.dump(scaler_cnn, 'models/cnn_scaler.pkl')\n",
    "joblib.dump(scaler_gru, 'models/gru_scaler.pkl')\n",
    "joblib.dump(scaler_hybrid_temp, 'models/hybrid_temp_scaler.pkl')\n",
    "joblib.dump(scaler_hybrid_stat, 'models/hybrid_stat_scaler.pkl')\n",
    "print(\"  âœ“ All scalers saved\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving encoders...\")\n",
    "joblib.dump(crop_encoder, 'models/crop_encoder.pkl')\n",
    "joblib.dump(region_encoder, 'models/region_encoder.pkl')\n",
    "print(\"  âœ“ All encoders saved\")\n",
    "\n",
    "import os\n",
    "print(\"\\nğŸ“ Files created:\")\n",
    "for f in sorted(os.listdir('models')):\n",
    "    size = os.path.getsize(f'models/{f}') / (1024*1024)\n",
    "    print(f\"  {f:<35} {size:>8.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ALL FILES SAVED!\")\n",
    "print(\"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
