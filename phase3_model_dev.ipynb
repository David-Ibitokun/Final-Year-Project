{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d6d4ce7c",
   "metadata": {},
   "source": [
    "# Phase 3: Model Development - IMPROVED VERSION\n",
    "## CNN, GRU, and Hybrid CNN-GRU Models\n",
    "\n",
    "### ğŸ¯ Key Improvements in This Version:\n",
    "\n",
    "#### 1. **3 Crops Only** (Rice Removed)\n",
    "- Training on: Maize, Cassava, Yams\n",
    "- **Why**: Rice had poor accuracy (27-33% vs 50-72% for others)\n",
    "- **Expected Impact**: +10-15% overall accuracy\n",
    "\n",
    "#### 2. **Hybrid Model Improvements**\n",
    "Previous issues fixed:\n",
    "- âœ… Reduced dropout (less over-regularization)\n",
    "- âœ… Added residual connections\n",
    "- âœ… Stronger focal loss (gamma=3.0) for class balance\n",
    "- âœ… Amplified class weights (1.5x Low/High, 0.7x Medium)\n",
    "- âœ… Lower learning rate (0.0002) for stability\n",
    "- âœ… Smaller batch size (24) for better gradients\n",
    "\n",
    "**Expected**: Hybrid should now outperform CNN/GRU with >60% accuracy\n",
    "\n",
    "---"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bd81e7aa",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "c491b05d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "GPU available: False - []\n",
      "âœ“ All libraries imported successfully!\n",
      "TensorFlow version: 2.20.0\n",
      "Random seed: 42\n"
     ]
    }
   ],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import warnings\n",
    "import random\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models, callbacks, regularizers\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.utils import to_categorical\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.preprocessing import StandardScaler, LabelEncoder\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import (accuracy_score, precision_score, recall_score, \n",
    "                             f1_score, confusion_matrix, classification_report)\n",
    "\n",
    "# Set random seeds for reproducibility\n",
    "RANDOM_SEED = 42\n",
    "np.random.seed(RANDOM_SEED)\n",
    "random.seed(RANDOM_SEED)\n",
    "tf.random.set_seed(RANDOM_SEED)\n",
    "\n",
    "pd.set_option('display.max_columns', None)\n",
    "\n",
    "# Check for GPUs\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "print(f\"GPU available: {len(gpus) > 0} - {gpus}\")\n",
    "\n",
    "sns.set_style('whitegrid')\n",
    "\n",
    "print(f\"âœ“ All libraries imported successfully!\")\n",
    "print(f\"TensorFlow version: {tf.__version__}\")\n",
    "print(f\"Random seed: {RANDOM_SEED}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f302f79e",
   "metadata": {},
   "source": [
    "---\n",
    "## Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "9096f0d1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Configuration complete (3 crops: Maize, Cassava, Yams)\n",
      "  CNN features: 26\n",
      "  GRU features: 26\n",
      "  Hybrid temporal: 17\n",
      "  Hybrid static: 13\n"
     ]
    }
   ],
   "source": [
    "# Define paths\n",
    "data_path = Path('project_data')\n",
    "splits_path = data_path / 'train_test_split'\n",
    "\n",
    "# Crops and regions - RICE REMOVED due to poor performance (27-33% accuracy)\n",
    "CROPS = ['Maize', 'Cassava', 'Yams']\n",
    "ZONES = [\"North West\", \"North East\", \"North Central\", \"South West\", \"South East\", \"South South\"]\n",
    "\n",
    "# Feature columns\n",
    "cnn_feature_cols = [\n",
    "    'Temperature_C', 'Rainfall_mm', 'Humidity_percent', 'CO2_ppm',\n",
    "    'GDD', 'Cumulative_Rainfall', 'Days_Into_Season',\n",
    "    'pH_Temperature_Interaction', 'Nitrogen_Rainfall_Interaction',\n",
    "    'Is_Rainy_Season', 'Is_Peak_Growing',\n",
    "    'Heat_Stress', 'Cold_Stress', 'Rainfall_Anomaly',\n",
    "    'Drought_Risk', 'Flood_Risk',\n",
    "    # Lag features\n",
    "    'Yield_Lag_1', 'Yield_Lag_2', 'Yield_Lag_3',\n",
    "    'Yield_MA_3yr', 'Temp_MA_3yr', 'Rain_MA_3yr',\n",
    "    'Yield_YoY_Change', 'Temp_YoY_Change', 'Rain_YoY_Change',\n",
    "    'Yield_Volatility_3yr'\n",
    "]\n",
    "\n",
    "gru_feature_cols = cnn_feature_cols.copy()  # Same features for GRU\n",
    "\n",
    "# Hybrid features\n",
    "hybrid_temporal_cols = [\n",
    "    'Temperature_C', 'Rainfall_mm', 'Humidity_percent', 'CO2_ppm',\n",
    "    'GDD', 'Cumulative_Rainfall', 'Days_Into_Season',\n",
    "    'Is_Rainy_Season', 'Is_Peak_Growing',\n",
    "    'Heat_Stress', 'Cold_Stress', 'Rainfall_Anomaly',\n",
    "    'Drought_Risk', 'Flood_Risk',\n",
    "    'Yield_Lag_1', 'Yield_MA_3yr', 'Yield_YoY_Change'\n",
    "]\n",
    "\n",
    "hybrid_static_cols = [\n",
    "    'Avg_pH', 'Avg_Nitrogen_ppm', 'Avg_Phosphorus_ppm', 'Avg_Organic_Matter_Percent',\n",
    "    'pH_Temperature_Interaction', 'Nitrogen_Rainfall_Interaction',\n",
    "    'Yield_Lag_2', 'Yield_Lag_3', 'Temp_MA_3yr', 'Rain_MA_3yr',\n",
    "    'Temp_YoY_Change', 'Rain_YoY_Change', 'Yield_Volatility_3yr'\n",
    "]\n",
    "\n",
    "target_col = 'Yield_kg_per_ha'\n",
    "\n",
    "print(\"âœ“ Configuration complete (3 crops: Maize, Cassava, Yams)\")\n",
    "print(f\"  CNN features: {len(cnn_feature_cols)}\")\n",
    "print(f\"  GRU features: {len(gru_feature_cols)}\")\n",
    "print(f\"  Hybrid temporal: {len(hybrid_temporal_cols)}\")\n",
    "print(f\"  Hybrid static: {len(hybrid_static_cols)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b3ae0106",
   "metadata": {},
   "source": [
    "---\n",
    "## Utility Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0f1831d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ“ Utility functions defined\n"
     ]
    }
   ],
   "source": [
    "def categorize_yield_balanced(yields, method='percentile'):\n",
    "    \"\"\"\n",
    "    Categorize yields into Low/Medium/High with balanced thresholds.\n",
    "    \"\"\"\n",
    "    if method == 'percentile':\n",
    "        low_thresh = np.percentile(yields, 33.33)\n",
    "        high_thresh = np.percentile(yields, 66.67)\n",
    "    else:\n",
    "        low_thresh = 5.0\n",
    "        high_thresh = 15.0\n",
    "    \n",
    "    categories = np.zeros(len(yields), dtype=int)\n",
    "    categories[yields <= low_thresh] = 0  # Low\n",
    "    categories[(yields > low_thresh) & (yields <= high_thresh)] = 1  # Medium\n",
    "    categories[yields > high_thresh] = 2  # High\n",
    "    \n",
    "    return categories, (low_thresh, high_thresh)\n",
    "\n",
    "def augment_data(X, y, num_augmented=2, noise_level=0.05):\n",
    "    \"\"\"\n",
    "    Augment training data with Gaussian noise.\n",
    "    \"\"\"\n",
    "    X_list = [X]\n",
    "    y_list = [y]\n",
    "    \n",
    "    feature_stds = np.std(X, axis=0)\n",
    "    \n",
    "    for i in range(num_augmented):\n",
    "        noise = np.random.normal(0, noise_level, size=X.shape) * feature_stds\n",
    "        X_noisy = X + noise\n",
    "        X_noisy = np.clip(X_noisy, X.min(axis=0) * 0.8, X.max(axis=0) * 1.2)\n",
    "        \n",
    "        X_list.append(X_noisy)\n",
    "        y_list.append(y)\n",
    "    \n",
    "    X_augmented = np.vstack(X_list)\n",
    "    y_augmented = np.vstack(y_list)\n",
    "    \n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "def augment_time_series(X, y, num_augmented=1, noise_level=0.03):\n",
    "    \"\"\"\n",
    "    Augment time series data with noise.\n",
    "    \"\"\"\n",
    "    X_list = [X]\n",
    "    y_list = [y]\n",
    "    \n",
    "    feature_stds = np.std(X.reshape(-1, X.shape[2]), axis=0)\n",
    "    \n",
    "    for i in range(num_augmented):\n",
    "        noise = np.random.normal(0, noise_level, size=X.shape) * feature_stds\n",
    "        X_noisy = X + noise\n",
    "        X_noisy = np.clip(X_noisy, X.min(axis=(0,1)) * 0.8, X.max(axis=(0,1)) * 1.2)\n",
    "        \n",
    "        X_list.append(X_noisy)\n",
    "        y_list.append(y)\n",
    "    \n",
    "    X_augmented = np.vstack([x.reshape(x.shape[0], -1) for x in X_list])\n",
    "    X_augmented = X_augmented.reshape(-1, X.shape[1], X.shape[2])\n",
    "    y_augmented = np.vstack(y_list)\n",
    "    \n",
    "    return X_augmented, y_augmented\n",
    "\n",
    "def augment_hybrid_data(X_temp, X_stat, y, num_augmented=1, noise_level=0.03):\n",
    "    \"\"\"\n",
    "    Augment Hybrid model data (temporal + static inputs).\n",
    "    \"\"\"\n",
    "    X_temp_list = [X_temp]\n",
    "    X_stat_list = [X_stat]\n",
    "    y_list = [y]\n",
    "    \n",
    "    temp_stds = np.std(X_temp.reshape(-1, X_temp.shape[2]), axis=0)\n",
    "    stat_stds = np.std(X_stat, axis=0)\n",
    "    \n",
    "    for i in range(num_augmented):\n",
    "        noise_temp = np.random.normal(0, noise_level, size=X_temp.shape) * temp_stds\n",
    "        X_temp_noisy = X_temp + noise_temp\n",
    "        X_temp_noisy = np.clip(X_temp_noisy, X_temp.min(axis=(0,1)) * 0.8, X_temp.max(axis=(0,1)) * 1.2)\n",
    "        \n",
    "        noise_stat = np.random.normal(0, noise_level, size=X_stat.shape) * stat_stds\n",
    "        X_stat_noisy = X_stat + noise_stat\n",
    "        X_stat_noisy = np.clip(X_stat_noisy, X_stat.min(axis=0) * 0.8, X_stat.max(axis=0) * 1.2)\n",
    "        \n",
    "        X_temp_list.append(X_temp_noisy)\n",
    "        X_stat_list.append(X_stat_noisy)\n",
    "        y_list.append(y)\n",
    "    \n",
    "    X_temp_aug = np.vstack([x.reshape(x.shape[0], -1) for x in X_temp_list])\n",
    "    X_temp_aug = X_temp_aug.reshape(-1, X_temp.shape[1], X_temp.shape[2])\n",
    "    \n",
    "    X_stat_aug = np.vstack(X_stat_list)\n",
    "    y_aug = np.vstack(y_list)\n",
    "    \n",
    "    return X_temp_aug, X_stat_aug, y_aug\n",
    "\n",
    "print(\"âœ“ Utility functions defined\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc6ff9fb",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 1: CNN Model (1D Convolutional Neural Network)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "08d8fc9d",
   "metadata": {},
   "source": [
    "### What is 1D-CNN?\n",
    "\n",
    "Convolutional Neural Networks apply filters to detect patterns in data. For time series, 1D-CNN uses sliding windows to extract:\n",
    "- **Seasonal patterns** (e.g., rainy vs dry seasons)\n",
    "- **Local trends** (e.g., temperature peaks during growing season)\n",
    "- **Multi-scale features** through multiple conv layers\n",
    "\n",
    "**Why CNN for crop yield?**\n",
    "- Efficient at capturing temporal patterns (monthly sequences)\n",
    "- Fewer parameters than recurrent networks\n",
    "- Can detect seasonal signatures that indicate yield outcomes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d4bfbff",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PART 1: CNN MODEL (1D CONVOLUTIONS)\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Loading CNN data...\n",
      "  Train: (3888, 35)\n",
      "  Val:   (648, 35)\n",
      "  Test:  (648, 35)\n",
      "\n",
      "âœ“ Encoded categorical variables\n",
      "  Total features (including encodings): 28\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART 1: CNN MODEL (1D CONVOLUTIONS)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load CNN data\n",
    "print(\"\\nğŸ“Š Loading CNN data...\")\n",
    "cnn_train = pd.read_csv(splits_path / 'cnn' / 'train.csv')\n",
    "cnn_val = pd.read_csv(splits_path / 'cnn' / 'val.csv')\n",
    "cnn_test = pd.read_csv(splits_path / 'cnn' / 'test.csv')\n",
    "\n",
    "print(f\"  Train: {cnn_train.shape}\")\n",
    "print(f\"  Val:   {cnn_val.shape}\")\n",
    "print(f\"  Test:  {cnn_test.shape}\")\n",
    "\n",
    "# Remove missing yields\n",
    "cnn_train = cnn_train.dropna(subset=[target_col])\n",
    "cnn_val = cnn_val.dropna(subset=[target_col])\n",
    "cnn_test = cnn_test.dropna(subset=[target_col])\n",
    "\n",
    "# Encode categorical variables\n",
    "crop_encoder = LabelEncoder()\n",
    "region_encoder = LabelEncoder()\n",
    "\n",
    "all_crops = pd.concat([cnn_train['Crop'], cnn_val['Crop'], cnn_test['Crop']])\n",
    "all_regions = pd.concat([cnn_train['Region'], cnn_val['Region'], cnn_test['Region']])\n",
    "\n",
    "crop_encoder.fit(all_crops)\n",
    "region_encoder.fit(all_regions)\n",
    "\n",
    "cnn_train['Crop_encoded'] = crop_encoder.transform(cnn_train['Crop'])\n",
    "cnn_train['Region_encoded'] = region_encoder.transform(cnn_train['Region'])\n",
    "cnn_val['Crop_encoded'] = crop_encoder.transform(cnn_val['Crop'])\n",
    "cnn_val['Region_encoded'] = region_encoder.transform(cnn_val['Region'])\n",
    "cnn_test['Crop_encoded'] = crop_encoder.transform(cnn_test['Crop'])\n",
    "cnn_test['Region_encoded'] = region_encoder.transform(cnn_test['Region'])\n",
    "\n",
    "# Add encoded features to feature list\n",
    "cnn_all_features = cnn_feature_cols + ['Crop_encoded', 'Region_encoded']\n",
    "\n",
    "print(f\"\\nâœ“ Encoded categorical variables\")\n",
    "print(f\"  Total features (including encodings): {len(cnn_all_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a0647195",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Creating sequences for CNN...\n",
      "\n",
      "  Train sequences: (324, 12, 28)\n",
      "  Val sequences:   (54, 12, 28)\n",
      "  Test sequences:  (54, 12, 28)\n",
      "\n",
      "  Normalizing features...\n",
      "  âœ“ Features normalized\n"
     ]
    }
   ],
   "source": [
    "# Prepare sequences for CNN\n",
    "print(\"\\nğŸ“Š Creating sequences for CNN...\")\n",
    "\n",
    "def create_sequences(df, feature_cols, target_col, sequence_length=12):\n",
    "    \"\"\"Create sliding window sequences from monthly data\"\"\"\n",
    "    sequences = []\n",
    "    targets = []\n",
    "    \n",
    "    # Group by Region, Crop, Year to create annual sequences\n",
    "    for (region, crop, year), group in df.groupby(['Region', 'Crop', 'Year']):\n",
    "        group_sorted = group.sort_values('Month')\n",
    "        \n",
    "        if len(group_sorted) >= sequence_length:\n",
    "            # Take first sequence_length months\n",
    "            seq = group_sorted.iloc[:sequence_length][feature_cols].values\n",
    "            # Target is the annual yield (sum of monthly yields)\n",
    "            target = group_sorted[target_col].sum()\n",
    "            \n",
    "            sequences.append(seq)\n",
    "            targets.append(target)\n",
    "    \n",
    "    return np.array(sequences), np.array(targets)\n",
    "\n",
    "sequence_length = 12  # 12 months\n",
    "X_cnn_train, y_cnn_train = create_sequences(cnn_train, cnn_all_features, target_col, sequence_length)\n",
    "X_cnn_val, y_cnn_val = create_sequences(cnn_val, cnn_all_features, target_col, sequence_length)\n",
    "X_cnn_test, y_cnn_test = create_sequences(cnn_test, cnn_all_features, target_col, sequence_length)\n",
    "\n",
    "print(f\"\\n  Train sequences: {X_cnn_train.shape}\")\n",
    "print(f\"  Val sequences:   {X_cnn_val.shape}\")\n",
    "print(f\"  Test sequences:  {X_cnn_test.shape}\")\n",
    "\n",
    "# Normalize features\n",
    "print(\"\\n  Normalizing features...\")\n",
    "scaler_cnn = StandardScaler()\n",
    "\n",
    "# Reshape for scaling\n",
    "X_cnn_train_reshaped = X_cnn_train.reshape(-1, X_cnn_train.shape[2])\n",
    "scaler_cnn.fit(X_cnn_train_reshaped)\n",
    "\n",
    "X_cnn_train_scaled = scaler_cnn.transform(X_cnn_train.reshape(-1, X_cnn_train.shape[2])).reshape(X_cnn_train.shape)\n",
    "X_cnn_val_scaled = scaler_cnn.transform(X_cnn_val.reshape(-1, X_cnn_val.shape[2])).reshape(X_cnn_val.shape)\n",
    "X_cnn_test_scaled = scaler_cnn.transform(X_cnn_test.reshape(-1, X_cnn_test.shape[2])).reshape(X_cnn_test.shape)\n",
    "\n",
    "print(\"  âœ“ Features normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "640fccd6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Categorizing yields for classification...\n",
      "\n",
      "Category thresholds (kg/ha):\n",
      "  Low:    < 2.66\n",
      "  Medium: 2.66 - 11.37\n",
      "  High:   > 11.37\n",
      "\n",
      "Class distribution (Train):\n",
      "  Class 0: 108 samples (33.3%)\n",
      "  Class 1: 108 samples (33.3%)\n",
      "  Class 2: 108 samples (33.3%)\n",
      "\n",
      "âœ“ Targets encoded as one-hot vectors\n"
     ]
    }
   ],
   "source": [
    "# Categorize yields\n",
    "print(\"\\nğŸ“Š Categorizing yields for classification...\")\n",
    "\n",
    "y_cnn_train_cat, cnn_percentiles = categorize_yield_balanced(y_cnn_train, method='percentile')\n",
    "y_cnn_val_cat, _ = categorize_yield_balanced(y_cnn_val, method='percentile')\n",
    "y_cnn_test_cat, _ = categorize_yield_balanced(y_cnn_test, method='percentile')\n",
    "\n",
    "print(f\"\\nCategory thresholds (kg/ha):\")\n",
    "print(f\"  Low:    < {cnn_percentiles[0]:.2f}\")\n",
    "print(f\"  Medium: {cnn_percentiles[0]:.2f} - {cnn_percentiles[1]:.2f}\")\n",
    "print(f\"  High:   > {cnn_percentiles[1]:.2f}\")\n",
    "\n",
    "print(f\"\\nClass distribution (Train):\")\n",
    "unique, counts = np.unique(y_cnn_train_cat, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"  Class {cls}: {count} samples ({count/len(y_cnn_train_cat)*100:.1f}%)\")\n",
    "\n",
    "# One-hot encode\n",
    "y_cnn_train_onehot = to_categorical(y_cnn_train_cat, num_classes=3)\n",
    "y_cnn_val_onehot = to_categorical(y_cnn_val_cat, num_classes=3)\n",
    "y_cnn_test_onehot = to_categorical(y_cnn_test_cat, num_classes=3)\n",
    "\n",
    "print(f\"\\nâœ“ Targets encoded as one-hot vectors\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "69fd8be6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ APPLYING DATA AUGMENTATION...\n",
      "  Original CNN training size: 324 samples\n",
      "  Augmented CNN training size: 1296 samples\n",
      "  Augmentation ratio: 4.0x\n",
      "\n",
      "âš–ï¸  CNN Class weights:\n",
      "   Class 0: weight=1.000 (n=432 samples)\n",
      "   Class 1: weight=1.000 (n=432 samples)\n",
      "   Class 2: weight=1.000 (n=432 samples)\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation for CNN\n",
    "print(\"\\nğŸ”„ APPLYING DATA AUGMENTATION...\")\n",
    "\n",
    "print(f\"  Original CNN training size: {X_cnn_train_scaled.shape[0]} samples\")\n",
    "X_cnn_train_aug, y_cnn_train_aug = augment_time_series(\n",
    "    X_cnn_train_scaled,\n",
    "    y_cnn_train_onehot,\n",
    "    num_augmented=3,  # Increased from 1 to 3 for more training data\n",
    "    noise_level=0.02  # Reduced from 0.03 to 0.02 for better quality\n",
    ")\n",
    "\n",
    "print(f\"  Augmented CNN training size: {X_cnn_train_aug.shape[0]} samples\")\n",
    "print(f\"  Augmentation ratio: {X_cnn_train_aug.shape[0] / X_cnn_train_scaled.shape[0]:.1f}x\")\n",
    "\n",
    "# Shuffle\n",
    "indices = np.random.permutation(X_cnn_train_aug.shape[0])\n",
    "X_cnn_train_aug = X_cnn_train_aug[indices]\n",
    "y_cnn_train_aug = y_cnn_train_aug[indices]\n",
    "\n",
    "# Compute class weights\n",
    "y_cnn_train_labels = np.argmax(y_cnn_train_aug, axis=1)\n",
    "cnn_class_weights_array = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_cnn_train_labels),\n",
    "    y=y_cnn_train_labels\n",
    ")\n",
    "cnn_class_weight_dict = dict(enumerate(cnn_class_weights_array))\n",
    "\n",
    "print(f\"\\nâš–ï¸  CNN Class weights:\")\n",
    "for cls, weight in cnn_class_weight_dict.items():\n",
    "    count = np.sum(y_cnn_train_labels == cls)\n",
    "    print(f\"   Class {cls}: weight={weight:.3f} (n={count} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "68213d5b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">5,440</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)         â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)          â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)  â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)               â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)         â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_max_pooling1d            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling1D</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">32,896</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">8,256</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_4           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ conv1d (\u001b[38;5;33mConv1D\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚         \u001b[38;5;34m5,440\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)         â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d (\u001b[38;5;33mMaxPooling1D\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout (\u001b[38;5;33mDropout\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)          â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_1 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚        \u001b[38;5;34m24,704\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_1           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_1 (\u001b[38;5;33mMaxPooling1D\u001b[0m)  â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m128\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_2 (\u001b[38;5;33mConv1D\u001b[0m)               â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)         â”‚        \u001b[38;5;34m98,560\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_2           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)         â”‚         \u001b[38;5;34m1,024\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_2 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m, \u001b[38;5;34m256\u001b[0m)         â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_max_pooling1d            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m256\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalMaxPooling1D\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense (\u001b[38;5;33mDense\u001b[0m)                   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚        \u001b[38;5;34m32,896\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_3           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_3 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m8,256\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_4           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_4 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_5 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚            \u001b[38;5;34m99\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">174,595</span> (682.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m174,595\u001b[0m (682.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">173,315</span> (677.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m173,315\u001b[0m (677.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">1,280</span> (5.00 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m1,280\u001b[0m (5.00 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Focal Loss for handling class imbalance\n",
    "def focal_loss(gamma=2.0, alpha=0.25):\n",
    "    def focal_loss_fixed(y_true, y_pred):\n",
    "        epsilon = tf.keras.backend.epsilon()\n",
    "        y_pred = tf.clip_by_value(y_pred, epsilon, 1. - epsilon)\n",
    "        cross_entropy = -y_true * tf.math.log(y_pred)\n",
    "        weight = alpha * y_true * tf.pow((1 - y_pred), gamma)\n",
    "        loss = weight * cross_entropy\n",
    "        return tf.reduce_mean(tf.reduce_sum(loss, axis=1))\n",
    "    return focal_loss_fixed\n",
    "\n",
    "# Build CNN model with Attention\n",
    "def build_cnn_model(sequence_length, n_features, learning_rate=0.0003):\n",
    "    \"\"\"\n",
    "    Build 1D-CNN model with attention for time-series classification.\n",
    "    \n",
    "    Architecture:\n",
    "    - Conv1D layers extract temporal patterns\n",
    "    - Attention mechanism focuses on important patterns\n",
    "    - Dense layers for classification\n",
    "    - Enhanced regularization to prevent overfitting\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(sequence_length, n_features)),\n",
    "        \n",
    "        # First conv block\n",
    "        layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same',\n",
    "                     kernel_regularizer=regularizers.l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Second conv block\n",
    "        layers.Conv1D(filters=128, kernel_size=3, activation='relu', padding='same',\n",
    "                     kernel_regularizer=regularizers.l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.MaxPooling1D(pool_size=2),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Third conv block for deeper features\n",
    "        layers.Conv1D(filters=256, kernel_size=3, activation='relu', padding='same',\n",
    "                     kernel_regularizer=regularizers.l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Global pooling\n",
    "        layers.GlobalMaxPooling1D(),\n",
    "        \n",
    "        # Dense layers with stronger regularization\n",
    "        layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Output layer\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate, clipnorm=1.0)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=focal_loss(gamma=2.0, alpha=0.25),\n",
    "        metrics=['accuracy',\n",
    "                 tf.keras.metrics.Precision(name='precision'),\n",
    "                 tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "cnn_model = build_cnn_model(\n",
    "    sequence_length=sequence_length,\n",
    "    n_features=X_cnn_train_aug.shape[2],\n",
    "    learning_rate=0.0003\n",
    ")\n",
    "cnn_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "b4ac9470",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training CNN model...\n",
      "Epoch 1/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.3398 - loss: 1.4494 - precision: 0.3406 - recall: 0.2931\n",
      "Epoch 1: val_loss improved from None to 1.25785, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 1: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m12s\u001b[0m 47ms/step - accuracy: 0.3596 - loss: 1.4330 - precision: 0.3638 - recall: 0.3102 - val_accuracy: 0.3333 - val_loss: 1.2579 - val_precision: 1.0000 - val_recall: 0.0370 - learning_rate: 3.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.4063 - loss: 1.3964 - precision: 0.4081 - recall: 0.3454\n",
      "Epoch 2: val_loss improved from 1.25785 to 1.25282, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 2: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 28ms/step - accuracy: 0.4151 - loss: 1.3842 - precision: 0.4229 - recall: 0.3511 - val_accuracy: 0.3333 - val_loss: 1.2528 - val_precision: 0.7143 - val_recall: 0.1852 - learning_rate: 3.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.4499 - loss: 1.3341 - precision: 0.4779 - recall: 0.3867\n",
      "Epoch 3: val_loss improved from 1.25282 to 1.24244, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 3: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.4522 - loss: 1.3326 - precision: 0.4803 - recall: 0.3866 - val_accuracy: 0.3519 - val_loss: 1.2424 - val_precision: 0.7500 - val_recall: 0.3333 - learning_rate: 3.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.4899 - loss: 1.3026 - precision: 0.5287 - recall: 0.4330\n",
      "Epoch 4: val_loss improved from 1.24244 to 1.21480, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 4: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.5000 - loss: 1.2974 - precision: 0.5403 - recall: 0.4344 - val_accuracy: 0.4259 - val_loss: 1.2148 - val_precision: 0.8000 - val_recall: 0.2963 - learning_rate: 3.0000e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.4954 - loss: 1.2616 - precision: 0.5195 - recall: 0.4048\n",
      "Epoch 5: val_loss improved from 1.21480 to 1.19566, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 5: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.5316 - loss: 1.2476 - precision: 0.5638 - recall: 0.4468 - val_accuracy: 0.4444 - val_loss: 1.1957 - val_precision: 0.7200 - val_recall: 0.3333 - learning_rate: 3.0000e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m37/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.5432 - loss: 1.2350 - precision: 0.5653 - recall: 0.4721\n",
      "Epoch 6: val_loss improved from 1.19566 to 1.18467, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 6: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.5525 - loss: 1.2235 - precision: 0.5916 - recall: 0.4884 - val_accuracy: 0.4630 - val_loss: 1.1847 - val_precision: 0.6429 - val_recall: 0.3333 - learning_rate: 3.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6245 - loss: 1.1878 - precision: 0.6649 - recall: 0.5564\n",
      "Epoch 7: val_loss improved from 1.18467 to 1.16101, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 7: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.6250 - loss: 1.1827 - precision: 0.6667 - recall: 0.5540 - val_accuracy: 0.4630 - val_loss: 1.1610 - val_precision: 0.6333 - val_recall: 0.3519 - learning_rate: 3.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m37/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6647 - loss: 1.1604 - precision: 0.7068 - recall: 0.5993\n",
      "Epoch 8: val_loss improved from 1.16101 to 1.13582, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 8: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6466 - loss: 1.1566 - precision: 0.6915 - recall: 0.5795 - val_accuracy: 0.4815 - val_loss: 1.1358 - val_precision: 0.6000 - val_recall: 0.3889 - learning_rate: 3.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.6744 - loss: 1.1303 - precision: 0.7398 - recall: 0.6147\n",
      "Epoch 9: val_loss improved from 1.13582 to 1.11489, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 9: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.6952 - loss: 1.1176 - precision: 0.7560 - recall: 0.6312 - val_accuracy: 0.5741 - val_loss: 1.1149 - val_precision: 0.5676 - val_recall: 0.3889 - learning_rate: 3.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7080 - loss: 1.0947 - precision: 0.7433 - recall: 0.6401\n",
      "Epoch 10: val_loss improved from 1.11489 to 1.09211, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 10: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.7153 - loss: 1.0923 - precision: 0.7549 - recall: 0.6535 - val_accuracy: 0.6481 - val_loss: 1.0921 - val_precision: 0.5897 - val_recall: 0.4259 - learning_rate: 3.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.7497 - loss: 1.0657 - precision: 0.8124 - recall: 0.6869\n",
      "Epoch 11: val_loss improved from 1.09211 to 1.06654, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 11: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.7454 - loss: 1.0635 - precision: 0.7996 - recall: 0.6867 - val_accuracy: 0.6296 - val_loss: 1.0665 - val_precision: 0.6304 - val_recall: 0.5370 - learning_rate: 3.0000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.7587 - loss: 1.0390 - precision: 0.7854 - recall: 0.7024\n",
      "Epoch 12: val_loss improved from 1.06654 to 1.05551, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 12: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.7623 - loss: 1.0348 - precision: 0.7967 - recall: 0.6983 - val_accuracy: 0.6296 - val_loss: 1.0555 - val_precision: 0.6531 - val_recall: 0.5926 - learning_rate: 3.0000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.7989 - loss: 1.0135 - precision: 0.8288 - recall: 0.7413\n",
      "Epoch 13: val_loss improved from 1.05551 to 1.03793, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 13: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 35ms/step - accuracy: 0.8086 - loss: 1.0059 - precision: 0.8384 - recall: 0.7407 - val_accuracy: 0.6481 - val_loss: 1.0379 - val_precision: 0.6471 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8095 - loss: 0.9895 - precision: 0.8323 - recall: 0.7546\n",
      "Epoch 14: val_loss improved from 1.03793 to 1.02489, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 14: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 31ms/step - accuracy: 0.8102 - loss: 0.9807 - precision: 0.8401 - recall: 0.7539 - val_accuracy: 0.6481 - val_loss: 1.0249 - val_precision: 0.6415 - val_recall: 0.6296 - learning_rate: 3.0000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8333 - loss: 0.9623 - precision: 0.8600 - recall: 0.7754\n",
      "Epoch 15: val_loss improved from 1.02489 to 1.00847, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 15: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.8364 - loss: 0.9577 - precision: 0.8642 - recall: 0.7809 - val_accuracy: 0.6481 - val_loss: 1.0085 - val_precision: 0.6538 - val_recall: 0.6296 - learning_rate: 3.0000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8541 - loss: 0.9391 - precision: 0.8833 - recall: 0.8223\n",
      "Epoch 16: val_loss improved from 1.00847 to 0.98791, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 16: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 34ms/step - accuracy: 0.8472 - loss: 0.9358 - precision: 0.8800 - recall: 0.8094 - val_accuracy: 0.6481 - val_loss: 0.9879 - val_precision: 0.6604 - val_recall: 0.6481 - learning_rate: 3.0000e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8508 - loss: 0.9180 - precision: 0.8804 - recall: 0.8193\n",
      "Epoch 17: val_loss improved from 0.98791 to 0.96679, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 17: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 36ms/step - accuracy: 0.8596 - loss: 0.9135 - precision: 0.8873 - recall: 0.8202 - val_accuracy: 0.6481 - val_loss: 0.9668 - val_precision: 0.6731 - val_recall: 0.6481 - learning_rate: 3.0000e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8656 - loss: 0.8899 - precision: 0.8892 - recall: 0.8193\n",
      "Epoch 18: val_loss improved from 0.96679 to 0.95234, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 18: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.8657 - loss: 0.8868 - precision: 0.8918 - recall: 0.8202 - val_accuracy: 0.6667 - val_loss: 0.9523 - val_precision: 0.6731 - val_recall: 0.6481 - learning_rate: 3.0000e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.8824 - loss: 0.8661 - precision: 0.9082 - recall: 0.8437\n",
      "Epoch 19: val_loss improved from 0.95234 to 0.93188, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 19: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.8812 - loss: 0.8627 - precision: 0.9095 - recall: 0.8372 - val_accuracy: 0.6667 - val_loss: 0.9319 - val_precision: 0.6731 - val_recall: 0.6481 - learning_rate: 3.0000e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.8720 - loss: 0.8480 - precision: 0.9091 - recall: 0.8381\n",
      "Epoch 20: val_loss improved from 0.93188 to 0.91120, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 20: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.8750 - loss: 0.8417 - precision: 0.9078 - recall: 0.8434 - val_accuracy: 0.6667 - val_loss: 0.9112 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.8902 - loss: 0.8254 - precision: 0.9015 - recall: 0.8459\n",
      "Epoch 21: val_loss improved from 0.91120 to 0.88909, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 21: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.8827 - loss: 0.8209 - precision: 0.9036 - recall: 0.8465 - val_accuracy: 0.6667 - val_loss: 0.8891 - val_precision: 0.6731 - val_recall: 0.6481 - learning_rate: 3.0000e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.8935 - loss: 0.8019 - precision: 0.9229 - recall: 0.8581\n",
      "Epoch 22: val_loss improved from 0.88909 to 0.86845, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 22: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.8920 - loss: 0.7993 - precision: 0.9142 - recall: 0.8549 - val_accuracy: 0.6852 - val_loss: 0.8684 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.8891 - loss: 0.7840 - precision: 0.9078 - recall: 0.8659\n",
      "Epoch 23: val_loss improved from 0.86845 to 0.85022, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 23: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.8873 - loss: 0.7806 - precision: 0.9093 - recall: 0.8588 - val_accuracy: 0.6667 - val_loss: 0.8502 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.8982 - loss: 0.7575 - precision: 0.9143 - recall: 0.8676\n",
      "Epoch 24: val_loss improved from 0.85022 to 0.83356, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 24: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9020 - loss: 0.7548 - precision: 0.9236 - recall: 0.8681 - val_accuracy: 0.6667 - val_loss: 0.8336 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9052 - loss: 0.7379 - precision: 0.9252 - recall: 0.8796\n",
      "Epoch 25: val_loss improved from 0.83356 to 0.81723, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 25: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9059 - loss: 0.7331 - precision: 0.9297 - recall: 0.8781 - val_accuracy: 0.6667 - val_loss: 0.8172 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9111 - loss: 0.7157 - precision: 0.9283 - recall: 0.8757\n",
      "Epoch 26: val_loss improved from 0.81723 to 0.80059, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 26: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 29ms/step - accuracy: 0.9136 - loss: 0.7111 - precision: 0.9347 - recall: 0.8835 - val_accuracy: 0.6667 - val_loss: 0.8006 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9116 - loss: 0.6960 - precision: 0.9242 - recall: 0.8845\n",
      "Epoch 27: val_loss improved from 0.80059 to 0.77960, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 27: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9128 - loss: 0.6925 - precision: 0.9238 - recall: 0.8881 - val_accuracy: 0.6667 - val_loss: 0.7796 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9019 - loss: 0.6768 - precision: 0.9188 - recall: 0.8701\n",
      "Epoch 28: val_loss improved from 0.77960 to 0.76450, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 28: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9074 - loss: 0.6721 - precision: 0.9199 - recall: 0.8773 - val_accuracy: 0.6852 - val_loss: 0.7645 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9234 - loss: 0.6550 - precision: 0.9400 - recall: 0.9044\n",
      "Epoch 29: val_loss improved from 0.76450 to 0.73680, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 29: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9190 - loss: 0.6513 - precision: 0.9369 - recall: 0.8935 - val_accuracy: 0.6852 - val_loss: 0.7368 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9192 - loss: 0.6373 - precision: 0.9306 - recall: 0.8975\n",
      "Epoch 30: val_loss improved from 0.73680 to 0.71498, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 30: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9290 - loss: 0.6298 - precision: 0.9422 - recall: 0.9051 - val_accuracy: 0.6852 - val_loss: 0.7150 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9257 - loss: 0.6167 - precision: 0.9372 - recall: 0.8971\n",
      "Epoch 31: val_loss improved from 0.71498 to 0.69904, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 31: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9252 - loss: 0.6121 - precision: 0.9442 - recall: 0.9005 - val_accuracy: 0.6667 - val_loss: 0.6990 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9273 - loss: 0.6003 - precision: 0.9332 - recall: 0.9049\n",
      "Epoch 32: val_loss improved from 0.69904 to 0.68498, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 32: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9252 - loss: 0.5939 - precision: 0.9375 - recall: 0.9028 - val_accuracy: 0.6667 - val_loss: 0.6850 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9273 - loss: 0.5805 - precision: 0.9423 - recall: 0.9117\n",
      "Epoch 33: val_loss improved from 0.68498 to 0.65510, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 33: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9244 - loss: 0.5755 - precision: 0.9424 - recall: 0.9082 - val_accuracy: 0.6852 - val_loss: 0.6551 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m37/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9387 - loss: 0.5583 - precision: 0.9440 - recall: 0.9255\n",
      "Epoch 34: val_loss improved from 0.65510 to 0.63469, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 34: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9360 - loss: 0.5556 - precision: 0.9438 - recall: 0.9198 - val_accuracy: 0.6852 - val_loss: 0.6347 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9402 - loss: 0.5407 - precision: 0.9511 - recall: 0.9152\n",
      "Epoch 35: val_loss improved from 0.63469 to 0.61830, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 35: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 27ms/step - accuracy: 0.9406 - loss: 0.5364 - precision: 0.9511 - recall: 0.9151 - val_accuracy: 0.6667 - val_loss: 0.6183 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9232 - loss: 0.5240 - precision: 0.9342 - recall: 0.9154\n",
      "Epoch 36: val_loss improved from 0.61830 to 0.60225, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 36: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9398 - loss: 0.5188 - precision: 0.9524 - recall: 0.9267 - val_accuracy: 0.6852 - val_loss: 0.6023 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9523 - loss: 0.5046 - precision: 0.9643 - recall: 0.9330\n",
      "Epoch 37: val_loss improved from 0.60225 to 0.57626, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 37: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 27ms/step - accuracy: 0.9452 - loss: 0.5016 - precision: 0.9576 - recall: 0.9228 - val_accuracy: 0.6852 - val_loss: 0.5763 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9363 - loss: 0.4884 - precision: 0.9550 - recall: 0.9087\n",
      "Epoch 38: val_loss improved from 0.57626 to 0.57053, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 38: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 28ms/step - accuracy: 0.9398 - loss: 0.4850 - precision: 0.9580 - recall: 0.9144 - val_accuracy: 0.6852 - val_loss: 0.5705 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9434 - loss: 0.4723 - precision: 0.9488 - recall: 0.9329\n",
      "Epoch 39: val_loss improved from 0.57053 to 0.55121, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 39: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9498 - loss: 0.4666 - precision: 0.9574 - recall: 0.9375 - val_accuracy: 0.6852 - val_loss: 0.5512 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m37/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9452 - loss: 0.4546 - precision: 0.9512 - recall: 0.9212\n",
      "Epoch 40: val_loss improved from 0.55121 to 0.53439, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 40: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9460 - loss: 0.4503 - precision: 0.9549 - recall: 0.9306 - val_accuracy: 0.6852 - val_loss: 0.5344 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9435 - loss: 0.4414 - precision: 0.9494 - recall: 0.9333\n",
      "Epoch 41: val_loss improved from 0.53439 to 0.52508, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 41: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9491 - loss: 0.4369 - precision: 0.9580 - recall: 0.9329 - val_accuracy: 0.6852 - val_loss: 0.5251 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9525 - loss: 0.4222 - precision: 0.9620 - recall: 0.9360\n",
      "Epoch 42: val_loss improved from 0.52508 to 0.52496, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 42: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 32ms/step - accuracy: 0.9545 - loss: 0.4190 - precision: 0.9620 - recall: 0.9375 - val_accuracy: 0.6667 - val_loss: 0.5250 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m37/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9458 - loss: 0.4097 - precision: 0.9574 - recall: 0.9308\n",
      "Epoch 43: val_loss improved from 0.52496 to 0.51333, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 43: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 21ms/step - accuracy: 0.9498 - loss: 0.4045 - precision: 0.9587 - recall: 0.9321 - val_accuracy: 0.6667 - val_loss: 0.5133 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9517 - loss: 0.3922 - precision: 0.9568 - recall: 0.9369\n",
      "Epoch 44: val_loss improved from 0.51333 to 0.49944, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 44: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9506 - loss: 0.3888 - precision: 0.9558 - recall: 0.9352 - val_accuracy: 0.6852 - val_loss: 0.4994 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9585 - loss: 0.3773 - precision: 0.9656 - recall: 0.9476\n",
      "Epoch 45: val_loss improved from 0.49944 to 0.49324, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 45: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9630 - loss: 0.3734 - precision: 0.9731 - recall: 0.9475 - val_accuracy: 0.6852 - val_loss: 0.4932 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m37/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9541 - loss: 0.3638 - precision: 0.9607 - recall: 0.9433\n",
      "Epoch 46: val_loss improved from 0.49324 to 0.47285, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 46: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9599 - loss: 0.3593 - precision: 0.9670 - recall: 0.9483 - val_accuracy: 0.6852 - val_loss: 0.4728 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9676 - loss: 0.3513 - precision: 0.9722 - recall: 0.9583\n",
      "Epoch 47: val_loss improved from 0.47285 to 0.46814, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 47: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9684 - loss: 0.3468 - precision: 0.9726 - recall: 0.9576 - val_accuracy: 0.6852 - val_loss: 0.4681 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9626 - loss: 0.3358 - precision: 0.9679 - recall: 0.9568\n",
      "Epoch 48: val_loss improved from 0.46814 to 0.45081, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 48: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9591 - loss: 0.3339 - precision: 0.9663 - recall: 0.9514 - val_accuracy: 0.6852 - val_loss: 0.4508 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9613 - loss: 0.3241 - precision: 0.9673 - recall: 0.9513\n",
      "Epoch 49: val_loss improved from 0.45081 to 0.44425, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 49: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9637 - loss: 0.3225 - precision: 0.9693 - recall: 0.9514 - val_accuracy: 0.6852 - val_loss: 0.4442 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9706 - loss: 0.3117 - precision: 0.9754 - recall: 0.9544\n",
      "Epoch 50: val_loss improved from 0.44425 to 0.42320, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 50: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9668 - loss: 0.3093 - precision: 0.9718 - recall: 0.9560 - val_accuracy: 0.6852 - val_loss: 0.4232 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9561 - loss: 0.2997 - precision: 0.9621 - recall: 0.9457\n",
      "Epoch 51: val_loss improved from 0.42320 to 0.40736, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 51: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9568 - loss: 0.2966 - precision: 0.9646 - recall: 0.9452 - val_accuracy: 0.6667 - val_loss: 0.4074 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m37/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9534 - loss: 0.2880 - precision: 0.9611 - recall: 0.9456\n",
      "Epoch 52: val_loss improved from 0.40736 to 0.38598, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 52: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9606 - loss: 0.2853 - precision: 0.9677 - recall: 0.9483 - val_accuracy: 0.6667 - val_loss: 0.3860 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9662 - loss: 0.2747 - precision: 0.9749 - recall: 0.9612\n",
      "Epoch 53: val_loss improved from 0.38598 to 0.37731, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 53: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9691 - loss: 0.2717 - precision: 0.9796 - recall: 0.9630 - val_accuracy: 0.6667 - val_loss: 0.3773 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9655 - loss: 0.2643 - precision: 0.9663 - recall: 0.9598\n",
      "Epoch 54: val_loss did not improve from 0.37731\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9684 - loss: 0.2617 - precision: 0.9712 - recall: 0.9630 - val_accuracy: 0.6667 - val_loss: 0.3793 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9666 - loss: 0.2561 - precision: 0.9733 - recall: 0.9449\n",
      "Epoch 55: val_loss improved from 0.37731 to 0.36027, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 55: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9707 - loss: 0.2525 - precision: 0.9772 - recall: 0.9576 - val_accuracy: 0.6667 - val_loss: 0.3603 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9705 - loss: 0.2437 - precision: 0.9780 - recall: 0.9660\n",
      "Epoch 56: val_loss improved from 0.36027 to 0.35798, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 56: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9715 - loss: 0.2410 - precision: 0.9774 - recall: 0.9660 - val_accuracy: 0.6667 - val_loss: 0.3580 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9640 - loss: 0.2333 - precision: 0.9739 - recall: 0.9575\n",
      "Epoch 57: val_loss improved from 0.35798 to 0.35702, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 57: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9653 - loss: 0.2311 - precision: 0.9757 - recall: 0.9599 - val_accuracy: 0.6667 - val_loss: 0.3570 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m37/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9714 - loss: 0.2247 - precision: 0.9742 - recall: 0.9613\n",
      "Epoch 58: val_loss improved from 0.35702 to 0.33974, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 58: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9738 - loss: 0.2216 - precision: 0.9789 - recall: 0.9668 - val_accuracy: 0.6667 - val_loss: 0.3397 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9763 - loss: 0.2137 - precision: 0.9800 - recall: 0.9716\n",
      "Epoch 59: val_loss improved from 0.33974 to 0.32365, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 59: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9784 - loss: 0.2130 - precision: 0.9828 - recall: 0.9707 - val_accuracy: 0.6667 - val_loss: 0.3237 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9725 - loss: 0.2054 - precision: 0.9752 - recall: 0.9677\n",
      "Epoch 60: val_loss did not improve from 0.32365\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9753 - loss: 0.2031 - precision: 0.9774 - recall: 0.9684 - val_accuracy: 0.6667 - val_loss: 0.3360 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m37/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9829 - loss: 0.1957 - precision: 0.9845 - recall: 0.9792\n",
      "Epoch 61: val_loss did not improve from 0.32365\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9830 - loss: 0.1938 - precision: 0.9844 - recall: 0.9730 - val_accuracy: 0.6667 - val_loss: 0.3306 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9729 - loss: 0.1895 - precision: 0.9783 - recall: 0.9674\n",
      "Epoch 62: val_loss improved from 0.32365 to 0.31605, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 62: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9815 - loss: 0.1861 - precision: 0.9845 - recall: 0.9776 - val_accuracy: 0.6667 - val_loss: 0.3160 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9666 - loss: 0.1816 - precision: 0.9724 - recall: 0.9616\n",
      "Epoch 63: val_loss did not improve from 0.31605\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9699 - loss: 0.1795 - precision: 0.9735 - recall: 0.9630 - val_accuracy: 0.6667 - val_loss: 0.3205 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9681 - loss: 0.1729 - precision: 0.9713 - recall: 0.9636\n",
      "Epoch 64: val_loss improved from 0.31605 to 0.31188, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 64: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9769 - loss: 0.1706 - precision: 0.9798 - recall: 0.9715 - val_accuracy: 0.6852 - val_loss: 0.3119 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9905 - loss: 0.1642 - precision: 0.9923 - recall: 0.9785\n",
      "Epoch 65: val_loss did not improve from 0.31188\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9869 - loss: 0.1626 - precision: 0.9906 - recall: 0.9769 - val_accuracy: 0.6852 - val_loss: 0.3184 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9766 - loss: 0.1590 - precision: 0.9778 - recall: 0.9670\n",
      "Epoch 66: val_loss did not improve from 0.31188\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 26ms/step - accuracy: 0.9753 - loss: 0.1572 - precision: 0.9759 - recall: 0.9668 - val_accuracy: 0.6852 - val_loss: 0.3140 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9801 - loss: 0.1515 - precision: 0.9807 - recall: 0.9770\n",
      "Epoch 67: val_loss improved from 0.31188 to 0.29342, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 67: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 33ms/step - accuracy: 0.9738 - loss: 0.1512 - precision: 0.9767 - recall: 0.9699 - val_accuracy: 0.6852 - val_loss: 0.2934 - val_precision: 0.6981 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9693 - loss: 0.1474 - precision: 0.9732 - recall: 0.9608\n",
      "Epoch 68: val_loss improved from 0.29342 to 0.28269, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 68: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9730 - loss: 0.1457 - precision: 0.9766 - recall: 0.9653 - val_accuracy: 0.6852 - val_loss: 0.2827 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9746 - loss: 0.1422 - precision: 0.9759 - recall: 0.9689\n",
      "Epoch 69: val_loss did not improve from 0.28269\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9745 - loss: 0.1397 - precision: 0.9766 - recall: 0.9676 - val_accuracy: 0.6852 - val_loss: 0.3170 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9784 - loss: 0.1341 - precision: 0.9813 - recall: 0.9720\n",
      "Epoch 70: val_loss did not improve from 0.28269\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9807 - loss: 0.1329 - precision: 0.9844 - recall: 0.9730 - val_accuracy: 0.6852 - val_loss: 0.2974 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m37/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9842 - loss: 0.1270 - precision: 0.9860 - recall: 0.9798\n",
      "Epoch 71: val_loss did not improve from 0.28269\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9846 - loss: 0.1259 - precision: 0.9868 - recall: 0.9792 - val_accuracy: 0.6852 - val_loss: 0.3078 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9839 - loss: 0.1222 - precision: 0.9866 - recall: 0.9824\n",
      "Epoch 72: val_loss did not improve from 0.28269\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9815 - loss: 0.1216 - precision: 0.9852 - recall: 0.9792 - val_accuracy: 0.6852 - val_loss: 0.2875 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9780 - loss: 0.1173 - precision: 0.9839 - recall: 0.9756\n",
      "Epoch 73: val_loss improved from 0.28269 to 0.27704, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 73: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9799 - loss: 0.1163 - precision: 0.9844 - recall: 0.9753 - val_accuracy: 0.6852 - val_loss: 0.2770 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9914 - loss: 0.1112 - precision: 0.9945 - recall: 0.9869\n",
      "Epoch 74: val_loss improved from 0.27704 to 0.27224, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 74: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9884 - loss: 0.1109 - precision: 0.9907 - recall: 0.9853 - val_accuracy: 0.6852 - val_loss: 0.2722 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9800 - loss: 0.1086 - precision: 0.9810 - recall: 0.9781\n",
      "Epoch 75: val_loss did not improve from 0.27224\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9784 - loss: 0.1085 - precision: 0.9806 - recall: 0.9769 - val_accuracy: 0.6852 - val_loss: 0.2895 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9823 - loss: 0.1038 - precision: 0.9847 - recall: 0.9765\n",
      "Epoch 76: val_loss did not improve from 0.27224\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9838 - loss: 0.1027 - precision: 0.9852 - recall: 0.9761 - val_accuracy: 0.6667 - val_loss: 0.2949 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9875 - loss: 0.0988 - precision: 0.9876 - recall: 0.9845\n",
      "Epoch 77: val_loss improved from 0.27224 to 0.25098, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 77: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9799 - loss: 0.1001 - precision: 0.9806 - recall: 0.9745 - val_accuracy: 0.7222 - val_loss: 0.2510 - val_precision: 0.7170 - val_recall: 0.7037 - learning_rate: 3.0000e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m37/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9890 - loss: 0.0952 - precision: 0.9889 - recall: 0.9805\n",
      "Epoch 78: val_loss did not improve from 0.25098\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9861 - loss: 0.0948 - precision: 0.9860 - recall: 0.9784 - val_accuracy: 0.6667 - val_loss: 0.2931 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9860 - loss: 0.0907 - precision: 0.9868 - recall: 0.9860\n",
      "Epoch 79: val_loss did not improve from 0.25098\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9846 - loss: 0.0906 - precision: 0.9861 - recall: 0.9846 - val_accuracy: 0.6852 - val_loss: 0.2867 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m37/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9846 - loss: 0.0880 - precision: 0.9849 - recall: 0.9806\n",
      "Epoch 80: val_loss improved from 0.25098 to 0.23417, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 80: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9838 - loss: 0.0870 - precision: 0.9845 - recall: 0.9792 - val_accuracy: 0.6852 - val_loss: 0.2342 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9846 - loss: 0.0843 - precision: 0.9847 - recall: 0.9804\n",
      "Epoch 81: val_loss did not improve from 0.23417\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9869 - loss: 0.0832 - precision: 0.9876 - recall: 0.9830 - val_accuracy: 0.6852 - val_loss: 0.2461 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9821 - loss: 0.0815 - precision: 0.9823 - recall: 0.9772\n",
      "Epoch 82: val_loss improved from 0.23417 to 0.22755, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 82: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 32ms/step - accuracy: 0.9830 - loss: 0.0805 - precision: 0.9844 - recall: 0.9769 - val_accuracy: 0.6852 - val_loss: 0.2276 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9845 - loss: 0.0778 - precision: 0.9873 - recall: 0.9738\n",
      "Epoch 83: val_loss did not improve from 0.22755\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9823 - loss: 0.0775 - precision: 0.9852 - recall: 0.9745 - val_accuracy: 0.6852 - val_loss: 0.2532 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9839 - loss: 0.0748 - precision: 0.9860 - recall: 0.9808\n",
      "Epoch 84: val_loss did not improve from 0.22755\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9807 - loss: 0.0741 - precision: 0.9844 - recall: 0.9769 - val_accuracy: 0.6667 - val_loss: 0.2477 - val_precision: 0.6923 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9859 - loss: 0.0711 - precision: 0.9879 - recall: 0.9830\n",
      "Epoch 85: val_loss did not improve from 0.22755\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9846 - loss: 0.0715 - precision: 0.9868 - recall: 0.9784 - val_accuracy: 0.7037 - val_loss: 0.2511 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 3.0000e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m36/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”â”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9811 - loss: 0.0693 - precision: 0.9829 - recall: 0.9779\n",
      "Epoch 86: val_loss did not improve from 0.22755\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9784 - loss: 0.0697 - precision: 0.9806 - recall: 0.9769 - val_accuracy: 0.6852 - val_loss: 0.2712 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9884 - loss: 0.0661 - precision: 0.9917 - recall: 0.9869\n",
      "Epoch 87: val_loss did not improve from 0.22755\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9846 - loss: 0.0661 - precision: 0.9876 - recall: 0.9823 - val_accuracy: 0.6852 - val_loss: 0.2686 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9824 - loss: 0.0655 - precision: 0.9850 - recall: 0.9797\n",
      "Epoch 88: val_loss did not improve from 0.22755\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9846 - loss: 0.0649 - precision: 0.9868 - recall: 0.9830 - val_accuracy: 0.7222 - val_loss: 0.2475 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 3.0000e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9776 - loss: 0.0648 - precision: 0.9816 - recall: 0.9770\n",
      "Epoch 89: val_loss did not improve from 0.22755\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9776 - loss: 0.0649 - precision: 0.9799 - recall: 0.9769 - val_accuracy: 0.6667 - val_loss: 0.2555 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9840 - loss: 0.0621 - precision: 0.9850 - recall: 0.9829\n",
      "Epoch 90: val_loss improved from 0.22755 to 0.21466, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 90: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9853 - loss: 0.0617 - precision: 0.9868 - recall: 0.9823 - val_accuracy: 0.6667 - val_loss: 0.2147 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9864 - loss: 0.0581 - precision: 0.9896 - recall: 0.9856\n",
      "Epoch 91: val_loss improved from 0.21466 to 0.19008, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 91: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9892 - loss: 0.0573 - precision: 0.9915 - recall: 0.9884 - val_accuracy: 0.7037 - val_loss: 0.1901 - val_precision: 0.6981 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9857 - loss: 0.0571 - precision: 0.9862 - recall: 0.9807\n",
      "Epoch 92: val_loss did not improve from 0.19008\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9884 - loss: 0.0561 - precision: 0.9891 - recall: 0.9846 - val_accuracy: 0.6852 - val_loss: 0.2210 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9839 - loss: 0.0544 - precision: 0.9888 - recall: 0.9814\n",
      "Epoch 93: val_loss did not improve from 0.19008\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9877 - loss: 0.0538 - precision: 0.9915 - recall: 0.9853 - val_accuracy: 0.6852 - val_loss: 0.2370 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9916 - loss: 0.0515 - precision: 0.9931 - recall: 0.9865\n",
      "Epoch 94: val_loss did not improve from 0.19008\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9900 - loss: 0.0512 - precision: 0.9922 - recall: 0.9846 - val_accuracy: 0.6852 - val_loss: 0.2312 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9919 - loss: 0.0502 - precision: 0.9948 - recall: 0.9865\n",
      "Epoch 95: val_loss did not improve from 0.19008\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9884 - loss: 0.0505 - precision: 0.9915 - recall: 0.9846 - val_accuracy: 0.7222 - val_loss: 0.2257 - val_precision: 0.7170 - val_recall: 0.7037 - learning_rate: 3.0000e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9866 - loss: 0.0491 - precision: 0.9884 - recall: 0.9862\n",
      "Epoch 96: val_loss did not improve from 0.19008\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9838 - loss: 0.0496 - precision: 0.9868 - recall: 0.9830 - val_accuracy: 0.6667 - val_loss: 0.2329 - val_precision: 0.6923 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9838 - loss: 0.0488 - precision: 0.9840 - recall: 0.9834\n",
      "Epoch 97: val_loss did not improve from 0.19008\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9846 - loss: 0.0483 - precision: 0.9868 - recall: 0.9838 - val_accuracy: 0.6852 - val_loss: 0.2665 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9843 - loss: 0.0481 - precision: 0.9847 - recall: 0.9821\n",
      "Epoch 98: val_loss did not improve from 0.19008\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9838 - loss: 0.0471 - precision: 0.9845 - recall: 0.9815 - val_accuracy: 0.6852 - val_loss: 0.2560 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 20ms/step - accuracy: 0.9834 - loss: 0.0465 - precision: 0.9843 - recall: 0.9799\n",
      "Epoch 99: val_loss did not improve from 0.19008\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 24ms/step - accuracy: 0.9869 - loss: 0.0472 - precision: 0.9876 - recall: 0.9823 - val_accuracy: 0.6667 - val_loss: 0.2469 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9890 - loss: 0.0429 - precision: 0.9901 - recall: 0.9876\n",
      "Epoch 100: val_loss did not improve from 0.19008\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 0.9915 - loss: 0.0429 - precision: 0.9930 - recall: 0.9884 - val_accuracy: 0.6852 - val_loss: 0.2217 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9879 - loss: 0.0416 - precision: 0.9899 - recall: 0.9874\n",
      "Epoch 101: val_loss did not improve from 0.19008\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9869 - loss: 0.0417 - precision: 0.9899 - recall: 0.9846 - val_accuracy: 0.7222 - val_loss: 0.2083 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 3.0000e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9827 - loss: 0.0429 - precision: 0.9854 - recall: 0.9795\n",
      "Epoch 102: val_loss did not improve from 0.19008\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9838 - loss: 0.0426 - precision: 0.9860 - recall: 0.9784 - val_accuracy: 0.7222 - val_loss: 0.1974 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 3.0000e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9768 - loss: 0.0407 - precision: 0.9785 - recall: 0.9742\n",
      "Epoch 103: val_loss improved from 0.19008 to 0.17836, saving model to models/cnn_best.weights.h5\n",
      "\n",
      "Epoch 103: finished saving model to models/cnn_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 34ms/step - accuracy: 0.9807 - loss: 0.0404 - precision: 0.9829 - recall: 0.9761 - val_accuracy: 0.7037 - val_loss: 0.1784 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 3.0000e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 15ms/step - accuracy: 0.9888 - loss: 0.0386 - precision: 0.9907 - recall: 0.9876\n",
      "Epoch 104: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 20ms/step - accuracy: 0.9869 - loss: 0.0390 - precision: 0.9876 - recall: 0.9846 - val_accuracy: 0.6667 - val_loss: 0.2560 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9871 - loss: 0.0390 - precision: 0.9871 - recall: 0.9846\n",
      "Epoch 105: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9892 - loss: 0.0386 - precision: 0.9891 - recall: 0.9846 - val_accuracy: 0.7037 - val_loss: 0.2064 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 3.0000e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9884 - loss: 0.0370 - precision: 0.9902 - recall: 0.9879\n",
      "Epoch 106: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 17ms/step - accuracy: 0.9877 - loss: 0.0379 - precision: 0.9892 - recall: 0.9853 - val_accuracy: 0.7222 - val_loss: 0.2152 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 3.0000e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9822 - loss: 0.0377 - precision: 0.9857 - recall: 0.9808\n",
      "Epoch 107: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9799 - loss: 0.0377 - precision: 0.9837 - recall: 0.9769 - val_accuracy: 0.7037 - val_loss: 0.2070 - val_precision: 0.7170 - val_recall: 0.7037 - learning_rate: 3.0000e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9854 - loss: 0.0359 - precision: 0.9861 - recall: 0.9850\n",
      "Epoch 108: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9869 - loss: 0.0357 - precision: 0.9884 - recall: 0.9861 - val_accuracy: 0.6667 - val_loss: 0.2759 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 21ms/step - accuracy: 0.9959 - loss: 0.0332 - precision: 0.9959 - recall: 0.9946\n",
      "Epoch 109: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9946 - loss: 0.0330 - precision: 0.9946 - recall: 0.9931 - val_accuracy: 0.6667 - val_loss: 0.2665 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m37/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9873 - loss: 0.0328 - precision: 0.9873 - recall: 0.9865\n",
      "Epoch 110: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9884 - loss: 0.0327 - precision: 0.9892 - recall: 0.9861 - val_accuracy: 0.7407 - val_loss: 0.1883 - val_precision: 0.7407 - val_recall: 0.7407 - learning_rate: 3.0000e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9835 - loss: 0.0335 - precision: 0.9844 - recall: 0.9802\n",
      "Epoch 111: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9884 - loss: 0.0325 - precision: 0.9891 - recall: 0.9846 - val_accuracy: 0.6852 - val_loss: 0.2476 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9931 - loss: 0.0299 - precision: 0.9964 - recall: 0.9931\n",
      "Epoch 112: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9907 - loss: 0.0301 - precision: 0.9930 - recall: 0.9907 - val_accuracy: 0.6667 - val_loss: 0.2404 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9964 - loss: 0.0287 - precision: 0.9964 - recall: 0.9963\n",
      "Epoch 113: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9977 - loss: 0.0281 - precision: 0.9977 - recall: 0.9969 - val_accuracy: 0.6667 - val_loss: 0.2444 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 3.0000e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9910 - loss: 0.0283 - precision: 0.9920 - recall: 0.9910\n",
      "Epoch 114: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9923 - loss: 0.0288 - precision: 0.9930 - recall: 0.9915 - val_accuracy: 0.6852 - val_loss: 0.2254 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 26ms/step - accuracy: 0.9814 - loss: 0.0293 - precision: 0.9827 - recall: 0.9765\n",
      "Epoch 115: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\n",
      "Epoch 115: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 37ms/step - accuracy: 0.9861 - loss: 0.0278 - precision: 0.9876 - recall: 0.9830 - val_accuracy: 0.6481 - val_loss: 0.2418 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 3.0000e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9904 - loss: 0.0266 - precision: 0.9922 - recall: 0.9899\n",
      "Epoch 116: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9931 - loss: 0.0262 - precision: 0.9954 - recall: 0.9923 - val_accuracy: 0.6852 - val_loss: 0.2103 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 1.5000e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9925 - loss: 0.0254 - precision: 0.9925 - recall: 0.9924\n",
      "Epoch 117: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9946 - loss: 0.0252 - precision: 0.9946 - recall: 0.9938 - val_accuracy: 0.6667 - val_loss: 0.2195 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 1.5000e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9940 - loss: 0.0251 - precision: 0.9950 - recall: 0.9928\n",
      "Epoch 118: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9946 - loss: 0.0250 - precision: 0.9954 - recall: 0.9923 - val_accuracy: 0.6852 - val_loss: 0.2264 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 1.5000e-04\n",
      "Epoch 119/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 19ms/step - accuracy: 0.9982 - loss: 0.0242 - precision: 0.9982 - recall: 0.9976\n",
      "Epoch 119: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 26ms/step - accuracy: 0.9985 - loss: 0.0240 - precision: 0.9985 - recall: 0.9961 - val_accuracy: 0.6852 - val_loss: 0.2365 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 1.5000e-04\n",
      "Epoch 120/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9985 - loss: 0.0236 - precision: 0.9985 - recall: 0.9974\n",
      "Epoch 120: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 22ms/step - accuracy: 0.9992 - loss: 0.0234 - precision: 0.9992 - recall: 0.9961 - val_accuracy: 0.6667 - val_loss: 0.2531 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 1.5000e-04\n",
      "Epoch 121/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 11ms/step - accuracy: 0.9936 - loss: 0.0243 - precision: 0.9952 - recall: 0.9916\n",
      "Epoch 121: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9954 - loss: 0.0239 - precision: 0.9961 - recall: 0.9931 - val_accuracy: 0.7037 - val_loss: 0.2236 - val_precision: 0.6981 - val_recall: 0.6852 - learning_rate: 1.5000e-04\n",
      "Epoch 122/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 14ms/step - accuracy: 0.9950 - loss: 0.0223 - precision: 0.9974 - recall: 0.9950\n",
      "Epoch 122: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9961 - loss: 0.0223 - precision: 0.9985 - recall: 0.9961 - val_accuracy: 0.6852 - val_loss: 0.2202 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 1.5000e-04\n",
      "Epoch 123/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9973 - loss: 0.0224 - precision: 0.9973 - recall: 0.9967\n",
      "Epoch 123: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 18ms/step - accuracy: 0.9954 - loss: 0.0226 - precision: 0.9961 - recall: 0.9946 - val_accuracy: 0.6852 - val_loss: 0.2266 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 1.5000e-04\n",
      "Epoch 124/300\n",
      "\u001b[1m37/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 10ms/step - accuracy: 1.0000 - loss: 0.0213 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 124: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 13ms/step - accuracy: 1.0000 - loss: 0.0212 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.7037 - val_loss: 0.2233 - val_precision: 0.6981 - val_recall: 0.6852 - learning_rate: 1.5000e-04\n",
      "Epoch 125/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9973 - loss: 0.0211 - precision: 0.9973 - recall: 0.9955\n",
      "Epoch 125: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 17ms/step - accuracy: 0.9985 - loss: 0.0209 - precision: 0.9985 - recall: 0.9969 - val_accuracy: 0.6852 - val_loss: 0.2319 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 1.5000e-04\n",
      "Epoch 126/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9942 - loss: 0.0214 - precision: 0.9942 - recall: 0.9927\n",
      "Epoch 126: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 19ms/step - accuracy: 0.9907 - loss: 0.0218 - precision: 0.9915 - recall: 0.9900 - val_accuracy: 0.7037 - val_loss: 0.2342 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 1.5000e-04\n",
      "Epoch 127/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9957 - loss: 0.0204 - precision: 0.9960 - recall: 0.9957\n",
      "Epoch 127: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\n",
      "Epoch 127: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9946 - loss: 0.0209 - precision: 0.9961 - recall: 0.9946 - val_accuracy: 0.7037 - val_loss: 0.2423 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 1.5000e-04\n",
      "Epoch 128/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9994 - loss: 0.0202 - precision: 0.9994 - recall: 0.9969\n",
      "Epoch 128: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 16ms/step - accuracy: 0.9969 - loss: 0.0205 - precision: 0.9977 - recall: 0.9946 - val_accuracy: 0.6852 - val_loss: 0.2564 - val_precision: 0.6981 - val_recall: 0.6852 - learning_rate: 7.5000e-05\n",
      "Epoch 129/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9969 - loss: 0.0199 - precision: 0.9969 - recall: 0.9969\n",
      "Epoch 129: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 21ms/step - accuracy: 0.9969 - loss: 0.0199 - precision: 0.9969 - recall: 0.9969 - val_accuracy: 0.6852 - val_loss: 0.2460 - val_precision: 0.6981 - val_recall: 0.6852 - learning_rate: 7.5000e-05\n",
      "Epoch 130/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9978 - loss: 0.0196 - precision: 0.9978 - recall: 0.9962\n",
      "Epoch 130: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 14ms/step - accuracy: 0.9992 - loss: 0.0195 - precision: 0.9992 - recall: 0.9985 - val_accuracy: 0.6852 - val_loss: 0.2431 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 7.5000e-05\n",
      "Epoch 131/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 12ms/step - accuracy: 0.9995 - loss: 0.0191 - precision: 0.9997 - recall: 0.9995\n",
      "Epoch 131: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9985 - loss: 0.0191 - precision: 0.9992 - recall: 0.9985 - val_accuracy: 0.7037 - val_loss: 0.2394 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 7.5000e-05\n",
      "Epoch 132/300\n",
      "\u001b[1m39/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 17ms/step - accuracy: 0.9974 - loss: 0.0192 - precision: 0.9974 - recall: 0.9964\n",
      "Epoch 132: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 25ms/step - accuracy: 0.9992 - loss: 0.0190 - precision: 0.9992 - recall: 0.9985 - val_accuracy: 0.6852 - val_loss: 0.2425 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 7.5000e-05\n",
      "Epoch 133/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 22ms/step - accuracy: 0.9970 - loss: 0.0190 - precision: 0.9980 - recall: 0.9970\n",
      "Epoch 133: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 30ms/step - accuracy: 0.9977 - loss: 0.0190 - precision: 0.9985 - recall: 0.9977 - val_accuracy: 0.6852 - val_loss: 0.2491 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 7.5000e-05\n",
      "Epoch 134/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9936 - loss: 0.0195 - precision: 0.9936 - recall: 0.9923\n",
      "Epoch 134: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9969 - loss: 0.0189 - precision: 0.9969 - recall: 0.9954 - val_accuracy: 0.6852 - val_loss: 0.2420 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 7.5000e-05\n",
      "Epoch 135/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9963 - loss: 0.0184 - precision: 0.9963 - recall: 0.9948\n",
      "Epoch 135: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 15ms/step - accuracy: 0.9969 - loss: 0.0184 - precision: 0.9969 - recall: 0.9961 - val_accuracy: 0.7037 - val_loss: 0.2300 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 7.5000e-05\n",
      "Epoch 136/300\n",
      "\u001b[1m38/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”â”\u001b[0m \u001b[1m0s\u001b[0m 16ms/step - accuracy: 0.9962 - loss: 0.0185 - precision: 0.9962 - recall: 0.9962\n",
      "Epoch 136: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9985 - loss: 0.0181 - precision: 0.9985 - recall: 0.9985 - val_accuracy: 0.6667 - val_loss: 0.2606 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 7.5000e-05\n",
      "Epoch 137/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 13ms/step - accuracy: 0.9975 - loss: 0.0179 - precision: 0.9979 - recall: 0.9973\n",
      "Epoch 137: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 20ms/step - accuracy: 0.9985 - loss: 0.0178 - precision: 0.9992 - recall: 0.9977 - val_accuracy: 0.6852 - val_loss: 0.2463 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 7.5000e-05\n",
      "Epoch 138/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 18ms/step - accuracy: 0.9971 - loss: 0.0177 - precision: 0.9981 - recall: 0.9971\n",
      "Epoch 138: val_loss did not improve from 0.17836\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 23ms/step - accuracy: 0.9977 - loss: 0.0177 - precision: 0.9985 - recall: 0.9977 - val_accuracy: 0.6852 - val_loss: 0.2232 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 7.5000e-05\n",
      "Epoch 138: early stopping\n",
      "Restoring model weights from the end of the best epoch: 103.\n",
      "\n",
      "âœ“ CNN model training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train CNN model\n",
    "print(\"\\nğŸš€ Training CNN model...\")\n",
    "\n",
    "Path('models').mkdir(exist_ok=True)\n",
    "\n",
    "cnn_callbacks = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=35,  # Increased patience for 300 epochs\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=12,  # Increased patience\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath='models/cnn_best.weights.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_cnn = cnn_model.fit(\n",
    "    X_cnn_train_aug, y_cnn_train_aug,\n",
    "    validation_data=(X_cnn_val_scaled, y_cnn_val_onehot),\n",
    "    epochs=300,  # Increased from 150 to 300\n",
    "    batch_size=32,\n",
    "    class_weight=cnn_class_weight_dict,\n",
    "    callbacks=cnn_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ CNN model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c9f59ccf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Evaluating CNN model...\n",
      "\u001b[1m11/11\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m1s\u001b[0m 53ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step\n",
      "\n",
      "================================================================================\n",
      "CNN MODEL RESULTS\n",
      "================================================================================\n",
      "\n",
      "Train Set:\n",
      "  Accuracy:  0.9969\n",
      "  Precision: 0.9969\n",
      "  Recall:    0.9969\n",
      "  F1-Score:  0.9969\n",
      "\n",
      "Validation Set:\n",
      "  Accuracy:  0.7037\n",
      "  Precision: 0.7333\n",
      "  Recall:    0.7037\n",
      "  F1-Score:  0.6667\n",
      "\n",
      "Test Set:\n",
      "  Accuracy:  0.7407\n",
      "  Precision: 0.7831\n",
      "  Recall:    0.7407\n",
      "  F1-Score:  0.7285\n",
      "\n",
      "\n",
      "Test Set Confusion Matrix:\n",
      "[[17  1  0]\n",
      " [ 0 16  2]\n",
      " [ 0 11  7]]\n",
      "\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       1.00      0.94      0.97        18\n",
      "      Medium       0.57      0.89      0.70        18\n",
      "        High       0.78      0.39      0.52        18\n",
      "\n",
      "    accuracy                           0.74        54\n",
      "   macro avg       0.78      0.74      0.73        54\n",
      "weighted avg       0.78      0.74      0.73        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate CNN model\n",
    "print(\"\\nğŸ“Š Evaluating CNN model...\")\n",
    "\n",
    "y_cnn_pred_train_probs = cnn_model.predict(X_cnn_train_scaled)\n",
    "y_cnn_pred_val_probs = cnn_model.predict(X_cnn_val_scaled)\n",
    "y_cnn_pred_test_probs = cnn_model.predict(X_cnn_test_scaled)\n",
    "\n",
    "y_cnn_pred_train = np.argmax(y_cnn_pred_train_probs, axis=1)\n",
    "y_cnn_pred_val = np.argmax(y_cnn_pred_val_probs, axis=1)\n",
    "y_cnn_pred_test = np.argmax(y_cnn_pred_test_probs, axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CNN MODEL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for split_name, y_true, y_pred in [\n",
    "    ('Train', y_cnn_train_cat, y_cnn_pred_train),\n",
    "    ('Validation', y_cnn_val_cat, y_cnn_pred_val),\n",
    "    ('Test', y_cnn_test_cat, y_cnn_pred_test)\n",
    "]:\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{split_name} Set:\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(\"\\n\\nTest Set Confusion Matrix:\")\n",
    "print(confusion_matrix(y_cnn_test_cat, y_cnn_pred_test))\n",
    "\n",
    "print(\"\\n\\nTest Set Classification Report:\")\n",
    "print(classification_report(y_cnn_test_cat, y_cnn_pred_test, \n",
    "                          target_names=['Low', 'Medium', 'High']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b4b0b024",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 2: GRU Model (Gated Recurrent Unit)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "81959e86",
   "metadata": {},
   "source": [
    "### What is GRU?\n",
    "\n",
    "GRU is a recurrent neural network (RNN) variant that maintains hidden state across time steps. Compared to LSTM:\n",
    "- **Fewer parameters** (2 gates vs 3 in LSTM)\n",
    "- **Faster training**\n",
    "- **Better for smaller datasets**\n",
    "- **Less prone to overfitting**\n",
    "\n",
    "**Why GRU for crop yield?**\n",
    "- Captures sequential dependencies (how previous months affect current growth)\n",
    "- Lighter than LSTM, better suited for 576 training samples\n",
    "- Bidirectional GRU sees both past and future context"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "a0d7c9c6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PART 2: GRU MODEL\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Loading GRU data...\n",
      "  Total GRU features: 28\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART 2: GRU MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load GRU data (same as CNN)\n",
    "print(\"\\nğŸ“Š Loading GRU data...\")\n",
    "gru_train = pd.read_csv(splits_path / 'gru' / 'train.csv')\n",
    "gru_val = pd.read_csv(splits_path / 'gru' / 'val.csv')\n",
    "gru_test = pd.read_csv(splits_path / 'gru' / 'test.csv')\n",
    "\n",
    "# Remove missing yields\n",
    "gru_train = gru_train.dropna(subset=[target_col])\n",
    "gru_val = gru_val.dropna(subset=[target_col])\n",
    "gru_test = gru_test.dropna(subset=[target_col])\n",
    "\n",
    "# Encode categorical\n",
    "gru_train['Crop_encoded'] = crop_encoder.transform(gru_train['Crop'])\n",
    "gru_train['Region_encoded'] = region_encoder.transform(gru_train['Region'])\n",
    "gru_val['Crop_encoded'] = crop_encoder.transform(gru_val['Crop'])\n",
    "gru_val['Region_encoded'] = region_encoder.transform(gru_val['Region'])\n",
    "gru_test['Crop_encoded'] = crop_encoder.transform(gru_test['Crop'])\n",
    "gru_test['Region_encoded'] = region_encoder.transform(gru_test['Region'])\n",
    "\n",
    "gru_all_features = gru_feature_cols + ['Crop_encoded', 'Region_encoded']\n",
    "\n",
    "print(f\"  Total GRU features: {len(gru_all_features)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "f96d5686",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Creating sequences for GRU...\n",
      "\n",
      "  Train sequences: (324, 12, 28)\n",
      "  Val sequences:   (54, 12, 28)\n",
      "  Test sequences:  (54, 12, 28)\n",
      "  âœ“ Features normalized\n"
     ]
    }
   ],
   "source": [
    "# Create sequences for GRU\n",
    "print(\"\\nğŸ“Š Creating sequences for GRU...\")\n",
    "\n",
    "X_gru_train, y_gru_train = create_sequences(gru_train, gru_all_features, target_col, sequence_length)\n",
    "X_gru_val, y_gru_val = create_sequences(gru_val, gru_all_features, target_col, sequence_length)\n",
    "X_gru_test, y_gru_test = create_sequences(gru_test, gru_all_features, target_col, sequence_length)\n",
    "\n",
    "print(f\"\\n  Train sequences: {X_gru_train.shape}\")\n",
    "print(f\"  Val sequences:   {X_gru_val.shape}\")\n",
    "print(f\"  Test sequences:  {X_gru_test.shape}\")\n",
    "\n",
    "# Normalize\n",
    "scaler_gru = StandardScaler()\n",
    "X_gru_train_reshaped = X_gru_train.reshape(-1, X_gru_train.shape[2])\n",
    "scaler_gru.fit(X_gru_train_reshaped)\n",
    "\n",
    "X_gru_train_scaled = scaler_gru.transform(X_gru_train.reshape(-1, X_gru_train.shape[2])).reshape(X_gru_train.shape)\n",
    "X_gru_val_scaled = scaler_gru.transform(X_gru_val.reshape(-1, X_gru_val.shape[2])).reshape(X_gru_val.shape)\n",
    "X_gru_test_scaled = scaler_gru.transform(X_gru_test.reshape(-1, X_gru_test.shape[2])).reshape(X_gru_test.shape)\n",
    "\n",
    "print(\"  âœ“ Features normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "7e8ce819",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Categorizing yields for GRU...\n",
      "\n",
      "Class distribution (GRU Train):\n",
      "  Class 0: 108 samples (33.3%)\n",
      "  Class 1: 108 samples (33.3%)\n",
      "  Class 2: 108 samples (33.3%)\n"
     ]
    }
   ],
   "source": [
    "# Categorize yields\n",
    "print(\"\\nğŸ“Š Categorizing yields for GRU...\")\n",
    "\n",
    "y_gru_train_cat, gru_percentiles = categorize_yield_balanced(y_gru_train, method='percentile')\n",
    "y_gru_val_cat, _ = categorize_yield_balanced(y_gru_val, method='percentile')\n",
    "y_gru_test_cat, _ = categorize_yield_balanced(y_gru_test, method='percentile')\n",
    "\n",
    "print(f\"\\nClass distribution (GRU Train):\")\n",
    "unique, counts = np.unique(y_gru_train_cat, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"  Class {cls}: {count} samples ({count/len(y_gru_train_cat)*100:.1f}%)\")\n",
    "\n",
    "y_gru_train_onehot = to_categorical(y_gru_train_cat, num_classes=3)\n",
    "y_gru_val_onehot = to_categorical(y_gru_val_cat, num_classes=3)\n",
    "y_gru_test_onehot = to_categorical(y_gru_test_cat, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "3443627b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ APPLYING DATA AUGMENTATION (GRU)...\n",
      "  Augmented GRU training size: 1296 samples\n",
      "\n",
      "âš–ï¸  GRU Class weights:\n",
      "   Class 0: weight=1.000 (n=432 samples)\n",
      "   Class 1: weight=1.000 (n=432 samples)\n",
      "   Class 2: weight=1.000 (n=432 samples)\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation for GRU\n",
    "print(\"\\nğŸ”„ APPLYING DATA AUGMENTATION (GRU)...\")\n",
    "\n",
    "X_gru_train_aug, y_gru_train_aug = augment_time_series(\n",
    "    X_gru_train_scaled,\n",
    "    y_gru_train_onehot,\n",
    "    num_augmented=3,  # Increased from 1 to 3\n",
    "    noise_level=0.02  # Reduced noise for quality\n",
    ")\n",
    "\n",
    "print(f\"  Augmented GRU training size: {X_gru_train_aug.shape[0]} samples\")\n",
    "\n",
    "# Shuffle\n",
    "indices = np.random.permutation(X_gru_train_aug.shape[0])\n",
    "X_gru_train_aug = X_gru_train_aug[indices]\n",
    "y_gru_train_aug = y_gru_train_aug[indices]\n",
    "\n",
    "# Class weights\n",
    "y_gru_train_labels = np.argmax(y_gru_train_aug, axis=1)\n",
    "gru_class_weights_array = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_gru_train_labels),\n",
    "    y=y_gru_train_labels\n",
    ")\n",
    "gru_class_weight_dict = dict(enumerate(gru_class_weights_array))\n",
    "\n",
    "print(f\"\\nâš–ï¸  GRU Class weights:\")\n",
    "for cls, weight in gru_class_weight_dict.items():\n",
    "    count = np.sum(y_gru_train_labels == cls)\n",
    "    print(f\"   Class {cls}: weight={weight:.3f} (n={count} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "bad9815c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)                    </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape           </span>â”ƒ<span style=\"font-weight: bold\">       Param # </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ bidirectional (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">72,576</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_5           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_6           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)        â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">31,104</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_7           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,160</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_8           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚           <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalization</span>)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">2,080</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">32</span>)             â”‚             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)              â”‚            <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ bidirectional (\u001b[38;5;33mBidirectional\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m192\u001b[0m)        â”‚        \u001b[38;5;34m72,576\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_5           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m192\u001b[0m)        â”‚           \u001b[38;5;34m768\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_6 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m192\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_1 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚        \u001b[38;5;34m99,072\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_6           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚           \u001b[38;5;34m512\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_7 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m128\u001b[0m)        â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_2 (\u001b[38;5;33mBidirectional\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚        \u001b[38;5;34m31,104\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_7           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_8 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚         \u001b[38;5;34m4,160\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization_8           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚           \u001b[38;5;34m256\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalization\u001b[0m)            â”‚                        â”‚               â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_9 (\u001b[38;5;33mDropout\u001b[0m)             â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_5 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚         \u001b[38;5;34m2,080\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_10 (\u001b[38;5;33mDropout\u001b[0m)            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m32\u001b[0m)             â”‚             \u001b[38;5;34m0\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_6 (\u001b[38;5;33mDense\u001b[0m)                 â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)              â”‚            \u001b[38;5;34m99\u001b[0m â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">210,883</span> (823.76 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m210,883\u001b[0m (823.76 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">209,987</span> (820.26 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m209,987\u001b[0m (820.26 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">896</span> (3.50 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m896\u001b[0m (3.50 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build GRU model with Attention\n",
    "def build_gru_model(sequence_length, n_features, learning_rate=0.0003):\n",
    "    \"\"\"\n",
    "    Build Bidirectional GRU model with attention.\n",
    "    \n",
    "    Architecture:\n",
    "    - Bidirectional GRU layers capture forward and backward patterns\n",
    "    - Attention mechanism for focusing on key time steps\n",
    "    - Enhanced regularization to prevent overfitting\n",
    "    \"\"\"\n",
    "    model = models.Sequential([\n",
    "        layers.Input(shape=(sequence_length, n_features)),\n",
    "        \n",
    "        # First Bidirectional GRU layer\n",
    "        layers.Bidirectional(layers.GRU(96, return_sequences=True,\n",
    "                                       kernel_regularizer=regularizers.l2(0.003),\n",
    "                                       recurrent_regularizer=regularizers.l2(0.003),\n",
    "                                       dropout=0.3,\n",
    "                                       recurrent_dropout=0.3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Second Bidirectional GRU layer\n",
    "        layers.Bidirectional(layers.GRU(64, return_sequences=True,\n",
    "                                       kernel_regularizer=regularizers.l2(0.003),\n",
    "                                       recurrent_regularizer=regularizers.l2(0.003),\n",
    "                                       dropout=0.3,\n",
    "                                       recurrent_dropout=0.3)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.5),\n",
    "        \n",
    "        # Third GRU layer\n",
    "        layers.Bidirectional(layers.GRU(32, return_sequences=False,\n",
    "                                       kernel_regularizer=regularizers.l2(0.002),\n",
    "                                       recurrent_regularizer=regularizers.l2(0.002),\n",
    "                                       dropout=0.2,\n",
    "                                       recurrent_dropout=0.2)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        # Dense layers\n",
    "        layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.002)),\n",
    "        layers.BatchNormalization(),\n",
    "        layers.Dropout(0.4),\n",
    "        \n",
    "        layers.Dense(32, activation='relu', kernel_regularizer=regularizers.l2(0.001)),\n",
    "        layers.Dropout(0.3),\n",
    "        \n",
    "        # Output layer\n",
    "        layers.Dense(3, activation='softmax')\n",
    "    ])\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate, clipnorm=1.0)\n",
    "    \n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=focal_loss(gamma=2.0, alpha=0.25),\n",
    "        metrics=['accuracy',\n",
    "                 tf.keras.metrics.Precision(name='precision'),\n",
    "                 tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "gru_model = build_gru_model(\n",
    "    sequence_length=sequence_length,\n",
    "    n_features=X_gru_train_aug.shape[2],\n",
    "    learning_rate=0.0003\n",
    ")\n",
    "gru_model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "44a8c1d0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training GRU model...\n",
      "Epoch 1/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.3526 - loss: 3.3977 - precision: 0.3487 - recall: 0.2889\n",
      "Epoch 1: val_loss improved from None to 3.00450, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 1: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m35s\u001b[0m 161ms/step - accuracy: 0.3719 - loss: 3.3163 - precision: 0.3717 - recall: 0.3086 - val_accuracy: 0.6667 - val_loss: 3.0045 - val_precision: 1.0000 - val_recall: 0.0556 - learning_rate: 3.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.3687 - loss: 3.1189 - precision: 0.3751 - recall: 0.2990\n",
      "Epoch 2: val_loss improved from 3.00450 to 2.76385, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 2: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.4012 - loss: 3.0505 - precision: 0.4118 - recall: 0.3295 - val_accuracy: 0.7037 - val_loss: 2.7639 - val_precision: 0.9474 - val_recall: 0.3333 - learning_rate: 3.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.4507 - loss: 2.8436 - precision: 0.4743 - recall: 0.3856\n",
      "Epoch 3: val_loss improved from 2.76385 to 2.55864, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 3: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.4707 - loss: 2.7887 - precision: 0.4901 - recall: 0.4012 - val_accuracy: 0.6481 - val_loss: 2.5586 - val_precision: 0.8235 - val_recall: 0.5185 - learning_rate: 3.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.4852 - loss: 2.6394 - precision: 0.5162 - recall: 0.4139\n",
      "Epoch 4: val_loss improved from 2.55864 to 2.38434, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 4: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.4954 - loss: 2.5872 - precision: 0.5222 - recall: 0.4167 - val_accuracy: 0.6296 - val_loss: 2.3843 - val_precision: 0.6512 - val_recall: 0.5185 - learning_rate: 3.0000e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.5244 - loss: 2.4369 - precision: 0.5434 - recall: 0.4535\n",
      "Epoch 5: val_loss improved from 2.38434 to 2.23953, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 5: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.5386 - loss: 2.3921 - precision: 0.5593 - recall: 0.4583 - val_accuracy: 0.5370 - val_loss: 2.2395 - val_precision: 0.5532 - val_recall: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.5962 - loss: 2.2471 - precision: 0.6310 - recall: 0.5262\n",
      "Epoch 6: val_loss improved from 2.23953 to 2.11524, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 6: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.5779 - loss: 2.2147 - precision: 0.6144 - recall: 0.5077 - val_accuracy: 0.5370 - val_loss: 2.1152 - val_precision: 0.5102 - val_recall: 0.4630 - learning_rate: 3.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.5625 - loss: 2.0953 - precision: 0.6015 - recall: 0.4933\n",
      "Epoch 7: val_loss improved from 2.11524 to 2.00239, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 7: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.5856 - loss: 2.0604 - precision: 0.6338 - recall: 0.5262 - val_accuracy: 0.4815 - val_loss: 2.0024 - val_precision: 0.5000 - val_recall: 0.4630 - learning_rate: 3.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.6739 - loss: 1.9512 - precision: 0.6960 - recall: 0.5873\n",
      "Epoch 8: val_loss improved from 2.00239 to 1.89362, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 8: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6590 - loss: 1.9218 - precision: 0.6837 - recall: 0.5872 - val_accuracy: 0.5185 - val_loss: 1.8936 - val_precision: 0.5294 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.6426 - loss: 1.8401 - precision: 0.6668 - recall: 0.5577\n",
      "Epoch 9: val_loss improved from 1.89362 to 1.78390, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 9: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 81ms/step - accuracy: 0.6397 - loss: 1.8124 - precision: 0.6673 - recall: 0.5633 - val_accuracy: 0.5556 - val_loss: 1.7839 - val_precision: 0.5490 - val_recall: 0.5185 - learning_rate: 3.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.6309 - loss: 1.7371 - precision: 0.6639 - recall: 0.5662\n",
      "Epoch 10: val_loss improved from 1.78390 to 1.69355, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 10: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.6458 - loss: 1.7109 - precision: 0.6854 - recall: 0.5833 - val_accuracy: 0.5000 - val_loss: 1.6936 - val_precision: 0.5192 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.6809 - loss: 1.6309 - precision: 0.7101 - recall: 0.6166\n",
      "Epoch 11: val_loss improved from 1.69355 to 1.59912, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 11: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.6744 - loss: 1.6107 - precision: 0.7008 - recall: 0.6019 - val_accuracy: 0.5185 - val_loss: 1.5991 - val_precision: 0.5200 - val_recall: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.6547 - loss: 1.5490 - precision: 0.6980 - recall: 0.6058\n",
      "Epoch 12: val_loss improved from 1.59912 to 1.54007, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 12: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 84ms/step - accuracy: 0.6582 - loss: 1.5321 - precision: 0.7012 - recall: 0.6011 - val_accuracy: 0.4815 - val_loss: 1.5401 - val_precision: 0.4717 - val_recall: 0.4630 - learning_rate: 3.0000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6821 - loss: 1.4638 - precision: 0.7069 - recall: 0.6092\n",
      "Epoch 13: val_loss improved from 1.54007 to 1.45919, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 13: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.6790 - loss: 1.4465 - precision: 0.7103 - recall: 0.6111 - val_accuracy: 0.5000 - val_loss: 1.4592 - val_precision: 0.4800 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.6942 - loss: 1.3938 - precision: 0.7290 - recall: 0.6270\n",
      "Epoch 14: val_loss improved from 1.45919 to 1.40119, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 14: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 0.6952 - loss: 1.3752 - precision: 0.7236 - recall: 0.6242 - val_accuracy: 0.5000 - val_loss: 1.4012 - val_precision: 0.4902 - val_recall: 0.4630 - learning_rate: 3.0000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.6834 - loss: 1.3283 - precision: 0.7244 - recall: 0.6309\n",
      "Epoch 15: val_loss improved from 1.40119 to 1.33611, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 15: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.6767 - loss: 1.3158 - precision: 0.7123 - recall: 0.6188 - val_accuracy: 0.4815 - val_loss: 1.3361 - val_precision: 0.4906 - val_recall: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.6995 - loss: 1.2598 - precision: 0.7283 - recall: 0.6399\n",
      "Epoch 16: val_loss improved from 1.33611 to 1.28329, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 16: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.6960 - loss: 1.2466 - precision: 0.7237 - recall: 0.6327 - val_accuracy: 0.5000 - val_loss: 1.2833 - val_precision: 0.4808 - val_recall: 0.4630 - learning_rate: 3.0000e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7015 - loss: 1.2051 - precision: 0.7320 - recall: 0.6294\n",
      "Epoch 17: val_loss improved from 1.28329 to 1.22672, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 17: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.6937 - loss: 1.1952 - precision: 0.7225 - recall: 0.6327 - val_accuracy: 0.5000 - val_loss: 1.2267 - val_precision: 0.4906 - val_recall: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.7349 - loss: 1.1479 - precision: 0.7678 - recall: 0.6780\n",
      "Epoch 18: val_loss improved from 1.22672 to 1.17991, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 18: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.7299 - loss: 1.1352 - precision: 0.7646 - recall: 0.6667 - val_accuracy: 0.4815 - val_loss: 1.1799 - val_precision: 0.4808 - val_recall: 0.4630 - learning_rate: 3.0000e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.7236 - loss: 1.1009 - precision: 0.7441 - recall: 0.6513\n",
      "Epoch 19: val_loss improved from 1.17991 to 1.11282, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 19: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 74ms/step - accuracy: 0.7222 - loss: 1.0905 - precision: 0.7420 - recall: 0.6481 - val_accuracy: 0.5000 - val_loss: 1.1128 - val_precision: 0.5094 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.6956 - loss: 1.0574 - precision: 0.7323 - recall: 0.6393\n",
      "Epoch 20: val_loss improved from 1.11282 to 1.08504, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 20: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.7114 - loss: 1.0449 - precision: 0.7436 - recall: 0.6489 - val_accuracy: 0.5000 - val_loss: 1.0850 - val_precision: 0.5000 - val_recall: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.7341 - loss: 1.0032 - precision: 0.7507 - recall: 0.6555\n",
      "Epoch 21: val_loss improved from 1.08504 to 1.04275, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 21: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.7292 - loss: 0.9935 - precision: 0.7520 - recall: 0.6551 - val_accuracy: 0.4815 - val_loss: 1.0428 - val_precision: 0.4808 - val_recall: 0.4630 - learning_rate: 3.0000e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.7278 - loss: 0.9618 - precision: 0.7608 - recall: 0.6852\n",
      "Epoch 22: val_loss improved from 1.04275 to 0.98508, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 22: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.7168 - loss: 0.9573 - precision: 0.7472 - recall: 0.6775 - val_accuracy: 0.5185 - val_loss: 0.9851 - val_precision: 0.5094 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7482 - loss: 0.9205 - precision: 0.7861 - recall: 0.6871\n",
      "Epoch 23: val_loss improved from 0.98508 to 0.94959, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 23: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 69ms/step - accuracy: 0.7454 - loss: 0.9129 - precision: 0.7709 - recall: 0.6906 - val_accuracy: 0.5000 - val_loss: 0.9496 - val_precision: 0.5000 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.7415 - loss: 0.8842 - precision: 0.7685 - recall: 0.6899\n",
      "Epoch 24: val_loss improved from 0.94959 to 0.89683, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 24: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.7384 - loss: 0.8757 - precision: 0.7646 - recall: 0.6890 - val_accuracy: 0.5000 - val_loss: 0.8968 - val_precision: 0.5094 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.7921 - loss: 0.8445 - precision: 0.8072 - recall: 0.7202\n",
      "Epoch 25: val_loss improved from 0.89683 to 0.86000, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 25: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.7755 - loss: 0.8390 - precision: 0.7885 - recall: 0.7076 - val_accuracy: 0.5185 - val_loss: 0.8600 - val_precision: 0.5094 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7641 - loss: 0.8101 - precision: 0.7890 - recall: 0.6949\n",
      "Epoch 26: val_loss improved from 0.86000 to 0.82576, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 26: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.7593 - loss: 0.8059 - precision: 0.7820 - recall: 0.6921 - val_accuracy: 0.5000 - val_loss: 0.8258 - val_precision: 0.5094 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.7573 - loss: 0.7782 - precision: 0.7877 - recall: 0.7062\n",
      "Epoch 27: val_loss improved from 0.82576 to 0.79400, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 27: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.7569 - loss: 0.7721 - precision: 0.7849 - recall: 0.7037 - val_accuracy: 0.5000 - val_loss: 0.7940 - val_precision: 0.5000 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.7512 - loss: 0.7544 - precision: 0.7931 - recall: 0.7093\n",
      "Epoch 28: val_loss improved from 0.79400 to 0.76340, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 28: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.7531 - loss: 0.7457 - precision: 0.7833 - recall: 0.7114 - val_accuracy: 0.5000 - val_loss: 0.7634 - val_precision: 0.5000 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.7651 - loss: 0.7170 - precision: 0.8012 - recall: 0.7112\n",
      "Epoch 29: val_loss improved from 0.76340 to 0.73955, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 29: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.7778 - loss: 0.7109 - precision: 0.8101 - recall: 0.7207 - val_accuracy: 0.5370 - val_loss: 0.7396 - val_precision: 0.5370 - val_recall: 0.5370 - learning_rate: 3.0000e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7383 - loss: 0.6950 - precision: 0.7511 - recall: 0.6804\n",
      "Epoch 30: val_loss improved from 0.73955 to 0.70672, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 30: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 95ms/step - accuracy: 0.7523 - loss: 0.6879 - precision: 0.7691 - recall: 0.6914 - val_accuracy: 0.5185 - val_loss: 0.7067 - val_precision: 0.5185 - val_recall: 0.5185 - learning_rate: 3.0000e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.7497 - loss: 0.6652 - precision: 0.7831 - recall: 0.6994\n",
      "Epoch 31: val_loss improved from 0.70672 to 0.68374, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 31: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 96ms/step - accuracy: 0.7600 - loss: 0.6593 - precision: 0.7864 - recall: 0.7045 - val_accuracy: 0.5000 - val_loss: 0.6837 - val_precision: 0.5000 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.7871 - loss: 0.6372 - precision: 0.8153 - recall: 0.7352\n",
      "Epoch 32: val_loss improved from 0.68374 to 0.66290, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 32: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 106ms/step - accuracy: 0.7855 - loss: 0.6305 - precision: 0.8133 - recall: 0.7361 - val_accuracy: 0.4630 - val_loss: 0.6629 - val_precision: 0.4615 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.7824 - loss: 0.6125 - precision: 0.8031 - recall: 0.7295\n",
      "Epoch 33: val_loss improved from 0.66290 to 0.64323, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 33: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 94ms/step - accuracy: 0.7762 - loss: 0.6086 - precision: 0.8032 - recall: 0.7276 - val_accuracy: 0.4630 - val_loss: 0.6432 - val_precision: 0.4630 - val_recall: 0.4630 - learning_rate: 3.0000e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.7836 - loss: 0.5856 - precision: 0.8168 - recall: 0.7121\n",
      "Epoch 34: val_loss improved from 0.64323 to 0.60834, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 34: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7832 - loss: 0.5846 - precision: 0.8074 - recall: 0.7245 - val_accuracy: 0.5000 - val_loss: 0.6083 - val_precision: 0.4906 - val_recall: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.7797 - loss: 0.5645 - precision: 0.8065 - recall: 0.7349\n",
      "Epoch 35: val_loss improved from 0.60834 to 0.60401, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 35: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 90ms/step - accuracy: 0.7793 - loss: 0.5618 - precision: 0.8095 - recall: 0.7346 - val_accuracy: 0.4444 - val_loss: 0.6040 - val_precision: 0.4340 - val_recall: 0.4259 - learning_rate: 3.0000e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.7900 - loss: 0.5383 - precision: 0.8160 - recall: 0.7287\n",
      "Epoch 36: val_loss improved from 0.60401 to 0.58653, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 36: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.7840 - loss: 0.5343 - precision: 0.8038 - recall: 0.7269 - val_accuracy: 0.4259 - val_loss: 0.5865 - val_precision: 0.4340 - val_recall: 0.4259 - learning_rate: 3.0000e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 133ms/step - accuracy: 0.8056 - loss: 0.5218 - precision: 0.8219 - recall: 0.7423\n",
      "Epoch 37: val_loss improved from 0.58653 to 0.55897, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 37: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 149ms/step - accuracy: 0.7909 - loss: 0.5204 - precision: 0.8134 - recall: 0.7330 - val_accuracy: 0.4444 - val_loss: 0.5590 - val_precision: 0.4340 - val_recall: 0.4259 - learning_rate: 3.0000e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.7563 - loss: 0.5088 - precision: 0.7834 - recall: 0.7147\n",
      "Epoch 38: val_loss improved from 0.55897 to 0.53267, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 38: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - accuracy: 0.7701 - loss: 0.5033 - precision: 0.7944 - recall: 0.7215 - val_accuracy: 0.4815 - val_loss: 0.5327 - val_precision: 0.4706 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.7776 - loss: 0.4832 - precision: 0.8098 - recall: 0.7208\n",
      "Epoch 39: val_loss improved from 0.53267 to 0.51677, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 39: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.7755 - loss: 0.4803 - precision: 0.8024 - recall: 0.7207 - val_accuracy: 0.5185 - val_loss: 0.5168 - val_precision: 0.5192 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 155ms/step - accuracy: 0.7892 - loss: 0.4670 - precision: 0.8269 - recall: 0.7469\n",
      "Epoch 40: val_loss improved from 0.51677 to 0.48875, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 40: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 170ms/step - accuracy: 0.7724 - loss: 0.4639 - precision: 0.8084 - recall: 0.7292 - val_accuracy: 0.4630 - val_loss: 0.4888 - val_precision: 0.4510 - val_recall: 0.4259 - learning_rate: 3.0000e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8100 - loss: 0.4491 - precision: 0.8261 - recall: 0.7532\n",
      "Epoch 41: val_loss improved from 0.48875 to 0.48625, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 41: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 114ms/step - accuracy: 0.8063 - loss: 0.4496 - precision: 0.8246 - recall: 0.7508 - val_accuracy: 0.4444 - val_loss: 0.4863 - val_precision: 0.4400 - val_recall: 0.4074 - learning_rate: 3.0000e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m40/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.7818 - loss: 0.4329 - precision: 0.8095 - recall: 0.7304\n",
      "Epoch 42: val_loss improved from 0.48625 to 0.45499, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 42: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.7832 - loss: 0.4326 - precision: 0.8145 - recall: 0.7353 - val_accuracy: 0.4630 - val_loss: 0.4550 - val_precision: 0.4808 - val_recall: 0.4630 - learning_rate: 3.0000e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8129 - loss: 0.4137 - precision: 0.8332 - recall: 0.7481\n",
      "Epoch 43: val_loss improved from 0.45499 to 0.44132, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 43: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.8032 - loss: 0.4116 - precision: 0.8296 - recall: 0.7515 - val_accuracy: 0.5000 - val_loss: 0.4413 - val_precision: 0.5200 - val_recall: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8145 - loss: 0.4004 - precision: 0.8398 - recall: 0.7476\n",
      "Epoch 44: val_loss improved from 0.44132 to 0.43069, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 44: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 85ms/step - accuracy: 0.7924 - loss: 0.3992 - precision: 0.8222 - recall: 0.7315 - val_accuracy: 0.4444 - val_loss: 0.4307 - val_precision: 0.4340 - val_recall: 0.4259 - learning_rate: 3.0000e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8064 - loss: 0.3856 - precision: 0.8380 - recall: 0.7626\n",
      "Epoch 45: val_loss improved from 0.43069 to 0.41427, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 45: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.8032 - loss: 0.3824 - precision: 0.8303 - recall: 0.7623 - val_accuracy: 0.4630 - val_loss: 0.4143 - val_precision: 0.4423 - val_recall: 0.4259 - learning_rate: 3.0000e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.8131 - loss: 0.3703 - precision: 0.8315 - recall: 0.7553\n",
      "Epoch 46: val_loss improved from 0.41427 to 0.38512, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 46: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.8171 - loss: 0.3674 - precision: 0.8390 - recall: 0.7639 - val_accuracy: 0.5556 - val_loss: 0.3851 - val_precision: 0.5385 - val_recall: 0.5185 - learning_rate: 3.0000e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8100 - loss: 0.3536 - precision: 0.8424 - recall: 0.7630\n",
      "Epoch 47: val_loss improved from 0.38512 to 0.38213, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 47: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.8148 - loss: 0.3530 - precision: 0.8405 - recall: 0.7685 - val_accuracy: 0.4630 - val_loss: 0.3821 - val_precision: 0.4706 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8310 - loss: 0.3402 - precision: 0.8593 - recall: 0.7935\n",
      "Epoch 48: val_loss did not improve from 0.38213\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 70ms/step - accuracy: 0.8140 - loss: 0.3393 - precision: 0.8419 - recall: 0.7724 - val_accuracy: 0.4630 - val_loss: 0.3840 - val_precision: 0.4528 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8111 - loss: 0.3302 - precision: 0.8229 - recall: 0.7560\n",
      "Epoch 49: val_loss improved from 0.38213 to 0.35196, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 49: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.7994 - loss: 0.3285 - precision: 0.8198 - recall: 0.7546 - val_accuracy: 0.5370 - val_loss: 0.3520 - val_precision: 0.5192 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8138 - loss: 0.3200 - precision: 0.8354 - recall: 0.7662\n",
      "Epoch 50: val_loss improved from 0.35196 to 0.34527, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 50: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 99ms/step - accuracy: 0.8025 - loss: 0.3183 - precision: 0.8224 - recall: 0.7539 - val_accuracy: 0.4815 - val_loss: 0.3453 - val_precision: 0.5098 - val_recall: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8189 - loss: 0.3034 - precision: 0.8410 - recall: 0.7750\n",
      "Epoch 51: val_loss improved from 0.34527 to 0.34030, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 51: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.8133 - loss: 0.3042 - precision: 0.8388 - recall: 0.7708 - val_accuracy: 0.4630 - val_loss: 0.3403 - val_precision: 0.4615 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8070 - loss: 0.2976 - precision: 0.8239 - recall: 0.7517\n",
      "Epoch 52: val_loss improved from 0.34030 to 0.32878, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 52: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 97ms/step - accuracy: 0.8094 - loss: 0.2959 - precision: 0.8288 - recall: 0.7546 - val_accuracy: 0.5000 - val_loss: 0.3288 - val_precision: 0.5000 - val_recall: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8232 - loss: 0.2840 - precision: 0.8442 - recall: 0.7829\n",
      "Epoch 53: val_loss improved from 0.32878 to 0.31991, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 53: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.8117 - loss: 0.2835 - precision: 0.8346 - recall: 0.7747 - val_accuracy: 0.5000 - val_loss: 0.3199 - val_precision: 0.4902 - val_recall: 0.4630 - learning_rate: 3.0000e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8273 - loss: 0.2716 - precision: 0.8577 - recall: 0.7949\n",
      "Epoch 54: val_loss improved from 0.31991 to 0.31403, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 54: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.8125 - loss: 0.2717 - precision: 0.8463 - recall: 0.7816 - val_accuracy: 0.5370 - val_loss: 0.3140 - val_precision: 0.5192 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8360 - loss: 0.2649 - precision: 0.8656 - recall: 0.7867\n",
      "Epoch 55: val_loss improved from 0.31403 to 0.30890, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 55: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 81ms/step - accuracy: 0.8171 - loss: 0.2644 - precision: 0.8370 - recall: 0.7608 - val_accuracy: 0.4815 - val_loss: 0.3089 - val_precision: 0.4902 - val_recall: 0.4630 - learning_rate: 3.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8438 - loss: 0.2549 - precision: 0.8675 - recall: 0.7974\n",
      "Epoch 56: val_loss improved from 0.30890 to 0.28058, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 56: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.8302 - loss: 0.2539 - precision: 0.8576 - recall: 0.7809 - val_accuracy: 0.5370 - val_loss: 0.2806 - val_precision: 0.5370 - val_recall: 0.5370 - learning_rate: 3.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.8529 - loss: 0.2497 - precision: 0.8704 - recall: 0.8096\n",
      "Epoch 57: val_loss improved from 0.28058 to 0.27928, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 57: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 120ms/step - accuracy: 0.8356 - loss: 0.2452 - precision: 0.8526 - recall: 0.7901 - val_accuracy: 0.5000 - val_loss: 0.2793 - val_precision: 0.5294 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 121ms/step - accuracy: 0.8471 - loss: 0.2367 - precision: 0.8636 - recall: 0.7848\n",
      "Epoch 58: val_loss improved from 0.27928 to 0.27238, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 58: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 134ms/step - accuracy: 0.8318 - loss: 0.2348 - precision: 0.8505 - recall: 0.7855 - val_accuracy: 0.5370 - val_loss: 0.2724 - val_precision: 0.5283 - val_recall: 0.5185 - learning_rate: 3.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.8472 - loss: 0.2257 - precision: 0.8755 - recall: 0.8092\n",
      "Epoch 59: val_loss improved from 0.27238 to 0.25946, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 59: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 104ms/step - accuracy: 0.8326 - loss: 0.2263 - precision: 0.8600 - recall: 0.7963 - val_accuracy: 0.5741 - val_loss: 0.2595 - val_precision: 0.5660 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.8309 - loss: 0.2193 - precision: 0.8545 - recall: 0.7864\n",
      "Epoch 60: val_loss improved from 0.25946 to 0.25529, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 60: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 90ms/step - accuracy: 0.8241 - loss: 0.2187 - precision: 0.8485 - recall: 0.7778 - val_accuracy: 0.5556 - val_loss: 0.2553 - val_precision: 0.5556 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.8294 - loss: 0.2112 - precision: 0.8470 - recall: 0.7982\n",
      "Epoch 61: val_loss improved from 0.25529 to 0.24011, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 61: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 136ms/step - accuracy: 0.8164 - loss: 0.2119 - precision: 0.8355 - recall: 0.7801 - val_accuracy: 0.5741 - val_loss: 0.2401 - val_precision: 0.5882 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8268 - loss: 0.2034 - precision: 0.8616 - recall: 0.8008\n",
      "Epoch 62: val_loss did not improve from 0.24011\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - accuracy: 0.8233 - loss: 0.2035 - precision: 0.8482 - recall: 0.7932 - val_accuracy: 0.5185 - val_loss: 0.2405 - val_precision: 0.5306 - val_recall: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8418 - loss: 0.1979 - precision: 0.8724 - recall: 0.8069\n",
      "Epoch 63: val_loss did not improve from 0.24011\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.8279 - loss: 0.1991 - precision: 0.8557 - recall: 0.7917 - val_accuracy: 0.5185 - val_loss: 0.2503 - val_precision: 0.5192 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8158 - loss: 0.1881 - precision: 0.8450 - recall: 0.7799\n",
      "Epoch 64: val_loss improved from 0.24011 to 0.23306, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 64: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 82ms/step - accuracy: 0.8187 - loss: 0.1896 - precision: 0.8425 - recall: 0.7801 - val_accuracy: 0.5185 - val_loss: 0.2331 - val_precision: 0.5192 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8183 - loss: 0.1860 - precision: 0.8421 - recall: 0.7729\n",
      "Epoch 65: val_loss improved from 0.23306 to 0.21442, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 65: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.8140 - loss: 0.1866 - precision: 0.8297 - recall: 0.7670 - val_accuracy: 0.5926 - val_loss: 0.2144 - val_precision: 0.6038 - val_recall: 0.5926 - learning_rate: 3.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8428 - loss: 0.1778 - precision: 0.8589 - recall: 0.7894\n",
      "Epoch 66: val_loss improved from 0.21442 to 0.20892, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 66: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 91ms/step - accuracy: 0.8387 - loss: 0.1792 - precision: 0.8605 - recall: 0.7948 - val_accuracy: 0.6111 - val_loss: 0.2089 - val_precision: 0.6226 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8143 - loss: 0.1729 - precision: 0.8539 - recall: 0.7693\n",
      "Epoch 67: val_loss improved from 0.20892 to 0.20094, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 67: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 77ms/step - accuracy: 0.8194 - loss: 0.1712 - precision: 0.8517 - recall: 0.7708 - val_accuracy: 0.5185 - val_loss: 0.2009 - val_precision: 0.5000 - val_recall: 0.4630 - learning_rate: 3.0000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8542 - loss: 0.1637 - precision: 0.8826 - recall: 0.8280\n",
      "Epoch 68: val_loss did not improve from 0.20094\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.8457 - loss: 0.1641 - precision: 0.8733 - recall: 0.8140 - val_accuracy: 0.5185 - val_loss: 0.2017 - val_precision: 0.5094 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8370 - loss: 0.1605 - precision: 0.8588 - recall: 0.8038\n",
      "Epoch 69: val_loss improved from 0.20094 to 0.19594, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 69: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.8310 - loss: 0.1608 - precision: 0.8569 - recall: 0.7901 - val_accuracy: 0.5000 - val_loss: 0.1959 - val_precision: 0.5200 - val_recall: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.8381 - loss: 0.1561 - precision: 0.8595 - recall: 0.7984\n",
      "Epoch 70: val_loss improved from 0.19594 to 0.19060, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 70: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 79ms/step - accuracy: 0.8241 - loss: 0.1561 - precision: 0.8498 - recall: 0.7816 - val_accuracy: 0.5741 - val_loss: 0.1906 - val_precision: 0.5660 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.8433 - loss: 0.1515 - precision: 0.8627 - recall: 0.8021\n",
      "Epoch 71: val_loss did not improve from 0.19060\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.8403 - loss: 0.1513 - precision: 0.8652 - recall: 0.8025 - val_accuracy: 0.5185 - val_loss: 0.1924 - val_precision: 0.4902 - val_recall: 0.4630 - learning_rate: 3.0000e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8398 - loss: 0.1445 - precision: 0.8644 - recall: 0.8142\n",
      "Epoch 72: val_loss improved from 0.19060 to 0.18129, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 72: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 82ms/step - accuracy: 0.8318 - loss: 0.1445 - precision: 0.8554 - recall: 0.8032 - val_accuracy: 0.5000 - val_loss: 0.1813 - val_precision: 0.5192 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8501 - loss: 0.1400 - precision: 0.8667 - recall: 0.8112\n",
      "Epoch 73: val_loss did not improve from 0.18129\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 72ms/step - accuracy: 0.8418 - loss: 0.1412 - precision: 0.8599 - recall: 0.8002 - val_accuracy: 0.5370 - val_loss: 0.1868 - val_precision: 0.5472 - val_recall: 0.5370 - learning_rate: 3.0000e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8530 - loss: 0.1364 - precision: 0.8805 - recall: 0.8171\n",
      "Epoch 74: val_loss improved from 0.18129 to 0.17807, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 74: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.8488 - loss: 0.1370 - precision: 0.8705 - recall: 0.8140 - val_accuracy: 0.5556 - val_loss: 0.1781 - val_precision: 0.5385 - val_recall: 0.5185 - learning_rate: 3.0000e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.8503 - loss: 0.1320 - precision: 0.8747 - recall: 0.8138\n",
      "Epoch 75: val_loss did not improve from 0.17807\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.8434 - loss: 0.1328 - precision: 0.8685 - recall: 0.8002 - val_accuracy: 0.4444 - val_loss: 0.1889 - val_precision: 0.4314 - val_recall: 0.4074 - learning_rate: 3.0000e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8682 - loss: 0.1242 - precision: 0.8870 - recall: 0.8107\n",
      "Epoch 76: val_loss did not improve from 0.17807\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.8519 - loss: 0.1266 - precision: 0.8720 - recall: 0.8094 - val_accuracy: 0.5185 - val_loss: 0.1911 - val_precision: 0.5200 - val_recall: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.8427 - loss: 0.1230 - precision: 0.8649 - recall: 0.7823\n",
      "Epoch 77: val_loss improved from 0.17807 to 0.15764, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 77: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.8356 - loss: 0.1244 - precision: 0.8637 - recall: 0.7824 - val_accuracy: 0.5370 - val_loss: 0.1576 - val_precision: 0.5200 - val_recall: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8555 - loss: 0.1179 - precision: 0.8812 - recall: 0.8244\n",
      "Epoch 78: val_loss improved from 0.15764 to 0.14822, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 78: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.8410 - loss: 0.1199 - precision: 0.8666 - recall: 0.8071 - val_accuracy: 0.6111 - val_loss: 0.1482 - val_precision: 0.6038 - val_recall: 0.5926 - learning_rate: 3.0000e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8631 - loss: 0.1123 - precision: 0.8856 - recall: 0.8169\n",
      "Epoch 79: val_loss did not improve from 0.14822\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 80ms/step - accuracy: 0.8573 - loss: 0.1134 - precision: 0.8785 - recall: 0.8148 - val_accuracy: 0.4815 - val_loss: 0.1568 - val_precision: 0.4600 - val_recall: 0.4259 - learning_rate: 3.0000e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.8516 - loss: 0.1070 - precision: 0.8755 - recall: 0.8257\n",
      "Epoch 80: val_loss improved from 0.14822 to 0.14303, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 80: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 80ms/step - accuracy: 0.8526 - loss: 0.1093 - precision: 0.8715 - recall: 0.8218 - val_accuracy: 0.6296 - val_loss: 0.1430 - val_precision: 0.6154 - val_recall: 0.5926 - learning_rate: 3.0000e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.8521 - loss: 0.1072 - precision: 0.8665 - recall: 0.8239\n",
      "Epoch 81: val_loss did not improve from 0.14303\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.8449 - loss: 0.1077 - precision: 0.8629 - recall: 0.8156 - val_accuracy: 0.4444 - val_loss: 0.1483 - val_precision: 0.4340 - val_recall: 0.4259 - learning_rate: 3.0000e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8406 - loss: 0.1042 - precision: 0.8684 - recall: 0.8119\n",
      "Epoch 82: val_loss improved from 0.14303 to 0.12542, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 82: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 89ms/step - accuracy: 0.8457 - loss: 0.1049 - precision: 0.8683 - recall: 0.8140 - val_accuracy: 0.6296 - val_loss: 0.1254 - val_precision: 0.6538 - val_recall: 0.6296 - learning_rate: 3.0000e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 81ms/step - accuracy: 0.8495 - loss: 0.1032 - precision: 0.8694 - recall: 0.8131\n",
      "Epoch 83: val_loss did not improve from 0.12542\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 86ms/step - accuracy: 0.8418 - loss: 0.1035 - precision: 0.8582 - recall: 0.8079 - val_accuracy: 0.5370 - val_loss: 0.1435 - val_precision: 0.5370 - val_recall: 0.5370 - learning_rate: 3.0000e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.8539 - loss: 0.0973 - precision: 0.8767 - recall: 0.8161\n",
      "Epoch 84: val_loss did not improve from 0.12542\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 73ms/step - accuracy: 0.8580 - loss: 0.0975 - precision: 0.8773 - recall: 0.8272 - val_accuracy: 0.6111 - val_loss: 0.1331 - val_precision: 0.6154 - val_recall: 0.5926 - learning_rate: 3.0000e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.8482 - loss: 0.0972 - precision: 0.8723 - recall: 0.8126\n",
      "Epoch 85: val_loss did not improve from 0.12542\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 68ms/step - accuracy: 0.8434 - loss: 0.0964 - precision: 0.8656 - recall: 0.8102 - val_accuracy: 0.6111 - val_loss: 0.1285 - val_precision: 0.6038 - val_recall: 0.5926 - learning_rate: 3.0000e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8510 - loss: 0.0906 - precision: 0.8803 - recall: 0.8196\n",
      "Epoch 86: val_loss did not improve from 0.12542\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 72ms/step - accuracy: 0.8549 - loss: 0.0920 - precision: 0.8791 - recall: 0.8194 - val_accuracy: 0.5556 - val_loss: 0.1333 - val_precision: 0.5660 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8641 - loss: 0.0878 - precision: 0.8790 - recall: 0.8279\n",
      "Epoch 87: val_loss did not improve from 0.12542\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 109ms/step - accuracy: 0.8611 - loss: 0.0874 - precision: 0.8749 - recall: 0.8256 - val_accuracy: 0.6111 - val_loss: 0.1411 - val_precision: 0.6000 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.8532 - loss: 0.0875 - precision: 0.8682 - recall: 0.8182\n",
      "Epoch 88: val_loss did not improve from 0.12542\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 122ms/step - accuracy: 0.8380 - loss: 0.0901 - precision: 0.8550 - recall: 0.8056 - val_accuracy: 0.5741 - val_loss: 0.1394 - val_precision: 0.5660 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8549 - loss: 0.0867 - precision: 0.8682 - recall: 0.8177\n",
      "Epoch 89: val_loss improved from 0.12542 to 0.12028, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 89: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 83ms/step - accuracy: 0.8511 - loss: 0.0852 - precision: 0.8719 - recall: 0.8248 - val_accuracy: 0.5556 - val_loss: 0.1203 - val_precision: 0.5686 - val_recall: 0.5370 - learning_rate: 3.0000e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.8723 - loss: 0.0798 - precision: 0.8926 - recall: 0.8498\n",
      "Epoch 90: val_loss improved from 0.12028 to 0.11735, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 90: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 66ms/step - accuracy: 0.8696 - loss: 0.0804 - precision: 0.8908 - recall: 0.8434 - val_accuracy: 0.6111 - val_loss: 0.1174 - val_precision: 0.6000 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8629 - loss: 0.0810 - precision: 0.8812 - recall: 0.8397\n",
      "Epoch 91: val_loss improved from 0.11735 to 0.10880, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 91: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 77ms/step - accuracy: 0.8526 - loss: 0.0819 - precision: 0.8682 - recall: 0.8233 - val_accuracy: 0.5556 - val_loss: 0.1088 - val_precision: 0.5472 - val_recall: 0.5370 - learning_rate: 3.0000e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.8503 - loss: 0.0794 - precision: 0.8727 - recall: 0.8098\n",
      "Epoch 92: val_loss improved from 0.10880 to 0.10658, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 92: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 75ms/step - accuracy: 0.8549 - loss: 0.0807 - precision: 0.8746 - recall: 0.8179 - val_accuracy: 0.5926 - val_loss: 0.1066 - val_precision: 0.6000 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.8695 - loss: 0.0731 - precision: 0.8862 - recall: 0.8345\n",
      "Epoch 93: val_loss improved from 0.10658 to 0.10086, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 93: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 78ms/step - accuracy: 0.8526 - loss: 0.0762 - precision: 0.8715 - recall: 0.8218 - val_accuracy: 0.5926 - val_loss: 0.1009 - val_precision: 0.5926 - val_recall: 0.5926 - learning_rate: 3.0000e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.8393 - loss: 0.0761 - precision: 0.8673 - recall: 0.8229\n",
      "Epoch 94: val_loss did not improve from 0.10086\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 76ms/step - accuracy: 0.8364 - loss: 0.0771 - precision: 0.8612 - recall: 0.8140 - val_accuracy: 0.5000 - val_loss: 0.1162 - val_precision: 0.4902 - val_recall: 0.4630 - learning_rate: 3.0000e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8616 - loss: 0.0708 - precision: 0.8830 - recall: 0.8312\n",
      "Epoch 95: val_loss improved from 0.10086 to 0.09848, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 95: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 87ms/step - accuracy: 0.8495 - loss: 0.0737 - precision: 0.8732 - recall: 0.8233 - val_accuracy: 0.7037 - val_loss: 0.0985 - val_precision: 0.6981 - val_recall: 0.6852 - learning_rate: 3.0000e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8518 - loss: 0.0714 - precision: 0.8770 - recall: 0.8192\n",
      "Epoch 96: val_loss did not improve from 0.09848\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 93ms/step - accuracy: 0.8426 - loss: 0.0719 - precision: 0.8649 - recall: 0.8148 - val_accuracy: 0.5741 - val_loss: 0.1096 - val_precision: 0.5769 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.8522 - loss: 0.0691 - precision: 0.8760 - recall: 0.8235\n",
      "Epoch 97: val_loss improved from 0.09848 to 0.09786, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 97: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 83ms/step - accuracy: 0.8495 - loss: 0.0702 - precision: 0.8684 - recall: 0.8194 - val_accuracy: 0.6296 - val_loss: 0.0979 - val_precision: 0.6226 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 96ms/step - accuracy: 0.8800 - loss: 0.0637 - precision: 0.8958 - recall: 0.8443\n",
      "Epoch 98: val_loss did not improve from 0.09786\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.8580 - loss: 0.0661 - precision: 0.8780 - recall: 0.8272 - val_accuracy: 0.6111 - val_loss: 0.1063 - val_precision: 0.5918 - val_recall: 0.5370 - learning_rate: 3.0000e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8398 - loss: 0.0683 - precision: 0.8676 - recall: 0.8019\n",
      "Epoch 99: val_loss improved from 0.09786 to 0.09338, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 99: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 118ms/step - accuracy: 0.8526 - loss: 0.0667 - precision: 0.8722 - recall: 0.8110 - val_accuracy: 0.6296 - val_loss: 0.0934 - val_precision: 0.6471 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8600 - loss: 0.0661 - precision: 0.8822 - recall: 0.8324\n",
      "Epoch 100: val_loss did not improve from 0.09338\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 109ms/step - accuracy: 0.8580 - loss: 0.0658 - precision: 0.8762 - recall: 0.8302 - val_accuracy: 0.5926 - val_loss: 0.1004 - val_precision: 0.5926 - val_recall: 0.5926 - learning_rate: 3.0000e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 91ms/step - accuracy: 0.8557 - loss: 0.0646 - precision: 0.8731 - recall: 0.8195\n",
      "Epoch 101: val_loss improved from 0.09338 to 0.09307, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 101: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.8557 - loss: 0.0649 - precision: 0.8741 - recall: 0.8194 - val_accuracy: 0.6296 - val_loss: 0.0931 - val_precision: 0.6346 - val_recall: 0.6111 - learning_rate: 3.0000e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 140ms/step - accuracy: 0.8630 - loss: 0.0616 - precision: 0.8793 - recall: 0.8318\n",
      "Epoch 102: val_loss did not improve from 0.09307\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 161ms/step - accuracy: 0.8534 - loss: 0.0644 - precision: 0.8692 - recall: 0.8202 - val_accuracy: 0.4444 - val_loss: 0.1202 - val_precision: 0.4314 - val_recall: 0.4074 - learning_rate: 3.0000e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 82ms/step - accuracy: 0.8487 - loss: 0.0615 - precision: 0.8670 - recall: 0.8217\n",
      "Epoch 103: val_loss improved from 0.09307 to 0.09179, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 103: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 98ms/step - accuracy: 0.8557 - loss: 0.0619 - precision: 0.8752 - recall: 0.8279 - val_accuracy: 0.5556 - val_loss: 0.0918 - val_precision: 0.5660 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8625 - loss: 0.0602 - precision: 0.8869 - recall: 0.8361\n",
      "Epoch 104: val_loss did not improve from 0.09179\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 100ms/step - accuracy: 0.8542 - loss: 0.0615 - precision: 0.8778 - recall: 0.8256 - val_accuracy: 0.5741 - val_loss: 0.0994 - val_precision: 0.5577 - val_recall: 0.5370 - learning_rate: 3.0000e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8592 - loss: 0.0577 - precision: 0.8737 - recall: 0.8277\n",
      "Epoch 105: val_loss improved from 0.09179 to 0.08424, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 105: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 101ms/step - accuracy: 0.8611 - loss: 0.0581 - precision: 0.8764 - recall: 0.8264 - val_accuracy: 0.6296 - val_loss: 0.0842 - val_precision: 0.6400 - val_recall: 0.5926 - learning_rate: 3.0000e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8747 - loss: 0.0582 - precision: 0.8887 - recall: 0.8404\n",
      "Epoch 106: val_loss improved from 0.08424 to 0.07149, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 106: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 103ms/step - accuracy: 0.8511 - loss: 0.0610 - precision: 0.8660 - recall: 0.8179 - val_accuracy: 0.7222 - val_loss: 0.0715 - val_precision: 0.7308 - val_recall: 0.7037 - learning_rate: 3.0000e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 163ms/step - accuracy: 0.8593 - loss: 0.0567 - precision: 0.8796 - recall: 0.8353\n",
      "Epoch 107: val_loss did not improve from 0.07149\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 176ms/step - accuracy: 0.8480 - loss: 0.0574 - precision: 0.8666 - recall: 0.8218 - val_accuracy: 0.5556 - val_loss: 0.0918 - val_precision: 0.5660 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 180ms/step - accuracy: 0.8533 - loss: 0.0558 - precision: 0.8869 - recall: 0.8301\n",
      "Epoch 108: val_loss did not improve from 0.07149\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 235ms/step - accuracy: 0.8534 - loss: 0.0572 - precision: 0.8809 - recall: 0.8218 - val_accuracy: 0.5926 - val_loss: 0.0919 - val_precision: 0.5882 - val_recall: 0.5556 - learning_rate: 3.0000e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 108ms/step - accuracy: 0.8690 - loss: 0.0539 - precision: 0.8868 - recall: 0.8406\n",
      "Epoch 109: val_loss did not improve from 0.07149\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 112ms/step - accuracy: 0.8611 - loss: 0.0553 - precision: 0.8753 - recall: 0.8287 - val_accuracy: 0.5926 - val_loss: 0.0937 - val_precision: 0.6038 - val_recall: 0.5926 - learning_rate: 3.0000e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 92ms/step - accuracy: 0.8737 - loss: 0.0524 - precision: 0.8874 - recall: 0.8416\n",
      "Epoch 110: val_loss did not improve from 0.07149\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.8642 - loss: 0.0532 - precision: 0.8803 - recall: 0.8341 - val_accuracy: 0.5370 - val_loss: 0.1069 - val_precision: 0.5714 - val_recall: 0.5185 - learning_rate: 3.0000e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 95ms/step - accuracy: 0.8634 - loss: 0.0532 - precision: 0.8827 - recall: 0.8267\n",
      "Epoch 111: val_loss did not improve from 0.07149\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 100ms/step - accuracy: 0.8627 - loss: 0.0533 - precision: 0.8794 - recall: 0.8272 - val_accuracy: 0.5370 - val_loss: 0.1007 - val_precision: 0.5192 - val_recall: 0.5000 - learning_rate: 3.0000e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 128ms/step - accuracy: 0.8760 - loss: 0.0505 - precision: 0.8839 - recall: 0.8347\n",
      "Epoch 112: val_loss did not improve from 0.07149\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 135ms/step - accuracy: 0.8665 - loss: 0.0540 - precision: 0.8817 - recall: 0.8341 - val_accuracy: 0.5556 - val_loss: 0.1091 - val_precision: 0.5577 - val_recall: 0.5370 - learning_rate: 3.0000e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.8682 - loss: 0.0519 - precision: 0.8784 - recall: 0.8428\n",
      "Epoch 113: val_loss did not improve from 0.07149\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 80ms/step - accuracy: 0.8619 - loss: 0.0535 - precision: 0.8728 - recall: 0.8364 - val_accuracy: 0.6111 - val_loss: 0.0884 - val_precision: 0.6078 - val_recall: 0.5741 - learning_rate: 3.0000e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 104ms/step - accuracy: 0.8437 - loss: 0.0504 - precision: 0.8635 - recall: 0.8200\n",
      "Epoch 114: val_loss did not improve from 0.07149\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 113ms/step - accuracy: 0.8565 - loss: 0.0527 - precision: 0.8736 - recall: 0.8264 - val_accuracy: 0.7037 - val_loss: 0.0730 - val_precision: 0.7308 - val_recall: 0.7037 - learning_rate: 3.0000e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 117ms/step - accuracy: 0.8738 - loss: 0.0476 - precision: 0.8910 - recall: 0.8421\n",
      "Epoch 115: val_loss did not improve from 0.07149\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 124ms/step - accuracy: 0.8681 - loss: 0.0502 - precision: 0.8865 - recall: 0.8380 - val_accuracy: 0.5000 - val_loss: 0.0931 - val_precision: 0.4706 - val_recall: 0.4444 - learning_rate: 3.0000e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 151ms/step - accuracy: 0.8645 - loss: 0.0502 - precision: 0.8824 - recall: 0.8427\n",
      "Epoch 116: val_loss did not improve from 0.07149\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 158ms/step - accuracy: 0.8673 - loss: 0.0517 - precision: 0.8805 - recall: 0.8418 - val_accuracy: 0.6667 - val_loss: 0.0851 - val_precision: 0.6604 - val_recall: 0.6481 - learning_rate: 3.0000e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8670 - loss: 0.0492 - precision: 0.8831 - recall: 0.8229\n",
      "Epoch 117: val_loss did not improve from 0.07149\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 108ms/step - accuracy: 0.8611 - loss: 0.0500 - precision: 0.8768 - recall: 0.8241 - val_accuracy: 0.4815 - val_loss: 0.0990 - val_precision: 0.4906 - val_recall: 0.4815 - learning_rate: 3.0000e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8383 - loss: 0.0497 - precision: 0.8669 - recall: 0.8063\n",
      "Epoch 118: ReduceLROnPlateau reducing learning rate to 0.0001500000071246177.\n",
      "\n",
      "Epoch 118: val_loss did not improve from 0.07149\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8326 - loss: 0.0509 - precision: 0.8519 - recall: 0.7986 - val_accuracy: 0.7037 - val_loss: 0.0764 - val_precision: 0.6863 - val_recall: 0.6481 - learning_rate: 3.0000e-04\n",
      "Epoch 119/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 98ms/step - accuracy: 0.8506 - loss: 0.0483 - precision: 0.8734 - recall: 0.8185\n",
      "Epoch 119: val_loss improved from 0.07149 to 0.06933, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 119: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 107ms/step - accuracy: 0.8603 - loss: 0.0484 - precision: 0.8819 - recall: 0.8295 - val_accuracy: 0.7037 - val_loss: 0.0693 - val_precision: 0.6981 - val_recall: 0.6852 - learning_rate: 1.5000e-04\n",
      "Epoch 120/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8809 - loss: 0.0438 - precision: 0.8908 - recall: 0.8529\n",
      "Epoch 120: val_loss did not improve from 0.06933\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - accuracy: 0.8719 - loss: 0.0460 - precision: 0.8853 - recall: 0.8457 - val_accuracy: 0.6852 - val_loss: 0.0696 - val_precision: 0.7059 - val_recall: 0.6667 - learning_rate: 1.5000e-04\n",
      "Epoch 121/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8684 - loss: 0.0454 - precision: 0.8874 - recall: 0.8389\n",
      "Epoch 121: val_loss improved from 0.06933 to 0.06913, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 121: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 104ms/step - accuracy: 0.8704 - loss: 0.0470 - precision: 0.8898 - recall: 0.8472 - val_accuracy: 0.6852 - val_loss: 0.0691 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 1.5000e-04\n",
      "Epoch 122/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 78ms/step - accuracy: 0.8772 - loss: 0.0440 - precision: 0.8922 - recall: 0.8516\n",
      "Epoch 122: val_loss improved from 0.06913 to 0.06853, saving model to models/gru_best.weights.h5\n",
      "\n",
      "Epoch 122: finished saving model to models/gru_best.weights.h5\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.8819 - loss: 0.0458 - precision: 0.8961 - recall: 0.8519 - val_accuracy: 0.6667 - val_loss: 0.0685 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 1.5000e-04\n",
      "Epoch 123/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 103ms/step - accuracy: 0.8770 - loss: 0.0432 - precision: 0.8949 - recall: 0.8436\n",
      "Epoch 123: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 107ms/step - accuracy: 0.8711 - loss: 0.0441 - precision: 0.8902 - recall: 0.8380 - val_accuracy: 0.6481 - val_loss: 0.0713 - val_precision: 0.6538 - val_recall: 0.6296 - learning_rate: 1.5000e-04\n",
      "Epoch 124/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8832 - loss: 0.0426 - precision: 0.8935 - recall: 0.8480\n",
      "Epoch 124: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.8719 - loss: 0.0453 - precision: 0.8825 - recall: 0.8403 - val_accuracy: 0.6111 - val_loss: 0.0727 - val_precision: 0.6078 - val_recall: 0.5741 - learning_rate: 1.5000e-04\n",
      "Epoch 125/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 120ms/step - accuracy: 0.8712 - loss: 0.0419 - precision: 0.8844 - recall: 0.8458\n",
      "Epoch 125: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 129ms/step - accuracy: 0.8696 - loss: 0.0450 - precision: 0.8819 - recall: 0.8410 - val_accuracy: 0.5741 - val_loss: 0.0845 - val_precision: 0.5849 - val_recall: 0.5741 - learning_rate: 1.5000e-04\n",
      "Epoch 126/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.8781 - loss: 0.0408 - precision: 0.8946 - recall: 0.8467\n",
      "Epoch 126: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 119ms/step - accuracy: 0.8735 - loss: 0.0427 - precision: 0.8872 - recall: 0.8434 - val_accuracy: 0.6296 - val_loss: 0.0775 - val_precision: 0.6600 - val_recall: 0.6111 - learning_rate: 1.5000e-04\n",
      "Epoch 127/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 109ms/step - accuracy: 0.8826 - loss: 0.0400 - precision: 0.9016 - recall: 0.8592\n",
      "Epoch 127: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 116ms/step - accuracy: 0.8750 - loss: 0.0417 - precision: 0.8936 - recall: 0.8488 - val_accuracy: 0.6111 - val_loss: 0.0793 - val_precision: 0.6471 - val_recall: 0.6111 - learning_rate: 1.5000e-04\n",
      "Epoch 128/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 101ms/step - accuracy: 0.8852 - loss: 0.0395 - precision: 0.8911 - recall: 0.8512\n",
      "Epoch 128: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - accuracy: 0.8673 - loss: 0.0424 - precision: 0.8767 - recall: 0.8341 - val_accuracy: 0.6296 - val_loss: 0.0824 - val_precision: 0.6346 - val_recall: 0.6111 - learning_rate: 1.5000e-04\n",
      "Epoch 129/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.8672 - loss: 0.0427 - precision: 0.8814 - recall: 0.8416\n",
      "Epoch 129: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 101ms/step - accuracy: 0.8650 - loss: 0.0445 - precision: 0.8811 - recall: 0.8349 - val_accuracy: 0.6667 - val_loss: 0.0883 - val_precision: 0.6667 - val_recall: 0.6296 - learning_rate: 1.5000e-04\n",
      "Epoch 130/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.8471 - loss: 0.0455 - precision: 0.8710 - recall: 0.8193\n",
      "Epoch 130: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.8642 - loss: 0.0443 - precision: 0.8855 - recall: 0.8356 - val_accuracy: 0.6667 - val_loss: 0.0810 - val_precision: 0.6731 - val_recall: 0.6481 - learning_rate: 1.5000e-04\n",
      "Epoch 131/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8752 - loss: 0.0413 - precision: 0.8901 - recall: 0.8439\n",
      "Epoch 131: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.8665 - loss: 0.0431 - precision: 0.8826 - recall: 0.8356 - val_accuracy: 0.5926 - val_loss: 0.0973 - val_precision: 0.5849 - val_recall: 0.5741 - learning_rate: 1.5000e-04\n",
      "Epoch 132/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 107ms/step - accuracy: 0.8670 - loss: 0.0425 - precision: 0.8797 - recall: 0.8443\n",
      "Epoch 132: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 111ms/step - accuracy: 0.8665 - loss: 0.0431 - precision: 0.8792 - recall: 0.8426 - val_accuracy: 0.6111 - val_loss: 0.0967 - val_precision: 0.6038 - val_recall: 0.5926 - learning_rate: 1.5000e-04\n",
      "Epoch 133/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8647 - loss: 0.0451 - precision: 0.8751 - recall: 0.8405\n",
      "Epoch 133: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 108ms/step - accuracy: 0.8673 - loss: 0.0436 - precision: 0.8783 - recall: 0.8356 - val_accuracy: 0.6296 - val_loss: 0.0858 - val_precision: 0.6346 - val_recall: 0.6111 - learning_rate: 1.5000e-04\n",
      "Epoch 134/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.8687 - loss: 0.0423 - precision: 0.8820 - recall: 0.8395\n",
      "Epoch 134: ReduceLROnPlateau reducing learning rate to 7.500000356230885e-05.\n",
      "\n",
      "Epoch 134: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 99ms/step - accuracy: 0.8673 - loss: 0.0433 - precision: 0.8818 - recall: 0.8403 - val_accuracy: 0.6852 - val_loss: 0.0885 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 1.5000e-04\n",
      "Epoch 135/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8691 - loss: 0.0412 - precision: 0.8866 - recall: 0.8500\n",
      "Epoch 135: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 113ms/step - accuracy: 0.8735 - loss: 0.0411 - precision: 0.8902 - recall: 0.8449 - val_accuracy: 0.6667 - val_loss: 0.0845 - val_precision: 0.6538 - val_recall: 0.6296 - learning_rate: 7.5000e-05\n",
      "Epoch 136/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 112ms/step - accuracy: 0.8754 - loss: 0.0393 - precision: 0.8936 - recall: 0.8546\n",
      "Epoch 136: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 130ms/step - accuracy: 0.8704 - loss: 0.0409 - precision: 0.8894 - recall: 0.8441 - val_accuracy: 0.6296 - val_loss: 0.0912 - val_precision: 0.6346 - val_recall: 0.6111 - learning_rate: 7.5000e-05\n",
      "Epoch 137/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 106ms/step - accuracy: 0.8838 - loss: 0.0388 - precision: 0.9034 - recall: 0.8593\n",
      "Epoch 137: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 116ms/step - accuracy: 0.8804 - loss: 0.0395 - precision: 0.8976 - recall: 0.8526 - val_accuracy: 0.6481 - val_loss: 0.0857 - val_precision: 0.6667 - val_recall: 0.6296 - learning_rate: 7.5000e-05\n",
      "Epoch 138/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8902 - loss: 0.0359 - precision: 0.8989 - recall: 0.8647\n",
      "Epoch 138: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 105ms/step - accuracy: 0.8727 - loss: 0.0410 - precision: 0.8822 - recall: 0.8434 - val_accuracy: 0.6481 - val_loss: 0.0870 - val_precision: 0.6538 - val_recall: 0.6296 - learning_rate: 7.5000e-05\n",
      "Epoch 139/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 171ms/step - accuracy: 0.8830 - loss: 0.0413 - precision: 0.8948 - recall: 0.8680\n",
      "Epoch 139: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 187ms/step - accuracy: 0.8727 - loss: 0.0407 - precision: 0.8886 - recall: 0.8495 - val_accuracy: 0.5741 - val_loss: 0.0870 - val_precision: 0.5962 - val_recall: 0.5741 - learning_rate: 7.5000e-05\n",
      "Epoch 140/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 220ms/step - accuracy: 0.8681 - loss: 0.0375 - precision: 0.8811 - recall: 0.8441\n",
      "Epoch 140: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 298ms/step - accuracy: 0.8765 - loss: 0.0380 - precision: 0.8895 - recall: 0.8511 - val_accuracy: 0.6296 - val_loss: 0.0882 - val_precision: 0.6200 - val_recall: 0.5741 - learning_rate: 7.5000e-05\n",
      "Epoch 141/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 214ms/step - accuracy: 0.8781 - loss: 0.0367 - precision: 0.8929 - recall: 0.8492\n",
      "Epoch 141: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m18s\u001b[0m 228ms/step - accuracy: 0.8704 - loss: 0.0393 - precision: 0.8874 - recall: 0.8395 - val_accuracy: 0.6481 - val_loss: 0.0870 - val_precision: 0.6471 - val_recall: 0.6111 - learning_rate: 7.5000e-05\n",
      "Epoch 142/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 333ms/step - accuracy: 0.8801 - loss: 0.0379 - precision: 0.8943 - recall: 0.8490\n",
      "Epoch 142: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m16s\u001b[0m 388ms/step - accuracy: 0.8696 - loss: 0.0392 - precision: 0.8880 - recall: 0.8380 - val_accuracy: 0.6481 - val_loss: 0.0835 - val_precision: 0.6471 - val_recall: 0.6111 - learning_rate: 7.5000e-05\n",
      "Epoch 143/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 183ms/step - accuracy: 0.8985 - loss: 0.0364 - precision: 0.9141 - recall: 0.8755\n",
      "Epoch 143: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m14s\u001b[0m 202ms/step - accuracy: 0.8789 - loss: 0.0401 - precision: 0.8961 - recall: 0.8519 - val_accuracy: 0.6667 - val_loss: 0.0782 - val_precision: 0.6604 - val_recall: 0.6481 - learning_rate: 7.5000e-05\n",
      "Epoch 144/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 100ms/step - accuracy: 0.8923 - loss: 0.0364 - precision: 0.9007 - recall: 0.8619\n",
      "Epoch 144: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 108ms/step - accuracy: 0.8789 - loss: 0.0377 - precision: 0.8903 - recall: 0.8519 - val_accuracy: 0.6667 - val_loss: 0.0815 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 7.5000e-05\n",
      "Epoch 145/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 122ms/step - accuracy: 0.8717 - loss: 0.0387 - precision: 0.8893 - recall: 0.8505\n",
      "Epoch 145: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 136ms/step - accuracy: 0.8650 - loss: 0.0391 - precision: 0.8820 - recall: 0.8418 - val_accuracy: 0.6296 - val_loss: 0.0809 - val_precision: 0.6538 - val_recall: 0.6296 - learning_rate: 7.5000e-05\n",
      "Epoch 146/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.8831 - loss: 0.0393 - precision: 0.8982 - recall: 0.8583\n",
      "Epoch 146: ReduceLROnPlateau reducing learning rate to 3.7500001781154424e-05.\n",
      "\n",
      "Epoch 146: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 79ms/step - accuracy: 0.8819 - loss: 0.0397 - precision: 0.8981 - recall: 0.8565 - val_accuracy: 0.6481 - val_loss: 0.0945 - val_precision: 0.6538 - val_recall: 0.6296 - learning_rate: 7.5000e-05\n",
      "Epoch 147/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8746 - loss: 0.0364 - precision: 0.8945 - recall: 0.8528\n",
      "Epoch 147: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 89ms/step - accuracy: 0.8735 - loss: 0.0365 - precision: 0.8906 - recall: 0.8542 - val_accuracy: 0.6667 - val_loss: 0.0878 - val_precision: 0.6604 - val_recall: 0.6481 - learning_rate: 3.7500e-05\n",
      "Epoch 148/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 86ms/step - accuracy: 0.8875 - loss: 0.0362 - precision: 0.9026 - recall: 0.8541\n",
      "Epoch 148: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 92ms/step - accuracy: 0.8889 - loss: 0.0373 - precision: 0.9035 - recall: 0.8596 - val_accuracy: 0.6481 - val_loss: 0.0900 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 3.7500e-05\n",
      "Epoch 149/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8757 - loss: 0.0376 - precision: 0.8861 - recall: 0.8502\n",
      "Epoch 149: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 90ms/step - accuracy: 0.8742 - loss: 0.0379 - precision: 0.8864 - recall: 0.8488 - val_accuracy: 0.6111 - val_loss: 0.0948 - val_precision: 0.6078 - val_recall: 0.5741 - learning_rate: 3.7500e-05\n",
      "Epoch 150/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.8480 - loss: 0.0399 - precision: 0.8643 - recall: 0.8283\n",
      "Epoch 150: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 100ms/step - accuracy: 0.8611 - loss: 0.0403 - precision: 0.8742 - recall: 0.8364 - val_accuracy: 0.6296 - val_loss: 0.0845 - val_precision: 0.6400 - val_recall: 0.5926 - learning_rate: 3.7500e-05\n",
      "Epoch 151/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.8990 - loss: 0.0328 - precision: 0.9111 - recall: 0.8859\n",
      "Epoch 151: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 102ms/step - accuracy: 0.8796 - loss: 0.0377 - precision: 0.8912 - recall: 0.8596 - val_accuracy: 0.6667 - val_loss: 0.0800 - val_precision: 0.6604 - val_recall: 0.6481 - learning_rate: 3.7500e-05\n",
      "Epoch 152/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 84ms/step - accuracy: 0.8556 - loss: 0.0387 - precision: 0.8732 - recall: 0.8369\n",
      "Epoch 152: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 93ms/step - accuracy: 0.8619 - loss: 0.0387 - precision: 0.8795 - recall: 0.8395 - val_accuracy: 0.6667 - val_loss: 0.0785 - val_precision: 0.6731 - val_recall: 0.6481 - learning_rate: 3.7500e-05\n",
      "Epoch 153/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.8917 - loss: 0.0343 - precision: 0.9080 - recall: 0.8679\n",
      "Epoch 153: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 88ms/step - accuracy: 0.8866 - loss: 0.0365 - precision: 0.8998 - recall: 0.8665 - val_accuracy: 0.5926 - val_loss: 0.0883 - val_precision: 0.5962 - val_recall: 0.5741 - learning_rate: 3.7500e-05\n",
      "Epoch 154/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 102ms/step - accuracy: 0.8670 - loss: 0.0369 - precision: 0.8842 - recall: 0.8472\n",
      "Epoch 154: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 106ms/step - accuracy: 0.8696 - loss: 0.0372 - precision: 0.8856 - recall: 0.8480 - val_accuracy: 0.6111 - val_loss: 0.0819 - val_precision: 0.6078 - val_recall: 0.5741 - learning_rate: 3.7500e-05\n",
      "Epoch 155/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 0.8752 - loss: 0.0367 - precision: 0.8863 - recall: 0.8566\n",
      "Epoch 155: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.8719 - loss: 0.0386 - precision: 0.8844 - recall: 0.8503 - val_accuracy: 0.5926 - val_loss: 0.0828 - val_precision: 0.6038 - val_recall: 0.5926 - learning_rate: 3.7500e-05\n",
      "Epoch 156/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 90ms/step - accuracy: 0.8723 - loss: 0.0366 - precision: 0.9004 - recall: 0.8540\n",
      "Epoch 156: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 97ms/step - accuracy: 0.8711 - loss: 0.0387 - precision: 0.8917 - recall: 0.8511 - val_accuracy: 0.6667 - val_loss: 0.0762 - val_precision: 0.6731 - val_recall: 0.6481 - learning_rate: 3.7500e-05\n",
      "Epoch 157/300\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.8907 - loss: 0.0362 - precision: 0.9083 - recall: 0.8624\n",
      "Epoch 157: val_loss did not improve from 0.06853\n",
      "\u001b[1m41/41\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 95ms/step - accuracy: 0.8858 - loss: 0.0371 - precision: 0.9046 - recall: 0.8565 - val_accuracy: 0.6481 - val_loss: 0.0773 - val_precision: 0.6604 - val_recall: 0.6481 - learning_rate: 3.7500e-05\n",
      "Epoch 157: early stopping\n",
      "Restoring model weights from the end of the best epoch: 122.\n",
      "\n",
      "âœ“ GRU model training complete!\n"
     ]
    }
   ],
   "source": [
    "# Train GRU model\n",
    "print(\"\\nğŸš€ Training GRU model...\")\n",
    "\n",
    "gru_callbacks = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=35,  # Increased patience\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.5,\n",
    "        patience=12,\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath='models/gru_best.weights.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "history_gru = gru_model.fit(\n",
    "    X_gru_train_aug, y_gru_train_aug,\n",
    "    validation_data=(X_gru_val_scaled, y_gru_val_onehot),\n",
    "    epochs=300,  # Increased from 150 to 300\n",
    "    batch_size=32,\n",
    "    class_weight=gru_class_weight_dict,\n",
    "    callbacks=gru_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ GRU model training complete!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "9563a98e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Evaluating GRU model...\n",
      "\u001b[1m11/11\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 384ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step \n",
      "\n",
      "================================================================================\n",
      "GRU MODEL RESULTS\n",
      "================================================================================\n",
      "\n",
      "Train Set:\n",
      "  Accuracy:  0.9568\n",
      "  Precision: 0.9567\n",
      "  Recall:    0.9568\n",
      "  F1-Score:  0.9566\n",
      "\n",
      "Validation Set:\n",
      "  Accuracy:  0.6667\n",
      "  Precision: 0.5000\n",
      "  Recall:    0.6667\n",
      "  F1-Score:  0.5556\n",
      "\n",
      "Test Set:\n",
      "  Accuracy:  0.6852\n",
      "  Precision: 0.8381\n",
      "  Recall:    0.6852\n",
      "  F1-Score:  0.5948\n",
      "\n",
      "\n",
      "Test Set Confusion Matrix:\n",
      "[[18  0  0]\n",
      " [ 0 18  0]\n",
      " [ 0 17  1]]\n",
      "\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       1.00      1.00      1.00        18\n",
      "      Medium       0.51      1.00      0.68        18\n",
      "        High       1.00      0.06      0.11        18\n",
      "\n",
      "    accuracy                           0.69        54\n",
      "   macro avg       0.84      0.69      0.59        54\n",
      "weighted avg       0.84      0.69      0.59        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate GRU model\n",
    "print(\"\\nğŸ“Š Evaluating GRU model...\")\n",
    "\n",
    "y_gru_pred_train_probs = gru_model.predict(X_gru_train_scaled)\n",
    "y_gru_pred_val_probs = gru_model.predict(X_gru_val_scaled)\n",
    "y_gru_pred_test_probs = gru_model.predict(X_gru_test_scaled)\n",
    "\n",
    "y_gru_pred_train = np.argmax(y_gru_pred_train_probs, axis=1)\n",
    "y_gru_pred_val = np.argmax(y_gru_pred_val_probs, axis=1)\n",
    "y_gru_pred_test = np.argmax(y_gru_pred_test_probs, axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"GRU MODEL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for split_name, y_true, y_pred in [\n",
    "    ('Train', y_gru_train_cat, y_gru_pred_train),\n",
    "    ('Validation', y_gru_val_cat, y_gru_pred_val),\n",
    "    ('Test', y_gru_test_cat, y_gru_pred_test)\n",
    "]:\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{split_name} Set:\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(\"\\n\\nTest Set Confusion Matrix:\")\n",
    "print(confusion_matrix(y_gru_test_cat, y_gru_pred_test))\n",
    "\n",
    "print(\"\\n\\nTest Set Classification Report:\")\n",
    "print(classification_report(y_gru_test_cat, y_gru_pred_test,\n",
    "                          target_names=['Low', 'Medium', 'High']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "62010648",
   "metadata": {},
   "source": [
    "---\n",
    "## Part 3: Hybrid CNN-GRU Model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2438dcdf",
   "metadata": {},
   "source": [
    "### What is Hybrid CNN-GRU?\n",
    "\n",
    "Combines the strengths of both architectures:\n",
    "\n",
    "**CNN Branch (Temporal):**\n",
    "- Extracts local patterns from monthly sequences\n",
    "- Captures seasonal signatures, growth patterns\n",
    "\n",
    "**GRU Branch (Sequential):**\n",
    "- Models temporal dependencies from CNN features\n",
    "- Captures how patterns evolve across growing season\n",
    "\n",
    "**Static Branch:**\n",
    "- Processes soil properties and lag features\n",
    "- Non-temporal but crucial predictors\n",
    "\n",
    "**Fusion:**\n",
    "- Concatenates temporal and static representations\n",
    "- Dense layers learn optimal combination\n",
    "- Most powerful of the three models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "2965e281",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "PART 3: HYBRID CNN-GRU MODEL\n",
      "================================================================================\n",
      "\n",
      "ğŸ“Š Loading Hybrid data...\n",
      "  Temporal features: 17\n",
      "  Static features: 15\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PART 3: HYBRID CNN-GRU MODEL\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Load Hybrid data\n",
    "print(\"\\nğŸ“Š Loading Hybrid data...\")\n",
    "hybrid_train = pd.read_csv(splits_path / 'hybrid' / 'train.csv')\n",
    "hybrid_val = pd.read_csv(splits_path / 'hybrid' / 'val.csv')\n",
    "hybrid_test = pd.read_csv(splits_path / 'hybrid' / 'test.csv')\n",
    "\n",
    "# Remove missing yields\n",
    "hybrid_train = hybrid_train.dropna(subset=[target_col])\n",
    "hybrid_val = hybrid_val.dropna(subset=[target_col])\n",
    "hybrid_test = hybrid_test.dropna(subset=[target_col])\n",
    "\n",
    "# Encode categorical\n",
    "hybrid_train['Crop_encoded'] = crop_encoder.transform(hybrid_train['Crop'])\n",
    "hybrid_train['Region_encoded'] = region_encoder.transform(hybrid_train['Region'])\n",
    "hybrid_val['Crop_encoded'] = crop_encoder.transform(hybrid_val['Crop'])\n",
    "hybrid_val['Region_encoded'] = region_encoder.transform(hybrid_val['Region'])\n",
    "hybrid_test['Crop_encoded'] = crop_encoder.transform(hybrid_test['Crop'])\n",
    "hybrid_test['Region_encoded'] = region_encoder.transform(hybrid_test['Region'])\n",
    "\n",
    "# Add encodings to static features\n",
    "hybrid_static_cols_full = hybrid_static_cols + ['Crop_encoded', 'Region_encoded']\n",
    "\n",
    "print(f\"  Temporal features: {len(hybrid_temporal_cols)}\")\n",
    "print(f\"  Static features: {len(hybrid_static_cols_full)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ed942a97",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Creating Hybrid sequences...\n",
      "\n",
      "  Train temporal: (324, 12, 17)\n",
      "  Train static:   (324, 15)\n",
      "  Val temporal:   (54, 12, 17)\n",
      "  Test temporal:  (54, 12, 17)\n"
     ]
    }
   ],
   "source": [
    "# Prepare Hybrid sequences\n",
    "print(\"\\nğŸ“Š Creating Hybrid sequences...\")\n",
    "\n",
    "def create_hybrid_sequences(df, temporal_cols, static_cols, target_col, sequence_length=12):\n",
    "    \"\"\"Create sequences with separate temporal and static components\"\"\"\n",
    "    temporal_sequences = []\n",
    "    static_features = []\n",
    "    targets = []\n",
    "    \n",
    "    for (region, crop, year), group in df.groupby(['Region', 'Crop', 'Year']):\n",
    "        group_sorted = group.sort_values('Month')\n",
    "        \n",
    "        if len(group_sorted) >= sequence_length:\n",
    "            # Temporal sequence (first 12 months)\n",
    "            temporal_seq = group_sorted.iloc[:sequence_length][temporal_cols].values\n",
    "            \n",
    "            # Static features (same across all months, take first)\n",
    "            static_feat = group_sorted.iloc[0][static_cols].values\n",
    "            \n",
    "            # Target (annual yield)\n",
    "            target = group_sorted[target_col].sum()\n",
    "            \n",
    "            temporal_sequences.append(temporal_seq)\n",
    "            static_features.append(static_feat)\n",
    "            targets.append(target)\n",
    "    \n",
    "    return np.array(temporal_sequences), np.array(static_features), np.array(targets)\n",
    "\n",
    "X_hybrid_temp_train, X_hybrid_stat_train, y_hybrid_train = create_hybrid_sequences(\n",
    "    hybrid_train, hybrid_temporal_cols, hybrid_static_cols_full, target_col, sequence_length\n",
    ")\n",
    "X_hybrid_temp_val, X_hybrid_stat_val, y_hybrid_val = create_hybrid_sequences(\n",
    "    hybrid_val, hybrid_temporal_cols, hybrid_static_cols_full, target_col, sequence_length\n",
    ")\n",
    "X_hybrid_temp_test, X_hybrid_stat_test, y_hybrid_test = create_hybrid_sequences(\n",
    "    hybrid_test, hybrid_temporal_cols, hybrid_static_cols_full, target_col, sequence_length\n",
    ")\n",
    "\n",
    "print(f\"\\n  Train temporal: {X_hybrid_temp_train.shape}\")\n",
    "print(f\"  Train static:   {X_hybrid_stat_train.shape}\")\n",
    "print(f\"  Val temporal:   {X_hybrid_temp_val.shape}\")\n",
    "print(f\"  Test temporal:  {X_hybrid_temp_test.shape}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "47d07bc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "  Normalizing Hybrid features...\n",
      "  âœ“ Features normalized\n"
     ]
    }
   ],
   "source": [
    "# Normalize Hybrid features\n",
    "print(\"\\n  Normalizing Hybrid features...\")\n",
    "\n",
    "# Temporal features\n",
    "scaler_hybrid_temp = StandardScaler()\n",
    "X_hybrid_temp_train_reshaped = X_hybrid_temp_train.reshape(-1, X_hybrid_temp_train.shape[2])\n",
    "scaler_hybrid_temp.fit(X_hybrid_temp_train_reshaped)\n",
    "\n",
    "X_hybrid_temp_train_scaled = scaler_hybrid_temp.transform(\n",
    "    X_hybrid_temp_train.reshape(-1, X_hybrid_temp_train.shape[2])\n",
    ").reshape(X_hybrid_temp_train.shape)\n",
    "X_hybrid_temp_val_scaled = scaler_hybrid_temp.transform(\n",
    "    X_hybrid_temp_val.reshape(-1, X_hybrid_temp_val.shape[2])\n",
    ").reshape(X_hybrid_temp_val.shape)\n",
    "X_hybrid_temp_test_scaled = scaler_hybrid_temp.transform(\n",
    "    X_hybrid_temp_test.reshape(-1, X_hybrid_temp_test.shape[2])\n",
    ").reshape(X_hybrid_temp_test.shape)\n",
    "\n",
    "# Static features\n",
    "scaler_hybrid_stat = StandardScaler()\n",
    "X_hybrid_stat_train_scaled = scaler_hybrid_stat.fit_transform(X_hybrid_stat_train)\n",
    "X_hybrid_stat_val_scaled = scaler_hybrid_stat.transform(X_hybrid_stat_val)\n",
    "X_hybrid_stat_test_scaled = scaler_hybrid_stat.transform(X_hybrid_stat_test)\n",
    "\n",
    "print(\"  âœ“ Features normalized\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "876de97b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Categorizing yields for Hybrid...\n",
      "\n",
      "Class distribution (Hybrid Train):\n",
      "  Class 0: 108 samples (33.3%)\n",
      "  Class 1: 108 samples (33.3%)\n",
      "  Class 2: 108 samples (33.3%)\n"
     ]
    }
   ],
   "source": [
    "# Categorize yields for Hybrid\n",
    "print(\"\\nğŸ“Š Categorizing yields for Hybrid...\")\n",
    "\n",
    "y_hybrid_train_cat, hybrid_percentiles = categorize_yield_balanced(y_hybrid_train, method='percentile')\n",
    "y_hybrid_val_cat, _ = categorize_yield_balanced(y_hybrid_val, method='percentile')\n",
    "y_hybrid_test_cat, _ = categorize_yield_balanced(y_hybrid_test, method='percentile')\n",
    "\n",
    "print(f\"\\nClass distribution (Hybrid Train):\")\n",
    "unique, counts = np.unique(y_hybrid_train_cat, return_counts=True)\n",
    "for cls, count in zip(unique, counts):\n",
    "    print(f\"  Class {cls}: {count} samples ({count/len(y_hybrid_train_cat)*100:.1f}%)\")\n",
    "\n",
    "y_hybrid_train_onehot = to_categorical(y_hybrid_train_cat, num_classes=3)\n",
    "y_hybrid_val_onehot = to_categorical(y_hybrid_val_cat, num_classes=3)\n",
    "y_hybrid_test_onehot = to_categorical(y_hybrid_test_cat, num_classes=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "eb434406",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ”„ APPLYING DATA AUGMENTATION (Hybrid)...\n",
      "  Augmented Hybrid training size: 1296 samples\n",
      "\n",
      "âš–ï¸  Hybrid Class weights:\n",
      "   Class 0: weight=1.000 (n=432 samples)\n",
      "   Class 1: weight=1.000 (n=432 samples)\n",
      "   Class 2: weight=1.000 (n=432 samples)\n"
     ]
    }
   ],
   "source": [
    "# Data augmentation for Hybrid\n",
    "print(\"\\nğŸ”„ APPLYING DATA AUGMENTATION (Hybrid)...\")\n",
    "\n",
    "X_hybrid_temp_aug, X_hybrid_stat_aug, y_hybrid_train_aug = augment_hybrid_data(\n",
    "    X_hybrid_temp_train_scaled,\n",
    "    X_hybrid_stat_train_scaled,\n",
    "    y_hybrid_train_onehot,\n",
    "    num_augmented=3,  # Increased from 1 to 3\n",
    "    noise_level=0.02  # Reduced noise\n",
    ")\n",
    "\n",
    "print(f\"  Augmented Hybrid training size: {X_hybrid_temp_aug.shape[0]} samples\")\n",
    "\n",
    "# Shuffle\n",
    "indices = np.random.permutation(X_hybrid_temp_aug.shape[0])\n",
    "X_hybrid_temp_aug = X_hybrid_temp_aug[indices]\n",
    "X_hybrid_stat_aug = X_hybrid_stat_aug[indices]\n",
    "y_hybrid_train_aug = y_hybrid_train_aug[indices]\n",
    "\n",
    "# Class weights\n",
    "y_hybrid_train_labels = np.argmax(y_hybrid_train_aug, axis=1)\n",
    "hybrid_class_weights_array = compute_class_weight(\n",
    "    'balanced',\n",
    "    classes=np.unique(y_hybrid_train_labels),\n",
    "    y=y_hybrid_train_labels\n",
    ")\n",
    "hybrid_class_weight_dict = dict(enumerate(hybrid_class_weights_array))\n",
    "\n",
    "print(f\"\\nâš–ï¸  Hybrid Class weights:\")\n",
    "for cls, weight in hybrid_class_weight_dict.items():\n",
    "    count = np.sum(y_hybrid_train_labels == cls)\n",
    "    print(f\"   Class {cls}: weight={weight:.3f} (n={count} samples)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "7e919e58",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ temporal_input      â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">17</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,328</span> â”‚ temporal_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">12</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ conv1d_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_2     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MaxPooling1D</span>)      â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_11          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)     â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ max_pooling1d_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">24,704</span> â”‚ dropout_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ conv1d_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ static_input        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">15</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_12          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ static_input[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_5 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv1D</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">98,560</span> â”‚ dropout_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ dense_7[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">1,024</span> â”‚ conv1d_5[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_15          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_13          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">12,384</span> â”‚ dropout_15[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_3     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    â”‚    <span style=\"color: #00af00; text-decoration-color: #00af00\">203,904</span> â”‚ dropout_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> â”‚ dense_8[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> â”‚ bidirectional_3[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_16          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_14          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">6</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)    â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">6,208</span> â”‚ dropout_16[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_4     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">99,072</span> â”‚ dropout_14[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Bidirectional</span>)     â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">256</span> â”‚ dense_9[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span> â”‚ bidirectional_4[<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_17          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">64</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ dropout_17[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">37,056</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">768</span> â”‚ dense_10[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_18          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_11 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,528</span> â”‚ dropout_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">384</span> â”‚ dense_11[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_19          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_12 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚     <span style=\"color: #00af00; text-decoration-color: #00af00\">18,528</span> â”‚ dropout_18[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">96</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ dropout_19[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dense_12[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_13 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">4,656</span> â”‚ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">192</span> â”‚ dense_13[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_20          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">48</span>)        â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_14 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)    â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)         â”‚        <span style=\"color: #00af00; text-decoration-color: #00af00\">147</span> â”‚ dropout_20[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ temporal_input      â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m17\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_3 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚      \u001b[38;5;34m3,328\u001b[0m â”‚ temporal_input[\u001b[38;5;34m0\u001b[0mâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m12\u001b[0m, \u001b[38;5;34m64\u001b[0m)    â”‚        \u001b[38;5;34m256\u001b[0m â”‚ conv1d_3[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ max_pooling1d_2     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mMaxPooling1D\u001b[0m)      â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_11          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m64\u001b[0m)     â”‚          \u001b[38;5;34m0\u001b[0m â”‚ max_pooling1d_2[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_4 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚     \u001b[38;5;34m24,704\u001b[0m â”‚ dropout_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚        \u001b[38;5;34m512\u001b[0m â”‚ conv1d_4[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ static_input        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m15\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_12          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m128\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_7 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ static_input[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv1d_5 (\u001b[38;5;33mConv1D\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚     \u001b[38;5;34m98,560\u001b[0m â”‚ dropout_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ dense_7[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚      \u001b[38;5;34m1,024\u001b[0m â”‚ conv1d_5[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_15          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_13          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m256\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_8 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚     \u001b[38;5;34m12,384\u001b[0m â”‚ dropout_15[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_3     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m192\u001b[0m)    â”‚    \u001b[38;5;34m203,904\u001b[0m â”‚ dropout_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚ (\u001b[38;5;33mBidirectional\u001b[0m)     â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚        \u001b[38;5;34m384\u001b[0m â”‚ dense_8[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m192\u001b[0m)    â”‚        \u001b[38;5;34m768\u001b[0m â”‚ bidirectional_3[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_16          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_14          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m6\u001b[0m, \u001b[38;5;34m192\u001b[0m)    â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_9 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚      \u001b[38;5;34m6,208\u001b[0m â”‚ dropout_16[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ bidirectional_4     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚     \u001b[38;5;34m99,072\u001b[0m â”‚ dropout_14[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚ (\u001b[38;5;33mBidirectional\u001b[0m)     â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚        \u001b[38;5;34m256\u001b[0m â”‚ dense_9[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)       â”‚        \u001b[38;5;34m512\u001b[0m â”‚ bidirectional_4[\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_17          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m64\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ dropout_17[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_10 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       â”‚     \u001b[38;5;34m37,056\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       â”‚        \u001b[38;5;34m768\u001b[0m â”‚ dense_10[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_18          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m192\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_11 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚     \u001b[38;5;34m18,528\u001b[0m â”‚ dropout_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚        \u001b[38;5;34m384\u001b[0m â”‚ dense_11[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_19          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_12 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚     \u001b[38;5;34m18,528\u001b[0m â”‚ dropout_18[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add (\u001b[38;5;33mAdd\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m96\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ dropout_19[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m], â”‚\n",
       "â”‚                     â”‚                   â”‚            â”‚ dense_12[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_13 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚      \u001b[38;5;34m4,656\u001b[0m â”‚ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalizatioâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚        \u001b[38;5;34m192\u001b[0m â”‚ dense_13[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_20          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m48\u001b[0m)        â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mDropout\u001b[0m)           â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_14 (\u001b[38;5;33mDense\u001b[0m)    â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m3\u001b[0m)         â”‚        \u001b[38;5;34m147\u001b[0m â”‚ dropout_20[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">534,691</span> (2.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m534,691\u001b[0m (2.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">531,907</span> (2.03 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m531,907\u001b[0m (2.03 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">2,784</span> (10.88 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m2,784\u001b[0m (10.88 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Build Hybrid CNN-GRU model with IMPROVED architecture to fix class imbalance\n",
    "def build_hybrid_cnn_gru_model(sequence_length, n_temporal_features, n_static_features, learning_rate=0.0002):\n",
    "    \"\"\"\n",
    "    Build IMPROVED Hybrid CNN-GRU model to fix underperformance issues:\n",
    "    \n",
    "    FIXES IMPLEMENTED:\n",
    "    1. Reduced dropout to prevent over-regularization (was causing Medium bias)\n",
    "    2. Added residual connections for better gradient flow\n",
    "    3. Increased model capacity in fusion layers\n",
    "    4. Lower learning rate for more stable training\n",
    "    5. Stronger focal loss (gamma=3.0) to focus on hard examples (Low/High yields)\n",
    "    \n",
    "    Temporal Branch:\n",
    "    - CNN extracts patterns from monthly sequences\n",
    "    - GRU models temporal dependencies with residual connections\n",
    "    \n",
    "    Static Branch:\n",
    "    - Dense layers for soil and lag features\n",
    "    - Reduced dropout to retain more discriminative information\n",
    "    \n",
    "    Fusion:\n",
    "    - Enhanced capacity with residual connections\n",
    "    - Better integration of temporal + static features\n",
    "    \"\"\"\n",
    "    # Temporal input (CNN â†’ GRU)\n",
    "    temporal_input = layers.Input(shape=(sequence_length, n_temporal_features), name='temporal_input')\n",
    "    \n",
    "    # CNN layers with residual connections\n",
    "    x = layers.Conv1D(filters=64, kernel_size=3, activation='relu', padding='same',\n",
    "                     kernel_regularizer=regularizers.l2(0.001))(temporal_input)  # Reduced regularization\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    cnn_skip1 = x  # Store for residual\n",
    "    x = layers.MaxPooling1D(pool_size=2)(x)\n",
    "    x = layers.Dropout(0.25)(x)  # Reduced from 0.4\n",
    "    \n",
    "    x = layers.Conv1D(filters=128, kernel_size=3, activation='relu', padding='same',\n",
    "                     kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.25)(x)  # Reduced from 0.4\n",
    "    \n",
    "    x = layers.Conv1D(filters=256, kernel_size=3, activation='relu', padding='same',\n",
    "                     kernel_regularizer=regularizers.l2(0.001))(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.3)(x)  # Reduced from 0.5\n",
    "    \n",
    "    # Bidirectional GRU with anti-overfitting regularization\n",
    "    x = layers.Bidirectional(layers.GRU(96, return_sequences=True,\n",
    "                                       kernel_regularizer=regularizers.l2(0.01),  # INCREASED from 0.001\n",
    "                                       recurrent_regularizer=regularizers.l2(0.01),  # INCREASED from 0.001\n",
    "                                       dropout=0.3,  # INCREASED from 0.2\n",
    "                                       recurrent_dropout=0.3))(x)  # INCREASED from 0.2\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)  # INCREASED from 0.3\n",
    "    \n",
    "    x = layers.Bidirectional(layers.GRU(64, return_sequences=False,\n",
    "                                       kernel_regularizer=regularizers.l2(0.01),  # INCREASED from 0.001\n",
    "                                       recurrent_regularizer=regularizers.l2(0.01),  # INCREASED from 0.001\n",
    "                                       dropout=0.3,  # INCREASED from 0.2\n",
    "                                       recurrent_dropout=0.3))(x)  # INCREASED from 0.2\n",
    "    temporal_out = layers.BatchNormalization()(x)\n",
    "    \n",
    "    # Static input branch with anti-overfitting regularization\n",
    "    static_input = layers.Input(shape=(n_static_features,), name='static_input')\n",
    "    y = layers.Dense(128, activation='relu', kernel_regularizer=regularizers.l2(0.01))(static_input)  # INCREASED from 0.001\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Dropout(0.4)(y)  # INCREASED from 0.3\n",
    "    static_skip1 = y  # Store for residual\n",
    "    \n",
    "    y = layers.Dense(96, activation='relu', kernel_regularizer=regularizers.l2(0.01))(y)  # INCREASED from 0.001\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    y = layers.Dropout(0.35)(y)  # INCREASED from 0.25\n",
    "    \n",
    "    y = layers.Dense(64, activation='relu', kernel_regularizer=regularizers.l2(0.01))(y)  # INCREASED from 0.001\n",
    "    y = layers.BatchNormalization()(y)\n",
    "    static_out = layers.Dropout(0.3)(y)  # INCREASED from 0.2\n",
    "    \n",
    "    # Enhanced fusion layer with anti-overfitting regularization\n",
    "    merged = layers.concatenate([temporal_out, static_out])\n",
    "    \n",
    "    z = layers.Dense(192, activation='relu', kernel_regularizer=regularizers.l2(0.01))(merged)  # INCREASED from 0.001\n",
    "    z = layers.BatchNormalization()(z)\n",
    "    z = layers.Dropout(0.45)(z)  # INCREASED from 0.35\n",
    "    fusion_skip = z  # Store for residual\n",
    "    \n",
    "    z = layers.Dense(96, activation='relu', kernel_regularizer=regularizers.l2(0.01))(z)  # INCREASED from 0.001\n",
    "    z = layers.BatchNormalization()(z)\n",
    "    z = layers.Dropout(0.4)(z)  # INCREASED from 0.3\n",
    "    \n",
    "    # Residual connection\n",
    "    z_reshaped = layers.Dense(96, kernel_regularizer=regularizers.l2(0.01))(fusion_skip)  # Match dimensions\n",
    "    z = layers.Add()([z, z_reshaped])  # Add residual\n",
    "    \n",
    "    z = layers.Dense(48, activation='relu', kernel_regularizer=regularizers.l2(0.01))(z)  # INCREASED from 0.001\n",
    "    z = layers.BatchNormalization()(z)\n",
    "    z = layers.Dropout(0.35)(z)  # INCREASED from 0.25\n",
    "    \n",
    "    # Output layer\n",
    "    output = layers.Dense(3, activation='softmax')(z)\n",
    "    \n",
    "    model = models.Model(inputs=[temporal_input, static_input], outputs=output)\n",
    "    \n",
    "    optimizer = Adam(learning_rate=learning_rate, clipnorm=1.0)\n",
    "    \n",
    "    # CRITICAL FIX: Stronger focal loss to combat class imbalance\n",
    "    # gamma=3.0 focuses more on hard-to-classify examples (Low/High yields)\n",
    "    # alpha=0.3 increased to give more weight to minority classes\n",
    "    model.compile(\n",
    "        optimizer=optimizer,\n",
    "        loss=focal_loss(gamma=3.0, alpha=0.3),  # Increased from gamma=2.0, alpha=0.25\n",
    "        metrics=['accuracy',\n",
    "                 tf.keras.metrics.Precision(name='precision'),\n",
    "                 tf.keras.metrics.Recall(name='recall')]\n",
    "    )\n",
    "    \n",
    "    return model\n",
    "\n",
    "hybrid_model = build_hybrid_cnn_gru_model(\n",
    "    sequence_length=sequence_length,\n",
    "    n_temporal_features=X_hybrid_temp_aug.shape[2],\n",
    "    n_static_features=X_hybrid_stat_aug.shape[1],\n",
    "    learning_rate=0.0002  # Reduced from 0.0003 for more stable training\n",
    ")\n",
    "hybrid_model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "083d407f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Training IMPROVED Hybrid CNN-GRU model...\n",
      "ANTI-OVERFITTING IMPROVEMENTS:\n",
      "  â€¢ INCREASED L2 regularization (0.001 â†’ 0.01) to prevent memorization\n",
      "  â€¢ INCREASED dropout (0.2-0.35 â†’ 0.3-0.45) for better generalization\n",
      "  â€¢ Added residual connections for gradient flow\n",
      "  â€¢ Stronger focal loss (gamma=3.0) for hard examples\n",
      "  â€¢ Lower learning rate (0.0002) for stability\n",
      "  â€¢ Enhanced class weights for Low/High yield detection\n",
      "\n",
      "Amplified Class Weights (to combat Medium bias):\n",
      "  Class 0 (Low): 1.5000\n",
      "  Class 1 (Medium): 0.7000\n",
      "  Class 2 (High): 1.5000\n",
      "Epoch 1/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.3082 - loss: 20.0945 - precision: 0.3105 - recall: 0.2606\n",
      "Epoch 1: val_loss improved from None to 18.60689, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 1: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m30s\u001b[0m 108ms/step - accuracy: 0.3542 - loss: 19.6818 - precision: 0.3550 - recall: 0.2986 - val_accuracy: 0.3333 - val_loss: 18.6069 - val_precision: 0.2667 - val_recall: 0.0741 - learning_rate: 2.0000e-04\n",
      "Epoch 2/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.4246 - loss: 18.4376 - precision: 0.4389 - recall: 0.3616\n",
      "Epoch 2: val_loss improved from 18.60689 to 17.17013, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 2: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.4429 - loss: 18.0957 - precision: 0.4482 - recall: 0.3704 - val_accuracy: 0.3333 - val_loss: 17.1701 - val_precision: 0.3478 - val_recall: 0.2963 - learning_rate: 2.0000e-04\n",
      "Epoch 3/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.4684 - loss: 17.0238 - precision: 0.4808 - recall: 0.4025\n",
      "Epoch 3: val_loss improved from 17.17013 to 15.83053, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 3: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.5015 - loss: 16.6945 - precision: 0.5178 - recall: 0.4375 - val_accuracy: 0.5185 - val_loss: 15.8305 - val_precision: 0.5366 - val_recall: 0.4074 - learning_rate: 2.0000e-04\n",
      "Epoch 4/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.5055 - loss: 15.6792 - precision: 0.5314 - recall: 0.4479\n",
      "Epoch 4: val_loss improved from 15.83053 to 14.58179, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 4: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.5463 - loss: 15.3656 - precision: 0.5680 - recall: 0.4931 - val_accuracy: 0.6296 - val_loss: 14.5818 - val_precision: 0.6415 - val_recall: 0.6296 - learning_rate: 2.0000e-04\n",
      "Epoch 5/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.6206 - loss: 14.4248 - precision: 0.6436 - recall: 0.5778\n",
      "Epoch 5: val_loss improved from 14.58179 to 13.39401, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 5: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.6304 - loss: 14.1125 - precision: 0.6588 - recall: 0.5810 - val_accuracy: 0.5370 - val_loss: 13.3940 - val_precision: 0.5192 - val_recall: 0.5000 - learning_rate: 2.0000e-04\n",
      "Epoch 6/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.6385 - loss: 13.2104 - precision: 0.6720 - recall: 0.6037\n",
      "Epoch 6: val_loss improved from 13.39401 to 12.32537, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 6: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.6636 - loss: 12.9347 - precision: 0.6933 - recall: 0.6296 - val_accuracy: 0.5370 - val_loss: 12.3254 - val_precision: 0.5370 - val_recall: 0.5370 - learning_rate: 2.0000e-04\n",
      "Epoch 7/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7186 - loss: 12.1130 - precision: 0.7360 - recall: 0.6728\n",
      "Epoch 7: val_loss improved from 12.32537 to 11.29628, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 7: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.7160 - loss: 11.8532 - precision: 0.7411 - recall: 0.6782 - val_accuracy: 0.5741 - val_loss: 11.2963 - val_precision: 0.5741 - val_recall: 0.5741 - learning_rate: 2.0000e-04\n",
      "Epoch 8/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.7379 - loss: 11.1003 - precision: 0.7655 - recall: 0.6994\n",
      "Epoch 8: val_loss improved from 11.29628 to 10.37533, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 8: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.7670 - loss: 10.8507 - precision: 0.7917 - recall: 0.7245 - val_accuracy: 0.5926 - val_loss: 10.3753 - val_precision: 0.5849 - val_recall: 0.5741 - learning_rate: 2.0000e-04\n",
      "Epoch 9/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.7802 - loss: 10.1782 - precision: 0.8004 - recall: 0.7613\n",
      "Epoch 9: val_loss improved from 10.37533 to 9.53752, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 9: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.7894 - loss: 9.9530 - precision: 0.8149 - recall: 0.7608 - val_accuracy: 0.6111 - val_loss: 9.5375 - val_precision: 0.6111 - val_recall: 0.6111 - learning_rate: 2.0000e-04\n",
      "Epoch 10/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.7949 - loss: 9.3245 - precision: 0.8162 - recall: 0.7677\n",
      "Epoch 10: val_loss improved from 9.53752 to 8.76798, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 10: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8071 - loss: 9.1253 - precision: 0.8270 - recall: 0.7785 - val_accuracy: 0.6111 - val_loss: 8.7680 - val_precision: 0.6111 - val_recall: 0.6111 - learning_rate: 2.0000e-04\n",
      "Epoch 11/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8242 - loss: 8.5628 - precision: 0.8401 - recall: 0.7840\n",
      "Epoch 11: val_loss improved from 8.76798 to 8.05674, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 11: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.8264 - loss: 8.3744 - precision: 0.8434 - recall: 0.7940 - val_accuracy: 0.6481 - val_loss: 8.0567 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 12/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.8309 - loss: 7.8445 - precision: 0.8504 - recall: 0.8068\n",
      "Epoch 12: val_loss improved from 8.05674 to 7.41177, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 12: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.8248 - loss: 7.6854 - precision: 0.8430 - recall: 0.8040 - val_accuracy: 0.6667 - val_loss: 7.4118 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 13/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.8495 - loss: 7.2037 - precision: 0.8574 - recall: 0.8238\n",
      "Epoch 13: val_loss improved from 7.41177 to 6.80827, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 13: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.8534 - loss: 7.0501 - precision: 0.8670 - recall: 0.8302 - val_accuracy: 0.6481 - val_loss: 6.8083 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 14/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8458 - loss: 6.6100 - precision: 0.8574 - recall: 0.8237\n",
      "Epoch 14: val_loss improved from 6.80827 to 6.25987, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 14: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.8495 - loss: 6.4676 - precision: 0.8640 - recall: 0.8287 - val_accuracy: 0.6481 - val_loss: 6.2599 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 15/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8418 - loss: 6.0689 - precision: 0.8513 - recall: 0.8207\n",
      "Epoch 15: val_loss improved from 6.25987 to 5.74278, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 15: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.8580 - loss: 5.9325 - precision: 0.8698 - recall: 0.8403 - val_accuracy: 0.6481 - val_loss: 5.7428 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 16/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.8826 - loss: 5.5522 - precision: 0.8994 - recall: 0.8470\n",
      "Epoch 16: val_loss improved from 5.74278 to 5.28052, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 16: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.8804 - loss: 5.4368 - precision: 0.8944 - recall: 0.8565 - val_accuracy: 0.6481 - val_loss: 5.2805 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 17/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.8809 - loss: 5.0916 - precision: 0.8890 - recall: 0.8638\n",
      "Epoch 17: val_loss improved from 5.28052 to 4.83615, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 17: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.8735 - loss: 4.9873 - precision: 0.8859 - recall: 0.8565 - val_accuracy: 0.6667 - val_loss: 4.8362 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 18/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.8643 - loss: 4.6805 - precision: 0.8818 - recall: 0.8561\n",
      "Epoch 18: val_loss improved from 4.83615 to 4.45661, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 18: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.8773 - loss: 4.5741 - precision: 0.8892 - recall: 0.8665 - val_accuracy: 0.6481 - val_loss: 4.4566 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 19/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.8831 - loss: 4.2882 - precision: 0.8916 - recall: 0.8649\n",
      "Epoch 19: val_loss improved from 4.45661 to 4.06947, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 19: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.8904 - loss: 4.1923 - precision: 0.8959 - recall: 0.8704 - val_accuracy: 0.6481 - val_loss: 4.0695 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 20/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8781 - loss: 3.9279 - precision: 0.8880 - recall: 0.8671\n",
      "Epoch 20: val_loss improved from 4.06947 to 3.74505, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 20: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.8812 - loss: 3.8455 - precision: 0.8892 - recall: 0.8673 - val_accuracy: 0.6667 - val_loss: 3.7451 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 21/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8885 - loss: 3.6002 - precision: 0.8927 - recall: 0.8703\n",
      "Epoch 21: val_loss improved from 3.74505 to 3.44381, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 21: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 55ms/step - accuracy: 0.8958 - loss: 3.5195 - precision: 0.9017 - recall: 0.8843 - val_accuracy: 0.6667 - val_loss: 3.4438 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 22/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8805 - loss: 3.3027 - precision: 0.9041 - recall: 0.8759\n",
      "Epoch 22: val_loss improved from 3.44381 to 3.18853, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 22: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 51ms/step - accuracy: 0.8920 - loss: 3.2270 - precision: 0.9067 - recall: 0.8850 - val_accuracy: 0.6667 - val_loss: 3.1885 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 23/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9156 - loss: 3.0210 - precision: 0.9258 - recall: 0.9047\n",
      "Epoch 23: val_loss improved from 3.18853 to 2.92251, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 23: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.9151 - loss: 2.9539 - precision: 0.9234 - recall: 0.9028 - val_accuracy: 0.6667 - val_loss: 2.9225 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 24/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.8902 - loss: 2.7688 - precision: 0.9056 - recall: 0.8725\n",
      "Epoch 24: val_loss improved from 2.92251 to 2.66765, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 24: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 54ms/step - accuracy: 0.8904 - loss: 2.7113 - precision: 0.9008 - recall: 0.8758 - val_accuracy: 0.6667 - val_loss: 2.6676 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 25/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.8950 - loss: 2.5413 - precision: 0.8996 - recall: 0.8868\n",
      "Epoch 25: val_loss improved from 2.66765 to 2.46758, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 25: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9043 - loss: 2.4858 - precision: 0.9100 - recall: 0.8897 - val_accuracy: 0.6667 - val_loss: 2.4676 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 26/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9054 - loss: 2.3241 - precision: 0.9072 - recall: 0.8972\n",
      "Epoch 26: val_loss improved from 2.46758 to 2.26421, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 26: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9128 - loss: 2.2749 - precision: 0.9159 - recall: 0.8997 - val_accuracy: 0.6481 - val_loss: 2.2642 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 27/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.8957 - loss: 2.1338 - precision: 0.9033 - recall: 0.8841\n",
      "Epoch 27: val_loss improved from 2.26421 to 2.09005, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 27: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.8951 - loss: 2.0895 - precision: 0.9039 - recall: 0.8850 - val_accuracy: 0.6481 - val_loss: 2.0901 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 28/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9003 - loss: 1.9614 - precision: 0.9043 - recall: 0.8865\n",
      "Epoch 28: val_loss improved from 2.09005 to 1.92816, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 28: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.8966 - loss: 1.9213 - precision: 0.9028 - recall: 0.8819 - val_accuracy: 0.6481 - val_loss: 1.9282 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 29/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9128 - loss: 1.7936 - precision: 0.9265 - recall: 0.9032\n",
      "Epoch 29: val_loss improved from 1.92816 to 1.74986, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 29: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9167 - loss: 1.7574 - precision: 0.9262 - recall: 0.9097 - val_accuracy: 0.6667 - val_loss: 1.7499 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 30/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9116 - loss: 1.6472 - precision: 0.9229 - recall: 0.9030\n",
      "Epoch 30: val_loss improved from 1.74986 to 1.60948, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 30: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9174 - loss: 1.6158 - precision: 0.9304 - recall: 0.9082 - val_accuracy: 0.6667 - val_loss: 1.6095 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 31/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9101 - loss: 1.5187 - precision: 0.9244 - recall: 0.9078\n",
      "Epoch 31: val_loss improved from 1.60948 to 1.54178, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 31: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9151 - loss: 1.4836 - precision: 0.9240 - recall: 0.9105 - val_accuracy: 0.6481 - val_loss: 1.5418 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 32/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9237 - loss: 1.3930 - precision: 0.9264 - recall: 0.9138\n",
      "Epoch 32: val_loss improved from 1.54178 to 1.40336, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 32: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9298 - loss: 1.3647 - precision: 0.9340 - recall: 0.9174 - val_accuracy: 0.6667 - val_loss: 1.4034 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 33/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9159 - loss: 1.2913 - precision: 0.9224 - recall: 0.9049\n",
      "Epoch 33: val_loss improved from 1.40336 to 1.29000, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 33: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9290 - loss: 1.2559 - precision: 0.9354 - recall: 0.9159 - val_accuracy: 0.6667 - val_loss: 1.2900 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 34/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9176 - loss: 1.1847 - precision: 0.9245 - recall: 0.9061\n",
      "Epoch 34: val_loss improved from 1.29000 to 1.17013, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 34: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 48ms/step - accuracy: 0.9213 - loss: 1.1582 - precision: 0.9277 - recall: 0.9105 - val_accuracy: 0.6667 - val_loss: 1.1701 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 35/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9161 - loss: 1.0881 - precision: 0.9236 - recall: 0.9063\n",
      "Epoch 35: val_loss improved from 1.17013 to 1.08282, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 35: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9151 - loss: 1.0677 - precision: 0.9202 - recall: 0.9074 - val_accuracy: 0.6667 - val_loss: 1.0828 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 36/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.8996 - loss: 1.0124 - precision: 0.9069 - recall: 0.8927\n",
      "Epoch 36: val_loss improved from 1.08282 to 1.01629, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 36: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9198 - loss: 0.9843 - precision: 0.9263 - recall: 0.9120 - val_accuracy: 0.6667 - val_loss: 1.0163 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 37/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9040 - loss: 0.9295 - precision: 0.9113 - recall: 0.8968\n",
      "Epoch 37: val_loss improved from 1.01629 to 0.92747, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 37: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9198 - loss: 0.9091 - precision: 0.9269 - recall: 0.9097 - val_accuracy: 0.6667 - val_loss: 0.9275 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 38/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9345 - loss: 0.8567 - precision: 0.9404 - recall: 0.9189\n",
      "Epoch 38: val_loss improved from 0.92747 to 0.87189, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 38: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9344 - loss: 0.8394 - precision: 0.9395 - recall: 0.9228 - val_accuracy: 0.6667 - val_loss: 0.8719 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 39/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9357 - loss: 0.7910 - precision: 0.9440 - recall: 0.9329\n",
      "Epoch 39: val_loss improved from 0.87189 to 0.81799, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 39: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9367 - loss: 0.7765 - precision: 0.9430 - recall: 0.9321 - val_accuracy: 0.6667 - val_loss: 0.8180 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 40/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9299 - loss: 0.7384 - precision: 0.9291 - recall: 0.9077\n",
      "Epoch 40: val_loss improved from 0.81799 to 0.78721, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 40: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 49ms/step - accuracy: 0.9252 - loss: 0.7214 - precision: 0.9263 - recall: 0.9113 - val_accuracy: 0.6667 - val_loss: 0.7872 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 41/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9189 - loss: 0.6823 - precision: 0.9237 - recall: 0.9137\n",
      "Epoch 41: val_loss improved from 0.78721 to 0.71852, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 41: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9236 - loss: 0.6692 - precision: 0.9297 - recall: 0.9182 - val_accuracy: 0.6667 - val_loss: 0.7185 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 42/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9333 - loss: 0.6356 - precision: 0.9366 - recall: 0.9269\n",
      "Epoch 42: val_loss improved from 0.71852 to 0.66957, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 42: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 50ms/step - accuracy: 0.9344 - loss: 0.6210 - precision: 0.9406 - recall: 0.9290 - val_accuracy: 0.6667 - val_loss: 0.6696 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 43/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9293 - loss: 0.5875 - precision: 0.9302 - recall: 0.9267\n",
      "Epoch 43: val_loss improved from 0.66957 to 0.63349, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 43: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.9321 - loss: 0.5767 - precision: 0.9346 - recall: 0.9267 - val_accuracy: 0.6667 - val_loss: 0.6335 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 44/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9373 - loss: 0.5458 - precision: 0.9418 - recall: 0.9348\n",
      "Epoch 44: val_loss did not improve from 0.63349\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 45ms/step - accuracy: 0.9390 - loss: 0.5386 - precision: 0.9432 - recall: 0.9360 - val_accuracy: 0.6667 - val_loss: 0.6385 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 45/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9419 - loss: 0.5094 - precision: 0.9440 - recall: 0.9328\n",
      "Epoch 45: val_loss improved from 0.63349 to 0.52735, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 45: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9429 - loss: 0.5017 - precision: 0.9454 - recall: 0.9352 - val_accuracy: 0.6667 - val_loss: 0.5274 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 46/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9298 - loss: 0.4772 - precision: 0.9373 - recall: 0.9155\n",
      "Epoch 46: val_loss did not improve from 0.52735\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9344 - loss: 0.4693 - precision: 0.9383 - recall: 0.9267 - val_accuracy: 0.6481 - val_loss: 0.5312 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 47/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9298 - loss: 0.4463 - precision: 0.9350 - recall: 0.9228\n",
      "Epoch 47: val_loss improved from 0.52735 to 0.50354, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 47: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9321 - loss: 0.4380 - precision: 0.9366 - recall: 0.9236 - val_accuracy: 0.6667 - val_loss: 0.5035 - val_precision: 0.6604 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 48/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9262 - loss: 0.4215 - precision: 0.9277 - recall: 0.9178\n",
      "Epoch 48: val_loss improved from 0.50354 to 0.47841, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 48: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9360 - loss: 0.4114 - precision: 0.9391 - recall: 0.9282 - val_accuracy: 0.6481 - val_loss: 0.4784 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 49/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9288 - loss: 0.3966 - precision: 0.9294 - recall: 0.9185\n",
      "Epoch 49: val_loss improved from 0.47841 to 0.41640, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 49: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9375 - loss: 0.3875 - precision: 0.9393 - recall: 0.9321 - val_accuracy: 0.6667 - val_loss: 0.4164 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 50/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9181 - loss: 0.3703 - precision: 0.9233 - recall: 0.9163\n",
      "Epoch 50: val_loss did not improve from 0.41640\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 46ms/step - accuracy: 0.9344 - loss: 0.3630 - precision: 0.9378 - recall: 0.9306 - val_accuracy: 0.6667 - val_loss: 0.5137 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 51/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 45ms/step - accuracy: 0.9462 - loss: 0.3470 - precision: 0.9489 - recall: 0.9354\n",
      "Epoch 51: val_loss improved from 0.41640 to 0.37196, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 51: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 52ms/step - accuracy: 0.9506 - loss: 0.3393 - precision: 0.9548 - recall: 0.9452 - val_accuracy: 0.6667 - val_loss: 0.3720 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 52/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9385 - loss: 0.3268 - precision: 0.9400 - recall: 0.9335\n",
      "Epoch 52: val_loss did not improve from 0.37196\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9390 - loss: 0.3212 - precision: 0.9432 - recall: 0.9352 - val_accuracy: 0.6667 - val_loss: 0.4552 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 53/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9506 - loss: 0.3064 - precision: 0.9577 - recall: 0.9439\n",
      "Epoch 53: val_loss did not improve from 0.37196\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9460 - loss: 0.3029 - precision: 0.9509 - recall: 0.9406 - val_accuracy: 0.6667 - val_loss: 0.4490 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 54/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9369 - loss: 0.2945 - precision: 0.9390 - recall: 0.9301\n",
      "Epoch 54: val_loss did not improve from 0.37196\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.9375 - loss: 0.2884 - precision: 0.9400 - recall: 0.9313 - val_accuracy: 0.6667 - val_loss: 0.3981 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 55/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9371 - loss: 0.2763 - precision: 0.9420 - recall: 0.9343\n",
      "Epoch 55: val_loss did not improve from 0.37196\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 41ms/step - accuracy: 0.9383 - loss: 0.2721 - precision: 0.9409 - recall: 0.9329 - val_accuracy: 0.6667 - val_loss: 0.4679 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 56/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9330 - loss: 0.2672 - precision: 0.9415 - recall: 0.9263\n",
      "Epoch 56: val_loss did not improve from 0.37196\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 45ms/step - accuracy: 0.9390 - loss: 0.2590 - precision: 0.9459 - recall: 0.9313 - val_accuracy: 0.6667 - val_loss: 0.4575 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 57/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9499 - loss: 0.2459 - precision: 0.9521 - recall: 0.9416\n",
      "Epoch 57: val_loss improved from 0.37196 to 0.31841, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 57: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9529 - loss: 0.2412 - precision: 0.9579 - recall: 0.9475 - val_accuracy: 0.6667 - val_loss: 0.3184 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 58/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 44ms/step - accuracy: 0.9597 - loss: 0.2301 - precision: 0.9638 - recall: 0.9542\n",
      "Epoch 58: val_loss improved from 0.31841 to 0.27896, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 58: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9529 - loss: 0.2282 - precision: 0.9594 - recall: 0.9483 - val_accuracy: 0.5926 - val_loss: 0.2790 - val_precision: 0.6078 - val_recall: 0.5741 - learning_rate: 2.0000e-04\n",
      "Epoch 59/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9442 - loss: 0.2277 - precision: 0.9519 - recall: 0.9365\n",
      "Epoch 59: val_loss did not improve from 0.27896\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9452 - loss: 0.2224 - precision: 0.9501 - recall: 0.9398 - val_accuracy: 0.6667 - val_loss: 0.3660 - val_precision: 0.6538 - val_recall: 0.6296 - learning_rate: 2.0000e-04\n",
      "Epoch 60/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 42ms/step - accuracy: 0.9503 - loss: 0.2109 - precision: 0.9514 - recall: 0.9410\n",
      "Epoch 60: val_loss did not improve from 0.27896\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9498 - loss: 0.2083 - precision: 0.9525 - recall: 0.9429 - val_accuracy: 0.6667 - val_loss: 0.2803 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 61/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9565 - loss: 0.1990 - precision: 0.9609 - recall: 0.9533\n",
      "Epoch 61: val_loss improved from 0.27896 to 0.22229, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 61: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9599 - loss: 0.1968 - precision: 0.9642 - recall: 0.9552 - val_accuracy: 0.6852 - val_loss: 0.2223 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 62/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step - accuracy: 0.9519 - loss: 0.1889 - precision: 0.9585 - recall: 0.9467\n",
      "Epoch 62: val_loss improved from 0.22229 to 0.21087, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 62: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 57ms/step - accuracy: 0.9614 - loss: 0.1852 - precision: 0.9658 - recall: 0.9576 - val_accuracy: 0.7037 - val_loss: 0.2109 - val_precision: 0.6923 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 63/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9470 - loss: 0.1847 - precision: 0.9553 - recall: 0.9443\n",
      "Epoch 63: val_loss did not improve from 0.21087\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 42ms/step - accuracy: 0.9498 - loss: 0.1830 - precision: 0.9548 - recall: 0.9444 - val_accuracy: 0.6481 - val_loss: 0.3401 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 64/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9548 - loss: 0.1753 - precision: 0.9546 - recall: 0.9471\n",
      "Epoch 64: val_loss improved from 0.21087 to 0.19928, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 64: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9529 - loss: 0.1723 - precision: 0.9534 - recall: 0.9468 - val_accuracy: 0.7037 - val_loss: 0.1993 - val_precision: 0.7170 - val_recall: 0.7037 - learning_rate: 2.0000e-04\n",
      "Epoch 65/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9324 - loss: 0.1683 - precision: 0.9323 - recall: 0.9255\n",
      "Epoch 65: val_loss did not improve from 0.19928\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9444 - loss: 0.1667 - precision: 0.9456 - recall: 0.9390 - val_accuracy: 0.7037 - val_loss: 0.4398 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 2.0000e-04\n",
      "Epoch 66/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 38ms/step - accuracy: 0.9441 - loss: 0.1637 - precision: 0.9467 - recall: 0.9377\n",
      "Epoch 66: val_loss did not improve from 0.19928\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9537 - loss: 0.1602 - precision: 0.9557 - recall: 0.9483 - val_accuracy: 0.7593 - val_loss: 0.3071 - val_precision: 0.7593 - val_recall: 0.7593 - learning_rate: 2.0000e-04\n",
      "Epoch 67/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 36ms/step - accuracy: 0.9591 - loss: 0.1527 - precision: 0.9644 - recall: 0.9496\n",
      "Epoch 67: val_loss did not improve from 0.19928\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 39ms/step - accuracy: 0.9583 - loss: 0.1514 - precision: 0.9626 - recall: 0.9545 - val_accuracy: 0.6667 - val_loss: 0.3712 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 68/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9607 - loss: 0.1474 - precision: 0.9660 - recall: 0.9535\n",
      "Epoch 68: val_loss did not improve from 0.19928\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 44ms/step - accuracy: 0.9576 - loss: 0.1450 - precision: 0.9634 - recall: 0.9545 - val_accuracy: 0.6667 - val_loss: 0.3075 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 69/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 39ms/step - accuracy: 0.9509 - loss: 0.1417 - precision: 0.9538 - recall: 0.9493\n",
      "Epoch 69: val_loss did not improve from 0.19928\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 42ms/step - accuracy: 0.9606 - loss: 0.1376 - precision: 0.9627 - recall: 0.9560 - val_accuracy: 0.6667 - val_loss: 0.2472 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 70/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 35ms/step - accuracy: 0.9669 - loss: 0.1313 - precision: 0.9713 - recall: 0.9628\n",
      "Epoch 70: val_loss improved from 0.19928 to 0.17160, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 70: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 47ms/step - accuracy: 0.9599 - loss: 0.1308 - precision: 0.9627 - recall: 0.9568 - val_accuracy: 0.6852 - val_loss: 0.1716 - val_precision: 0.6981 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 71/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9498 - loss: 0.1303 - precision: 0.9512 - recall: 0.9314\n",
      "Epoch 71: val_loss did not improve from 0.17160\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9468 - loss: 0.1295 - precision: 0.9484 - recall: 0.9367 - val_accuracy: 0.6667 - val_loss: 0.2025 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 72/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9482 - loss: 0.1260 - precision: 0.9541 - recall: 0.9419\n",
      "Epoch 72: val_loss improved from 0.17160 to 0.16693, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 72: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 46ms/step - accuracy: 0.9560 - loss: 0.1223 - precision: 0.9617 - recall: 0.9506 - val_accuracy: 0.7407 - val_loss: 0.1669 - val_precision: 0.7407 - val_recall: 0.7407 - learning_rate: 2.0000e-04\n",
      "Epoch 73/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 37ms/step - accuracy: 0.9588 - loss: 0.1196 - precision: 0.9646 - recall: 0.9570\n",
      "Epoch 73: val_loss did not improve from 0.16693\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 40ms/step - accuracy: 0.9653 - loss: 0.1175 - precision: 0.9674 - recall: 0.9630 - val_accuracy: 0.6852 - val_loss: 0.4189 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 74/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 41ms/step - accuracy: 0.9623 - loss: 0.1123 - precision: 0.9696 - recall: 0.9618\n",
      "Epoch 74: val_loss improved from 0.16693 to 0.13741, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 74: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 48ms/step - accuracy: 0.9614 - loss: 0.1119 - precision: 0.9651 - recall: 0.9599 - val_accuracy: 0.7593 - val_loss: 0.1374 - val_precision: 0.7593 - val_recall: 0.7593 - learning_rate: 2.0000e-04\n",
      "Epoch 75/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 40ms/step - accuracy: 0.9517 - loss: 0.1099 - precision: 0.9592 - recall: 0.9477\n",
      "Epoch 75: val_loss did not improve from 0.13741\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m2s\u001b[0m 43ms/step - accuracy: 0.9591 - loss: 0.1098 - precision: 0.9634 - recall: 0.9537 - val_accuracy: 0.6852 - val_loss: 0.1689 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 76/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9606 - loss: 0.1056 - precision: 0.9626 - recall: 0.9595\n",
      "Epoch 76: val_loss did not improve from 0.13741\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9606 - loss: 0.1050 - precision: 0.9628 - recall: 0.9583 - val_accuracy: 0.6667 - val_loss: 0.1849 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 77/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9628 - loss: 0.1068 - precision: 0.9648 - recall: 0.9566\n",
      "Epoch 77: val_loss did not improve from 0.13741\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 79ms/step - accuracy: 0.9622 - loss: 0.1018 - precision: 0.9650 - recall: 0.9576 - val_accuracy: 0.6852 - val_loss: 0.1545 - val_precision: 0.6731 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 78/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 87ms/step - accuracy: 0.9651 - loss: 0.0965 - precision: 0.9673 - recall: 0.9642\n",
      "Epoch 78: val_loss did not improve from 0.13741\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 107ms/step - accuracy: 0.9606 - loss: 0.0967 - precision: 0.9635 - recall: 0.9583 - val_accuracy: 0.6667 - val_loss: 0.3189 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 79/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 97ms/step - accuracy: 0.9535 - loss: 0.0981 - precision: 0.9554 - recall: 0.9415\n",
      "Epoch 79: val_loss did not improve from 0.13741\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 104ms/step - accuracy: 0.9552 - loss: 0.0963 - precision: 0.9587 - recall: 0.9491 - val_accuracy: 0.6667 - val_loss: 0.3801 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 80/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9627 - loss: 0.0914 - precision: 0.9676 - recall: 0.9591\n",
      "Epoch 80: val_loss did not improve from 0.13741\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 68ms/step - accuracy: 0.9645 - loss: 0.0908 - precision: 0.9666 - recall: 0.9614 - val_accuracy: 0.6852 - val_loss: 0.1821 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 81/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 49ms/step - accuracy: 0.9540 - loss: 0.0892 - precision: 0.9589 - recall: 0.9512\n",
      "Epoch 81: val_loss did not improve from 0.13741\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 53ms/step - accuracy: 0.9591 - loss: 0.0897 - precision: 0.9626 - recall: 0.9537 - val_accuracy: 0.6667 - val_loss: 0.2189 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 82/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9585 - loss: 0.0851 - precision: 0.9677 - recall: 0.9517\n",
      "Epoch 82: val_loss did not improve from 0.13741\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.9660 - loss: 0.0839 - precision: 0.9704 - recall: 0.9614 - val_accuracy: 0.7037 - val_loss: 0.1770 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 2.0000e-04\n",
      "Epoch 83/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9646 - loss: 0.0813 - precision: 0.9694 - recall: 0.9640\n",
      "Epoch 83: val_loss did not improve from 0.13741\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 64ms/step - accuracy: 0.9668 - loss: 0.0802 - precision: 0.9713 - recall: 0.9660 - val_accuracy: 0.7037 - val_loss: 0.1625 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 2.0000e-04\n",
      "Epoch 84/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9662 - loss: 0.0795 - precision: 0.9669 - recall: 0.9638\n",
      "Epoch 84: val_loss did not improve from 0.13741\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9537 - loss: 0.0818 - precision: 0.9551 - recall: 0.9514 - val_accuracy: 0.7222 - val_loss: 0.2408 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 2.0000e-04\n",
      "Epoch 85/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9599 - loss: 0.0805 - precision: 0.9606 - recall: 0.9545\n",
      "Epoch 85: val_loss did not improve from 0.13741\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - accuracy: 0.9668 - loss: 0.0779 - precision: 0.9674 - recall: 0.9614 - val_accuracy: 0.7222 - val_loss: 0.1396 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 2.0000e-04\n",
      "Epoch 86/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9733 - loss: 0.0754 - precision: 0.9759 - recall: 0.9684\n",
      "Epoch 86: val_loss improved from 0.13741 to 0.11958, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 86: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 74ms/step - accuracy: 0.9699 - loss: 0.0755 - precision: 0.9721 - recall: 0.9668 - val_accuracy: 0.6667 - val_loss: 0.1196 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 87/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9634 - loss: 0.0749 - precision: 0.9658 - recall: 0.9582\n",
      "Epoch 87: val_loss did not improve from 0.11958\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.9699 - loss: 0.0721 - precision: 0.9728 - recall: 0.9676 - val_accuracy: 0.6667 - val_loss: 0.2443 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 88/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9676 - loss: 0.0709 - precision: 0.9683 - recall: 0.9647\n",
      "Epoch 88: val_loss improved from 0.11958 to 0.10855, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 88: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.9707 - loss: 0.0713 - precision: 0.9728 - recall: 0.9653 - val_accuracy: 0.6852 - val_loss: 0.1085 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 89/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9600 - loss: 0.0688 - precision: 0.9650 - recall: 0.9557\n",
      "Epoch 89: val_loss did not improve from 0.10855\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9568 - loss: 0.0692 - precision: 0.9610 - recall: 0.9514 - val_accuracy: 0.6852 - val_loss: 0.1711 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 90/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9300 - loss: 0.0790 - precision: 0.9324 - recall: 0.9278\n",
      "Epoch 90: val_loss did not improve from 0.10855\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 55ms/step - accuracy: 0.9460 - loss: 0.0734 - precision: 0.9501 - recall: 0.9406 - val_accuracy: 0.7037 - val_loss: 0.4422 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 2.0000e-04\n",
      "Epoch 91/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9714 - loss: 0.0694 - precision: 0.9714 - recall: 0.9652\n",
      "Epoch 91: val_loss did not improve from 0.10855\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.9676 - loss: 0.0668 - precision: 0.9682 - recall: 0.9622 - val_accuracy: 0.6667 - val_loss: 0.3035 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 92/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 47ms/step - accuracy: 0.9624 - loss: 0.0667 - precision: 0.9659 - recall: 0.9604\n",
      "Epoch 92: val_loss did not improve from 0.10855\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 50ms/step - accuracy: 0.9684 - loss: 0.0639 - precision: 0.9728 - recall: 0.9668 - val_accuracy: 0.6852 - val_loss: 0.1353 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 93/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9625 - loss: 0.0632 - precision: 0.9657 - recall: 0.9559\n",
      "Epoch 93: val_loss did not improve from 0.10855\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 61ms/step - accuracy: 0.9660 - loss: 0.0625 - precision: 0.9674 - recall: 0.9630 - val_accuracy: 0.6852 - val_loss: 0.2684 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 94/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9696 - loss: 0.0630 - precision: 0.9733 - recall: 0.9665\n",
      "Epoch 94: val_loss did not improve from 0.10855\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 88ms/step - accuracy: 0.9707 - loss: 0.0607 - precision: 0.9751 - recall: 0.9676 - val_accuracy: 0.6852 - val_loss: 0.1401 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 95/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9612 - loss: 0.0620 - precision: 0.9650 - recall: 0.9568\n",
      "Epoch 95: val_loss did not improve from 0.10855\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9676 - loss: 0.0598 - precision: 0.9712 - recall: 0.9622 - val_accuracy: 0.6667 - val_loss: 0.3661 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 96/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 50ms/step - accuracy: 0.9572 - loss: 0.0626 - precision: 0.9613 - recall: 0.9512\n",
      "Epoch 96: val_loss did not improve from 0.10855\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 53ms/step - accuracy: 0.9645 - loss: 0.0595 - precision: 0.9681 - recall: 0.9591 - val_accuracy: 0.7037 - val_loss: 0.1105 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 2.0000e-04\n",
      "Epoch 97/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9724 - loss: 0.0552 - precision: 0.9721 - recall: 0.9631\n",
      "Epoch 97: val_loss improved from 0.10855 to 0.09924, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 97: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 76ms/step - accuracy: 0.9792 - loss: 0.0545 - precision: 0.9790 - recall: 0.9730 - val_accuracy: 0.7037 - val_loss: 0.0992 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 2.0000e-04\n",
      "Epoch 98/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9682 - loss: 0.0540 - precision: 0.9721 - recall: 0.9661\n",
      "Epoch 98: val_loss did not improve from 0.09924\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 60ms/step - accuracy: 0.9738 - loss: 0.0532 - precision: 0.9767 - recall: 0.9715 - val_accuracy: 0.7037 - val_loss: 0.1493 - val_precision: 0.6981 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 99/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9833 - loss: 0.0505 - precision: 0.9865 - recall: 0.9767\n",
      "Epoch 99: val_loss improved from 0.09924 to 0.08011, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 99: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 64ms/step - accuracy: 0.9807 - loss: 0.0513 - precision: 0.9829 - recall: 0.9769 - val_accuracy: 0.7037 - val_loss: 0.0801 - val_precision: 0.6981 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 100/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9621 - loss: 0.0574 - precision: 0.9710 - recall: 0.9586\n",
      "Epoch 100: val_loss did not improve from 0.08011\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9722 - loss: 0.0516 - precision: 0.9782 - recall: 0.9691 - val_accuracy: 0.7037 - val_loss: 0.1323 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 2.0000e-04\n",
      "Epoch 101/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9770 - loss: 0.0489 - precision: 0.9809 - recall: 0.9654\n",
      "Epoch 101: val_loss did not improve from 0.08011\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 72ms/step - accuracy: 0.9761 - loss: 0.0484 - precision: 0.9805 - recall: 0.9707 - val_accuracy: 0.6481 - val_loss: 0.1645 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 102/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 53ms/step - accuracy: 0.9704 - loss: 0.0536 - precision: 0.9713 - recall: 0.9526\n",
      "Epoch 102: val_loss did not improve from 0.08011\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9715 - loss: 0.0488 - precision: 0.9735 - recall: 0.9645 - val_accuracy: 0.7407 - val_loss: 0.0843 - val_precision: 0.7500 - val_recall: 0.7222 - learning_rate: 2.0000e-04\n",
      "Epoch 103/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9723 - loss: 0.0476 - precision: 0.9772 - recall: 0.9683\n",
      "Epoch 103: val_loss did not improve from 0.08011\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 59ms/step - accuracy: 0.9691 - loss: 0.0473 - precision: 0.9743 - recall: 0.9653 - val_accuracy: 0.6667 - val_loss: 0.2285 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 104/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9784 - loss: 0.0461 - precision: 0.9808 - recall: 0.9760\n",
      "Epoch 104: val_loss did not improve from 0.08011\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9745 - loss: 0.0471 - precision: 0.9774 - recall: 0.9699 - val_accuracy: 0.6852 - val_loss: 0.1471 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 105/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9536 - loss: 0.0517 - precision: 0.9602 - recall: 0.9514\n",
      "Epoch 105: val_loss did not improve from 0.08011\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9545 - loss: 0.0511 - precision: 0.9588 - recall: 0.9506 - val_accuracy: 0.6852 - val_loss: 0.4104 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 106/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9765 - loss: 0.0474 - precision: 0.9801 - recall: 0.9684\n",
      "Epoch 106: val_loss did not improve from 0.08011\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9738 - loss: 0.0481 - precision: 0.9774 - recall: 0.9676 - val_accuracy: 0.7037 - val_loss: 0.2014 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 2.0000e-04\n",
      "Epoch 107/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9787 - loss: 0.0450 - precision: 0.9792 - recall: 0.9739\n",
      "Epoch 107: val_loss did not improve from 0.08011\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.9761 - loss: 0.0448 - precision: 0.9775 - recall: 0.9715 - val_accuracy: 0.6852 - val_loss: 0.1283 - val_precision: 0.6981 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 108/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9628 - loss: 0.0475 - precision: 0.9677 - recall: 0.9622\n",
      "Epoch 108: val_loss did not improve from 0.08011\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9699 - loss: 0.0447 - precision: 0.9729 - recall: 0.9691 - val_accuracy: 0.6852 - val_loss: 0.1725 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 109/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9754 - loss: 0.0421 - precision: 0.9772 - recall: 0.9744\n",
      "Epoch 109: val_loss did not improve from 0.08011\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 65ms/step - accuracy: 0.9715 - loss: 0.0417 - precision: 0.9744 - recall: 0.9707 - val_accuracy: 0.6667 - val_loss: 0.1677 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 110/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9716 - loss: 0.0409 - precision: 0.9720 - recall: 0.9673\n",
      "Epoch 110: val_loss did not improve from 0.08011\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9722 - loss: 0.0406 - precision: 0.9729 - recall: 0.9684 - val_accuracy: 0.7407 - val_loss: 0.0889 - val_precision: 0.7358 - val_recall: 0.7222 - learning_rate: 2.0000e-04\n",
      "Epoch 111/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9702 - loss: 0.0402 - precision: 0.9758 - recall: 0.9682\n",
      "Epoch 111: val_loss improved from 0.08011 to 0.07804, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 111: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 69ms/step - accuracy: 0.9722 - loss: 0.0395 - precision: 0.9744 - recall: 0.9691 - val_accuracy: 0.6852 - val_loss: 0.0780 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 112/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9748 - loss: 0.0386 - precision: 0.9751 - recall: 0.9734\n",
      "Epoch 112: val_loss did not improve from 0.07804\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9691 - loss: 0.0401 - precision: 0.9706 - recall: 0.9668 - val_accuracy: 0.6667 - val_loss: 0.3242 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 113/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9563 - loss: 0.0524 - precision: 0.9636 - recall: 0.9499\n",
      "Epoch 113: val_loss did not improve from 0.07804\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.9630 - loss: 0.0454 - precision: 0.9680 - recall: 0.9583 - val_accuracy: 0.6481 - val_loss: 0.5728 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 114/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9744 - loss: 0.0404 - precision: 0.9785 - recall: 0.9701\n",
      "Epoch 114: val_loss did not improve from 0.07804\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 70ms/step - accuracy: 0.9761 - loss: 0.0398 - precision: 0.9798 - recall: 0.9722 - val_accuracy: 0.6667 - val_loss: 0.2970 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 115/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9730 - loss: 0.0418 - precision: 0.9732 - recall: 0.9705\n",
      "Epoch 115: val_loss did not improve from 0.07804\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 0.9722 - loss: 0.0407 - precision: 0.9737 - recall: 0.9699 - val_accuracy: 0.7037 - val_loss: 0.0822 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 2.0000e-04\n",
      "Epoch 116/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9600 - loss: 0.0435 - precision: 0.9656 - recall: 0.9550\n",
      "Epoch 116: val_loss did not improve from 0.07804\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9645 - loss: 0.0423 - precision: 0.9689 - recall: 0.9606 - val_accuracy: 0.6481 - val_loss: 0.1789 - val_precision: 0.6481 - val_recall: 0.6481 - learning_rate: 2.0000e-04\n",
      "Epoch 117/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9639 - loss: 0.0439 - precision: 0.9666 - recall: 0.9609\n",
      "Epoch 117: val_loss did not improve from 0.07804\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9660 - loss: 0.0418 - precision: 0.9674 - recall: 0.9630 - val_accuracy: 0.7222 - val_loss: 0.1291 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 2.0000e-04\n",
      "Epoch 118/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9559 - loss: 0.0452 - precision: 0.9558 - recall: 0.9514\n",
      "Epoch 118: val_loss did not improve from 0.07804\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9668 - loss: 0.0416 - precision: 0.9674 - recall: 0.9606 - val_accuracy: 0.7222 - val_loss: 0.0970 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 2.0000e-04\n",
      "Epoch 119/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9783 - loss: 0.0381 - precision: 0.9837 - recall: 0.9736\n",
      "Epoch 119: val_loss did not improve from 0.07804\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.9753 - loss: 0.0381 - precision: 0.9775 - recall: 0.9722 - val_accuracy: 0.6667 - val_loss: 0.1595 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 120/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9617 - loss: 0.0395 - precision: 0.9670 - recall: 0.9615\n",
      "Epoch 120: val_loss did not improve from 0.07804\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.9722 - loss: 0.0368 - precision: 0.9767 - recall: 0.9707 - val_accuracy: 0.6667 - val_loss: 0.1686 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 121/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9821 - loss: 0.0346 - precision: 0.9830 - recall: 0.9811\n",
      "Epoch 121: val_loss improved from 0.07804 to 0.07380, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 121: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.9769 - loss: 0.0344 - precision: 0.9798 - recall: 0.9745 - val_accuracy: 0.7222 - val_loss: 0.0738 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 2.0000e-04\n",
      "Epoch 122/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9577 - loss: 0.0368 - precision: 0.9606 - recall: 0.9555\n",
      "Epoch 122: val_loss did not improve from 0.07380\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 81ms/step - accuracy: 0.9699 - loss: 0.0347 - precision: 0.9744 - recall: 0.9676 - val_accuracy: 0.6667 - val_loss: 0.1981 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 123/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9805 - loss: 0.0330 - precision: 0.9808 - recall: 0.9796\n",
      "Epoch 123: val_loss did not improve from 0.07380\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 76ms/step - accuracy: 0.9769 - loss: 0.0330 - precision: 0.9791 - recall: 0.9761 - val_accuracy: 0.6667 - val_loss: 0.0804 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 124/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9780 - loss: 0.0312 - precision: 0.9814 - recall: 0.9758\n",
      "Epoch 124: val_loss did not improve from 0.07380\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 65ms/step - accuracy: 0.9776 - loss: 0.0309 - precision: 0.9813 - recall: 0.9738 - val_accuracy: 0.6667 - val_loss: 0.1156 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 125/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9702 - loss: 0.0387 - precision: 0.9747 - recall: 0.9676\n",
      "Epoch 125: val_loss did not improve from 0.07380\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.9668 - loss: 0.0394 - precision: 0.9698 - recall: 0.9653 - val_accuracy: 0.6667 - val_loss: 0.6314 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 126/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9504 - loss: 0.0435 - precision: 0.9518 - recall: 0.9463\n",
      "Epoch 126: val_loss did not improve from 0.07380\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9591 - loss: 0.0396 - precision: 0.9619 - recall: 0.9552 - val_accuracy: 0.7222 - val_loss: 0.2745 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 2.0000e-04\n",
      "Epoch 127/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9769 - loss: 0.0342 - precision: 0.9768 - recall: 0.9729\n",
      "Epoch 127: val_loss did not improve from 0.07380\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9745 - loss: 0.0340 - precision: 0.9744 - recall: 0.9707 - val_accuracy: 0.6852 - val_loss: 0.1821 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 128/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9781 - loss: 0.0312 - precision: 0.9781 - recall: 0.9774\n",
      "Epoch 128: val_loss did not improve from 0.07380\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.9807 - loss: 0.0302 - precision: 0.9807 - recall: 0.9799 - val_accuracy: 0.6852 - val_loss: 0.1113 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 129/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9831 - loss: 0.0290 - precision: 0.9832 - recall: 0.9814\n",
      "Epoch 129: val_loss did not improve from 0.07380\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9823 - loss: 0.0321 - precision: 0.9845 - recall: 0.9807 - val_accuracy: 0.6667 - val_loss: 0.1376 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 130/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9558 - loss: 0.0376 - precision: 0.9608 - recall: 0.9411\n",
      "Epoch 130: val_loss did not improve from 0.07380\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9645 - loss: 0.0360 - precision: 0.9688 - recall: 0.9568 - val_accuracy: 0.6667 - val_loss: 0.4717 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 131/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9554 - loss: 0.0391 - precision: 0.9643 - recall: 0.9478\n",
      "Epoch 131: val_loss did not improve from 0.07380\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 58ms/step - accuracy: 0.9699 - loss: 0.0363 - precision: 0.9750 - recall: 0.9622 - val_accuracy: 0.7037 - val_loss: 0.2643 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 2.0000e-04\n",
      "Epoch 132/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9653 - loss: 0.0375 - precision: 0.9669 - recall: 0.9574\n",
      "Epoch 132: val_loss did not improve from 0.07380\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.9668 - loss: 0.0359 - precision: 0.9696 - recall: 0.9583 - val_accuracy: 0.6667 - val_loss: 0.2527 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 133/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 51ms/step - accuracy: 0.9692 - loss: 0.0327 - precision: 0.9754 - recall: 0.9681\n",
      "Epoch 133: val_loss did not improve from 0.07380\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 54ms/step - accuracy: 0.9738 - loss: 0.0323 - precision: 0.9767 - recall: 0.9722 - val_accuracy: 0.6852 - val_loss: 0.1334 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 134/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9740 - loss: 0.0307 - precision: 0.9813 - recall: 0.9733\n",
      "Epoch 134: val_loss did not improve from 0.07380\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 56ms/step - accuracy: 0.9799 - loss: 0.0302 - precision: 0.9829 - recall: 0.9784 - val_accuracy: 0.6852 - val_loss: 0.1056 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 135/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 62ms/step - accuracy: 0.9768 - loss: 0.0285 - precision: 0.9805 - recall: 0.9739\n",
      "Epoch 135: val_loss improved from 0.07380 to 0.04231, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 135: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.9807 - loss: 0.0277 - precision: 0.9822 - recall: 0.9792 - val_accuracy: 0.7593 - val_loss: 0.0423 - val_precision: 0.7736 - val_recall: 0.7593 - learning_rate: 2.0000e-04\n",
      "Epoch 136/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9824 - loss: 0.0277 - precision: 0.9835 - recall: 0.9817\n",
      "Epoch 136: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.9799 - loss: 0.0286 - precision: 0.9814 - recall: 0.9792 - val_accuracy: 0.6296 - val_loss: 0.1363 - val_precision: 0.6415 - val_recall: 0.6296 - learning_rate: 2.0000e-04\n",
      "Epoch 137/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9809 - loss: 0.0321 - precision: 0.9820 - recall: 0.9773\n",
      "Epoch 137: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9776 - loss: 0.0321 - precision: 0.9798 - recall: 0.9707 - val_accuracy: 0.6667 - val_loss: 0.2732 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 138/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9729 - loss: 0.0300 - precision: 0.9746 - recall: 0.9657\n",
      "Epoch 138: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 68ms/step - accuracy: 0.9792 - loss: 0.0289 - precision: 0.9806 - recall: 0.9761 - val_accuracy: 0.6667 - val_loss: 0.1253 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 139/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9863 - loss: 0.0274 - precision: 0.9867 - recall: 0.9844\n",
      "Epoch 139: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.9830 - loss: 0.0276 - precision: 0.9837 - recall: 0.9807 - val_accuracy: 0.6667 - val_loss: 0.1722 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 140/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9694 - loss: 0.0336 - precision: 0.9718 - recall: 0.9662\n",
      "Epoch 140: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.9761 - loss: 0.0306 - precision: 0.9783 - recall: 0.9722 - val_accuracy: 0.6667 - val_loss: 0.2082 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 141/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9647 - loss: 0.0328 - precision: 0.9676 - recall: 0.9604\n",
      "Epoch 141: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.9676 - loss: 0.0318 - precision: 0.9712 - recall: 0.9630 - val_accuracy: 0.6667 - val_loss: 0.3497 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 142/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 48ms/step - accuracy: 0.9790 - loss: 0.0306 - precision: 0.9799 - recall: 0.9767\n",
      "Epoch 142: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 51ms/step - accuracy: 0.9823 - loss: 0.0296 - precision: 0.9837 - recall: 0.9792 - val_accuracy: 0.6667 - val_loss: 0.1986 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 143/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9811 - loss: 0.0279 - precision: 0.9869 - recall: 0.9795\n",
      "Epoch 143: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 65ms/step - accuracy: 0.9823 - loss: 0.0276 - precision: 0.9876 - recall: 0.9799 - val_accuracy: 0.6667 - val_loss: 0.2014 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 144/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9798 - loss: 0.0284 - precision: 0.9797 - recall: 0.9763\n",
      "Epoch 144: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 58ms/step - accuracy: 0.9769 - loss: 0.0279 - precision: 0.9768 - recall: 0.9738 - val_accuracy: 0.7222 - val_loss: 0.1409 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 2.0000e-04\n",
      "Epoch 145/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9832 - loss: 0.0271 - precision: 0.9832 - recall: 0.9828\n",
      "Epoch 145: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 64ms/step - accuracy: 0.9792 - loss: 0.0279 - precision: 0.9792 - recall: 0.9784 - val_accuracy: 0.6852 - val_loss: 0.1740 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 146/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9807 - loss: 0.0313 - precision: 0.9835 - recall: 0.9749\n",
      "Epoch 146: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 62ms/step - accuracy: 0.9815 - loss: 0.0313 - precision: 0.9860 - recall: 0.9753 - val_accuracy: 0.6667 - val_loss: 0.5286 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.0000e-04\n",
      "Epoch 147/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9723 - loss: 0.0307 - precision: 0.9743 - recall: 0.9690\n",
      "Epoch 147: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9722 - loss: 0.0303 - precision: 0.9736 - recall: 0.9691 - val_accuracy: 0.6852 - val_loss: 0.2782 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.0000e-04\n",
      "Epoch 148/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9755 - loss: 0.0275 - precision: 0.9770 - recall: 0.9720\n",
      "Epoch 148: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 62ms/step - accuracy: 0.9753 - loss: 0.0273 - precision: 0.9775 - recall: 0.9730 - val_accuracy: 0.7593 - val_loss: 0.0624 - val_precision: 0.7593 - val_recall: 0.7593 - learning_rate: 2.0000e-04\n",
      "Epoch 149/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9688 - loss: 0.0335 - precision: 0.9730 - recall: 0.9684\n",
      "Epoch 149: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 66ms/step - accuracy: 0.9776 - loss: 0.0295 - precision: 0.9799 - recall: 0.9761 - val_accuracy: 0.7593 - val_loss: 0.1467 - val_precision: 0.7547 - val_recall: 0.7407 - learning_rate: 2.0000e-04\n",
      "Epoch 150/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9818 - loss: 0.0286 - precision: 0.9817 - recall: 0.9768\n",
      "Epoch 150: ReduceLROnPlateau reducing learning rate to 0.00011999999696854502.\n",
      "\n",
      "Epoch 150: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.9830 - loss: 0.0276 - precision: 0.9837 - recall: 0.9799 - val_accuracy: 0.7222 - val_loss: 0.0612 - val_precision: 0.7170 - val_recall: 0.7037 - learning_rate: 2.0000e-04\n",
      "Epoch 151/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9802 - loss: 0.0272 - precision: 0.9801 - recall: 0.9755\n",
      "Epoch 151: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 64ms/step - accuracy: 0.9830 - loss: 0.0267 - precision: 0.9830 - recall: 0.9799 - val_accuracy: 0.7222 - val_loss: 0.0823 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 1.2000e-04\n",
      "Epoch 152/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 46ms/step - accuracy: 0.9822 - loss: 0.0242 - precision: 0.9837 - recall: 0.9819\n",
      "Epoch 152: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 49ms/step - accuracy: 0.9861 - loss: 0.0234 - precision: 0.9869 - recall: 0.9853 - val_accuracy: 0.7593 - val_loss: 0.0702 - val_precision: 0.7593 - val_recall: 0.7593 - learning_rate: 1.2000e-04\n",
      "Epoch 153/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9907 - loss: 0.0221 - precision: 0.9907 - recall: 0.9907\n",
      "Epoch 153: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 74ms/step - accuracy: 0.9900 - loss: 0.0219 - precision: 0.9900 - recall: 0.9900 - val_accuracy: 0.7037 - val_loss: 0.1131 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 1.2000e-04\n",
      "Epoch 154/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9910 - loss: 0.0209 - precision: 0.9925 - recall: 0.9897\n",
      "Epoch 154: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.9915 - loss: 0.0208 - precision: 0.9923 - recall: 0.9907 - val_accuracy: 0.6852 - val_loss: 0.0939 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 1.2000e-04\n",
      "Epoch 155/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 56ms/step - accuracy: 0.9906 - loss: 0.0200 - precision: 0.9933 - recall: 0.9906\n",
      "Epoch 155: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 63ms/step - accuracy: 0.9923 - loss: 0.0197 - precision: 0.9931 - recall: 0.9923 - val_accuracy: 0.6852 - val_loss: 0.1140 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 1.2000e-04\n",
      "Epoch 156/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9913 - loss: 0.0202 - precision: 0.9913 - recall: 0.9896\n",
      "Epoch 156: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.9900 - loss: 0.0207 - precision: 0.9900 - recall: 0.9884 - val_accuracy: 0.6667 - val_loss: 0.2131 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 1.2000e-04\n",
      "Epoch 157/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 59ms/step - accuracy: 0.9890 - loss: 0.0227 - precision: 0.9890 - recall: 0.9881\n",
      "Epoch 157: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 67ms/step - accuracy: 0.9877 - loss: 0.0218 - precision: 0.9876 - recall: 0.9861 - val_accuracy: 0.6667 - val_loss: 0.2189 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 1.2000e-04\n",
      "Epoch 158/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 80ms/step - accuracy: 0.9863 - loss: 0.0209 - precision: 0.9877 - recall: 0.9781\n",
      "Epoch 158: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 86ms/step - accuracy: 0.9884 - loss: 0.0201 - precision: 0.9899 - recall: 0.9853 - val_accuracy: 0.6667 - val_loss: 0.2171 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 1.2000e-04\n",
      "Epoch 159/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9949 - loss: 0.0189 - precision: 0.9970 - recall: 0.9949\n",
      "Epoch 159: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 78ms/step - accuracy: 0.9938 - loss: 0.0191 - precision: 0.9954 - recall: 0.9938 - val_accuracy: 0.7778 - val_loss: 0.0445 - val_precision: 0.7736 - val_recall: 0.7593 - learning_rate: 1.2000e-04\n",
      "Epoch 160/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 66ms/step - accuracy: 0.9912 - loss: 0.0195 - precision: 0.9915 - recall: 0.9911\n",
      "Epoch 160: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 69ms/step - accuracy: 0.9923 - loss: 0.0188 - precision: 0.9930 - recall: 0.9915 - val_accuracy: 0.6667 - val_loss: 0.2342 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 1.2000e-04\n",
      "Epoch 161/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9978 - loss: 0.0172 - precision: 0.9981 - recall: 0.9978\n",
      "Epoch 161: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 70ms/step - accuracy: 0.9938 - loss: 0.0172 - precision: 0.9954 - recall: 0.9938 - val_accuracy: 0.6852 - val_loss: 0.1070 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 1.2000e-04\n",
      "Epoch 162/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9972 - loss: 0.0166 - precision: 0.9972 - recall: 0.9972\n",
      "Epoch 162: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 75ms/step - accuracy: 0.9961 - loss: 0.0164 - precision: 0.9961 - recall: 0.9961 - val_accuracy: 0.7222 - val_loss: 0.0856 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 1.2000e-04\n",
      "Epoch 163/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 60ms/step - accuracy: 0.9913 - loss: 0.0167 - precision: 0.9913 - recall: 0.9913\n",
      "Epoch 163: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.9907 - loss: 0.0172 - precision: 0.9907 - recall: 0.9907 - val_accuracy: 0.6667 - val_loss: 0.1310 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 1.2000e-04\n",
      "Epoch 164/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 63ms/step - accuracy: 0.9974 - loss: 0.0172 - precision: 0.9974 - recall: 0.9966\n",
      "Epoch 164: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.9923 - loss: 0.0180 - precision: 0.9923 - recall: 0.9915 - val_accuracy: 0.6852 - val_loss: 0.2585 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 1.2000e-04\n",
      "Epoch 165/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9840 - loss: 0.0204 - precision: 0.9860 - recall: 0.9840\n",
      "Epoch 165: ReduceLROnPlateau reducing learning rate to 7.199999818112701e-05.\n",
      "\n",
      "Epoch 165: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 82ms/step - accuracy: 0.9884 - loss: 0.0196 - precision: 0.9907 - recall: 0.9884 - val_accuracy: 0.6852 - val_loss: 0.2914 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 1.2000e-04\n",
      "Epoch 166/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9852 - loss: 0.0181 - precision: 0.9877 - recall: 0.9852\n",
      "Epoch 166: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 68ms/step - accuracy: 0.9869 - loss: 0.0179 - precision: 0.9884 - recall: 0.9869 - val_accuracy: 0.7222 - val_loss: 0.2467 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 7.2000e-05\n",
      "Epoch 167/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9969 - loss: 0.0168 - precision: 0.9986 - recall: 0.9944\n",
      "Epoch 167: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.9969 - loss: 0.0165 - precision: 0.9977 - recall: 0.9954 - val_accuracy: 0.7037 - val_loss: 0.1836 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 7.2000e-05\n",
      "Epoch 168/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9965 - loss: 0.0164 - precision: 0.9965 - recall: 0.9960\n",
      "Epoch 168: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.9969 - loss: 0.0162 - precision: 0.9969 - recall: 0.9961 - val_accuracy: 0.7037 - val_loss: 0.1299 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 7.2000e-05\n",
      "Epoch 169/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9991 - loss: 0.0155 - precision: 0.9991 - recall: 0.9991\n",
      "Epoch 169: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 75ms/step - accuracy: 0.9985 - loss: 0.0154 - precision: 0.9985 - recall: 0.9985 - val_accuracy: 0.7037 - val_loss: 0.0893 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 7.2000e-05\n",
      "Epoch 170/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9997 - loss: 0.0148 - precision: 0.9997 - recall: 0.9994\n",
      "Epoch 170: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 71ms/step - accuracy: 0.9985 - loss: 0.0148 - precision: 0.9985 - recall: 0.9977 - val_accuracy: 0.7222 - val_loss: 0.0660 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 7.2000e-05\n",
      "Epoch 171/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 72ms/step - accuracy: 0.9997 - loss: 0.0143 - precision: 0.9997 - recall: 0.9985\n",
      "Epoch 171: val_loss did not improve from 0.04231\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 76ms/step - accuracy: 0.9985 - loss: 0.0143 - precision: 0.9985 - recall: 0.9977 - val_accuracy: 0.7037 - val_loss: 0.0813 - val_precision: 0.7170 - val_recall: 0.7037 - learning_rate: 7.2000e-05\n",
      "Epoch 172/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9991 - loss: 0.0139 - precision: 0.9991 - recall: 0.9991\n",
      "Epoch 172: val_loss improved from 0.04231 to 0.03754, saving model to models/hybrid_best.weights.h5\n",
      "\n",
      "Epoch 172: finished saving model to models/hybrid_best.weights.h5\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.9977 - loss: 0.0140 - precision: 0.9977 - recall: 0.9977 - val_accuracy: 0.7407 - val_loss: 0.0375 - val_precision: 0.7358 - val_recall: 0.7222 - learning_rate: 7.2000e-05\n",
      "Epoch 173/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9964 - loss: 0.0138 - precision: 0.9969 - recall: 0.9964\n",
      "Epoch 173: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 72ms/step - accuracy: 0.9969 - loss: 0.0137 - precision: 0.9977 - recall: 0.9969 - val_accuracy: 0.7407 - val_loss: 0.0524 - val_precision: 0.7407 - val_recall: 0.7407 - learning_rate: 7.2000e-05\n",
      "Epoch 174/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9986 - loss: 0.0133 - precision: 0.9986 - recall: 0.9986\n",
      "Epoch 174: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 75ms/step - accuracy: 0.9985 - loss: 0.0132 - precision: 0.9985 - recall: 0.9985 - val_accuracy: 0.7037 - val_loss: 0.0630 - val_precision: 0.7170 - val_recall: 0.7037 - learning_rate: 7.2000e-05\n",
      "Epoch 175/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 75ms/step - accuracy: 0.9946 - loss: 0.0145 - precision: 0.9946 - recall: 0.9946\n",
      "Epoch 175: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.9946 - loss: 0.0145 - precision: 0.9946 - recall: 0.9946 - val_accuracy: 0.6667 - val_loss: 0.4003 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 7.2000e-05\n",
      "Epoch 176/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9925 - loss: 0.0140 - precision: 0.9925 - recall: 0.9925\n",
      "Epoch 176: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 83ms/step - accuracy: 0.9938 - loss: 0.0139 - precision: 0.9938 - recall: 0.9938 - val_accuracy: 0.7037 - val_loss: 0.1143 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 7.2000e-05\n",
      "Epoch 177/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 74ms/step - accuracy: 0.9983 - loss: 0.0133 - precision: 0.9983 - recall: 0.9983\n",
      "Epoch 177: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.9977 - loss: 0.0132 - precision: 0.9977 - recall: 0.9977 - val_accuracy: 0.7037 - val_loss: 0.1335 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 7.2000e-05\n",
      "Epoch 178/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9966 - loss: 0.0132 - precision: 0.9989 - recall: 0.9951\n",
      "Epoch 178: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 70ms/step - accuracy: 0.9977 - loss: 0.0130 - precision: 0.9992 - recall: 0.9969 - val_accuracy: 0.7037 - val_loss: 0.1138 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 7.2000e-05\n",
      "Epoch 179/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9935 - loss: 0.0134 - precision: 0.9977 - recall: 0.9935\n",
      "Epoch 179: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.9946 - loss: 0.0132 - precision: 0.9961 - recall: 0.9946 - val_accuracy: 0.6667 - val_loss: 0.3690 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 7.2000e-05\n",
      "Epoch 180/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9974 - loss: 0.0132 - precision: 0.9978 - recall: 0.9974\n",
      "Epoch 180: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 74ms/step - accuracy: 0.9961 - loss: 0.0137 - precision: 0.9969 - recall: 0.9961 - val_accuracy: 0.6667 - val_loss: 0.2985 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 7.2000e-05\n",
      "Epoch 181/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 0.9910 - loss: 0.0136 - precision: 0.9952 - recall: 0.9895\n",
      "Epoch 181: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 69ms/step - accuracy: 0.9946 - loss: 0.0136 - precision: 0.9961 - recall: 0.9931 - val_accuracy: 0.6667 - val_loss: 0.1586 - val_precision: 0.6792 - val_recall: 0.6667 - learning_rate: 7.2000e-05\n",
      "Epoch 182/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9932 - loss: 0.0136 - precision: 0.9932 - recall: 0.9930\n",
      "Epoch 182: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 73ms/step - accuracy: 0.9907 - loss: 0.0145 - precision: 0.9907 - recall: 0.9900 - val_accuracy: 0.6667 - val_loss: 0.2381 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 7.2000e-05\n",
      "Epoch 183/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 0.9939 - loss: 0.0135 - precision: 0.9954 - recall: 0.9939\n",
      "Epoch 183: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 79ms/step - accuracy: 0.9946 - loss: 0.0136 - precision: 0.9954 - recall: 0.9946 - val_accuracy: 0.7037 - val_loss: 0.1901 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 7.2000e-05\n",
      "Epoch 184/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9838 - loss: 0.0176 - precision: 0.9876 - recall: 0.9834\n",
      "Epoch 184: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 79ms/step - accuracy: 0.9846 - loss: 0.0162 - precision: 0.9876 - recall: 0.9830 - val_accuracy: 0.6667 - val_loss: 0.2549 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 7.2000e-05\n",
      "Epoch 185/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 0.9947 - loss: 0.0137 - precision: 0.9966 - recall: 0.9934\n",
      "Epoch 185: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 77ms/step - accuracy: 0.9954 - loss: 0.0136 - precision: 0.9961 - recall: 0.9946 - val_accuracy: 0.7037 - val_loss: 0.2357 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 7.2000e-05\n",
      "Epoch 186/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 69ms/step - accuracy: 0.9985 - loss: 0.0129 - precision: 0.9985 - recall: 0.9985\n",
      "Epoch 186: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 73ms/step - accuracy: 0.9992 - loss: 0.0128 - precision: 0.9992 - recall: 0.9992 - val_accuracy: 0.7037 - val_loss: 0.1430 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 7.2000e-05\n",
      "Epoch 187/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 76ms/step - accuracy: 0.9962 - loss: 0.0128 - precision: 0.9972 - recall: 0.9953\n",
      "Epoch 187: ReduceLROnPlateau reducing learning rate to 4.3199997162446376e-05.\n",
      "\n",
      "Epoch 187: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 0.9961 - loss: 0.0127 - precision: 0.9977 - recall: 0.9954 - val_accuracy: 0.7037 - val_loss: 0.0748 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 7.2000e-05\n",
      "Epoch 188/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 85ms/step - accuracy: 0.9932 - loss: 0.0125 - precision: 0.9933 - recall: 0.9922\n",
      "Epoch 188: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 95ms/step - accuracy: 0.9969 - loss: 0.0122 - precision: 0.9977 - recall: 0.9961 - val_accuracy: 0.7037 - val_loss: 0.0946 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 4.3200e-05\n",
      "Epoch 189/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 110ms/step - accuracy: 0.9953 - loss: 0.0123 - precision: 0.9953 - recall: 0.9953\n",
      "Epoch 189: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 116ms/step - accuracy: 0.9946 - loss: 0.0124 - precision: 0.9946 - recall: 0.9946 - val_accuracy: 0.7222 - val_loss: 0.0835 - val_precision: 0.7222 - val_recall: 0.7222 - learning_rate: 4.3200e-05\n",
      "Epoch 190/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.9983 - loss: 0.0119 - precision: 0.9983 - recall: 0.9971\n",
      "Epoch 190: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m11s\u001b[0m 128ms/step - accuracy: 0.9985 - loss: 0.0119 - precision: 0.9985 - recall: 0.9977 - val_accuracy: 0.7037 - val_loss: 0.1513 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 4.3200e-05\n",
      "Epoch 191/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 68ms/step - accuracy: 0.9984 - loss: 0.0120 - precision: 0.9984 - recall: 0.9984\n",
      "Epoch 191: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m7s\u001b[0m 73ms/step - accuracy: 0.9969 - loss: 0.0122 - precision: 0.9969 - recall: 0.9969 - val_accuracy: 0.7037 - val_loss: 0.1747 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 4.3200e-05\n",
      "Epoch 192/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 70ms/step - accuracy: 0.9987 - loss: 0.0117 - precision: 0.9987 - recall: 0.9987\n",
      "Epoch 192: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 88ms/step - accuracy: 0.9985 - loss: 0.0119 - precision: 0.9985 - recall: 0.9985 - val_accuracy: 0.7037 - val_loss: 0.0710 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 4.3200e-05\n",
      "Epoch 193/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 77ms/step - accuracy: 0.9967 - loss: 0.0116 - precision: 0.9967 - recall: 0.9967\n",
      "Epoch 193: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 83ms/step - accuracy: 0.9969 - loss: 0.0116 - precision: 0.9969 - recall: 0.9969 - val_accuracy: 0.7037 - val_loss: 0.0893 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 4.3200e-05\n",
      "Epoch 194/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 83ms/step - accuracy: 0.9983 - loss: 0.0114 - precision: 0.9983 - recall: 0.9979\n",
      "Epoch 194: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 92ms/step - accuracy: 0.9985 - loss: 0.0114 - precision: 0.9985 - recall: 0.9977 - val_accuracy: 0.7037 - val_loss: 0.1427 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 4.3200e-05\n",
      "Epoch 195/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 54ms/step - accuracy: 0.9997 - loss: 0.0113 - precision: 0.9997 - recall: 0.9983\n",
      "Epoch 195: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 61ms/step - accuracy: 0.9992 - loss: 0.0111 - precision: 0.9992 - recall: 0.9985 - val_accuracy: 0.7037 - val_loss: 0.1455 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 4.3200e-05\n",
      "Epoch 196/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 65ms/step - accuracy: 1.0000 - loss: 0.0109 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 196: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 68ms/step - accuracy: 1.0000 - loss: 0.0108 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.7037 - val_loss: 0.1179 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 4.3200e-05\n",
      "Epoch 197/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9991 - loss: 0.0107 - precision: 0.9991 - recall: 0.9991\n",
      "Epoch 197: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 60ms/step - accuracy: 0.9985 - loss: 0.0107 - precision: 0.9985 - recall: 0.9985 - val_accuracy: 0.7037 - val_loss: 0.0947 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 4.3200e-05\n",
      "Epoch 198/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9986 - loss: 0.0106 - precision: 0.9986 - recall: 0.9981\n",
      "Epoch 198: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 63ms/step - accuracy: 0.9985 - loss: 0.0107 - precision: 0.9985 - recall: 0.9969 - val_accuracy: 0.6852 - val_loss: 0.2017 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 4.3200e-05\n",
      "Epoch 199/300\n",
      "\u001b[1m53/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 67ms/step - accuracy: 0.9991 - loss: 0.0106 - precision: 0.9991 - recall: 0.9991\n",
      "Epoch 199: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 71ms/step - accuracy: 0.9985 - loss: 0.0106 - precision: 0.9985 - recall: 0.9985 - val_accuracy: 0.6852 - val_loss: 0.1559 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 4.3200e-05\n",
      "Epoch 200/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 57ms/step - accuracy: 0.9976 - loss: 0.0105 - precision: 0.9977 - recall: 0.9976\n",
      "Epoch 200: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 62ms/step - accuracy: 0.9961 - loss: 0.0108 - precision: 0.9969 - recall: 0.9961 - val_accuracy: 0.7037 - val_loss: 0.1587 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 4.3200e-05\n",
      "Epoch 201/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 64ms/step - accuracy: 0.9979 - loss: 0.0107 - precision: 0.9989 - recall: 0.9965\n",
      "Epoch 201: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 67ms/step - accuracy: 0.9954 - loss: 0.0109 - precision: 0.9961 - recall: 0.9938 - val_accuracy: 0.7037 - val_loss: 0.2431 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 4.3200e-05\n",
      "Epoch 202/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 55ms/step - accuracy: 0.9955 - loss: 0.0110 - precision: 0.9955 - recall: 0.9955\n",
      "Epoch 202: ReduceLROnPlateau reducing learning rate to 2.5919998734025285e-05.\n",
      "\n",
      "Epoch 202: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 59ms/step - accuracy: 0.9969 - loss: 0.0108 - precision: 0.9969 - recall: 0.9969 - val_accuracy: 0.7037 - val_loss: 0.1839 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 4.3200e-05\n",
      "Epoch 203/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 52ms/step - accuracy: 0.9983 - loss: 0.0110 - precision: 0.9983 - recall: 0.9983\n",
      "Epoch 203: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 56ms/step - accuracy: 0.9985 - loss: 0.0111 - precision: 0.9985 - recall: 0.9985 - val_accuracy: 0.6852 - val_loss: 0.2099 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.5920e-05\n",
      "Epoch 204/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 61ms/step - accuracy: 0.9983 - loss: 0.0107 - precision: 0.9983 - recall: 0.9966\n",
      "Epoch 204: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 66ms/step - accuracy: 0.9985 - loss: 0.0105 - precision: 0.9985 - recall: 0.9977 - val_accuracy: 0.7037 - val_loss: 0.2337 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 2.5920e-05\n",
      "Epoch 205/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 58ms/step - accuracy: 0.9998 - loss: 0.0102 - precision: 0.9998 - recall: 0.9998\n",
      "Epoch 205: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m3s\u001b[0m 61ms/step - accuracy: 0.9992 - loss: 0.0102 - precision: 0.9992 - recall: 0.9992 - val_accuracy: 0.6667 - val_loss: 0.2147 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.5920e-05\n",
      "Epoch 206/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 73ms/step - accuracy: 1.0000 - loss: 0.0100 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 206: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m4s\u001b[0m 82ms/step - accuracy: 1.0000 - loss: 0.0100 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.7037 - val_loss: 0.1920 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 2.5920e-05\n",
      "Epoch 207/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 0.9996 - loss: 0.0100 - precision: 1.0000 - recall: 0.9996\n",
      "Epoch 207: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 100ms/step - accuracy: 0.9985 - loss: 0.0101 - precision: 0.9992 - recall: 0.9985 - val_accuracy: 0.6852 - val_loss: 0.1647 - val_precision: 0.6852 - val_recall: 0.6852 - learning_rate: 2.5920e-05\n",
      "Epoch 208/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 94ms/step - accuracy: 0.9906 - loss: 0.0123 - precision: 0.9945 - recall: 0.9900\n",
      "Epoch 208: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 105ms/step - accuracy: 0.9961 - loss: 0.0109 - precision: 0.9977 - recall: 0.9954 - val_accuracy: 0.6667 - val_loss: 0.1798 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.5920e-05\n",
      "Epoch 209/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 71ms/step - accuracy: 1.0000 - loss: 0.0101 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 209: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m9s\u001b[0m 75ms/step - accuracy: 1.0000 - loss: 0.0100 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.6667 - val_loss: 0.2035 - val_precision: 0.6667 - val_recall: 0.6667 - learning_rate: 2.5920e-05\n",
      "Epoch 210/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 93ms/step - accuracy: 1.0000 - loss: 0.0098 - precision: 1.0000 - recall: 0.9990\n",
      "Epoch 210: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m8s\u001b[0m 113ms/step - accuracy: 1.0000 - loss: 0.0098 - precision: 1.0000 - recall: 0.9992 - val_accuracy: 0.7037 - val_loss: 0.1501 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 2.5920e-05\n",
      "Epoch 211/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 79ms/step - accuracy: 0.9989 - loss: 0.0098 - precision: 0.9989 - recall: 0.9989\n",
      "Epoch 211: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m5s\u001b[0m 86ms/step - accuracy: 0.9992 - loss: 0.0097 - precision: 0.9992 - recall: 0.9992 - val_accuracy: 0.6852 - val_loss: 0.1736 - val_precision: 0.6981 - val_recall: 0.6852 - learning_rate: 2.5920e-05\n",
      "Epoch 212/300\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 88ms/step - accuracy: 1.0000 - loss: 0.0096 - precision: 1.0000 - recall: 1.0000\n",
      "Epoch 212: val_loss did not improve from 0.03754\n",
      "\u001b[1m54/54\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m6s\u001b[0m 96ms/step - accuracy: 1.0000 - loss: 0.0096 - precision: 1.0000 - recall: 1.0000 - val_accuracy: 0.7037 - val_loss: 0.1593 - val_precision: 0.7037 - val_recall: 0.7037 - learning_rate: 2.5920e-05\n",
      "Epoch 212: early stopping\n",
      "Restoring model weights from the end of the best epoch: 172.\n",
      "\n",
      "âœ“ Hybrid model training complete with improvements!\n"
     ]
    }
   ],
   "source": [
    "# Train Hybrid model with ANTI-OVERFITTING strategy\n",
    "print(\"\\nğŸš€ Training IMPROVED Hybrid CNN-GRU model...\")\n",
    "print(\"ANTI-OVERFITTING IMPROVEMENTS:\")\n",
    "print(\"  â€¢ INCREASED L2 regularization (0.001 â†’ 0.01) to prevent memorization\")\n",
    "print(\"  â€¢ INCREASED dropout (0.2-0.35 â†’ 0.3-0.45) for better generalization\")\n",
    "print(\"  â€¢ Added residual connections for gradient flow\")\n",
    "print(\"  â€¢ Stronger focal loss (gamma=3.0) for hard examples\")\n",
    "print(\"  â€¢ Lower learning rate (0.0002) for stability\")\n",
    "print(\"  â€¢ Enhanced class weights for Low/High yield detection\")\n",
    "\n",
    "hybrid_callbacks = [\n",
    "    callbacks.EarlyStopping(\n",
    "        monitor='val_loss',\n",
    "        patience=40,  # Increased patience for slower learning rate\n",
    "        restore_best_weights=True,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ReduceLROnPlateau(\n",
    "        monitor='val_loss',\n",
    "        factor=0.6,  # Less aggressive reduction\n",
    "        patience=15,  # More patience\n",
    "        min_lr=1e-7,\n",
    "        verbose=1\n",
    "    ),\n",
    "    callbacks.ModelCheckpoint(\n",
    "        filepath='models/hybrid_best.weights.h5',\n",
    "        monitor='val_loss',\n",
    "        save_best_only=True,\n",
    "        save_weights_only=True,\n",
    "        verbose=1\n",
    "    )\n",
    "]\n",
    "\n",
    "# CRITICAL FIX: Amplify class weights for better Low/High yield detection\n",
    "# The original weights were too balanced, causing Medium bias\n",
    "hybrid_class_weight_amplified = {}\n",
    "for cls, weight in hybrid_class_weight_dict.items():\n",
    "    if cls == 0 or cls == 2:  # Low and High classes\n",
    "        hybrid_class_weight_amplified[cls] = weight * 1.5  # 50% boost\n",
    "    else:  # Medium class\n",
    "        hybrid_class_weight_amplified[cls] = weight * 0.7  # Reduce medium weight\n",
    "\n",
    "print(\"\\nAmplified Class Weights (to combat Medium bias):\")\n",
    "for cls, weight in hybrid_class_weight_amplified.items():\n",
    "    class_names = ['Low', 'Medium', 'High']\n",
    "    print(f\"  Class {cls} ({class_names[cls]}): {weight:.4f}\")\n",
    "\n",
    "history_hybrid = hybrid_model.fit(\n",
    "    [X_hybrid_temp_aug, X_hybrid_stat_aug],\n",
    "    y_hybrid_train_aug,\n",
    "    validation_data=([X_hybrid_temp_val_scaled, X_hybrid_stat_val_scaled], y_hybrid_val_onehot),\n",
    "    epochs=300,  # Keep high epochs due to early stopping\n",
    "    batch_size=24,  # Smaller batch for better gradient estimation\n",
    "    class_weight=hybrid_class_weight_amplified,  # Use amplified weights\n",
    "    callbacks=hybrid_callbacks,\n",
    "    verbose=1\n",
    ")\n",
    "\n",
    "print(\"\\nâœ“ Hybrid model training complete with improvements!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "7081f994",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ“Š Evaluating Hybrid model...\n",
      "\u001b[1m11/11\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m10s\u001b[0m 358ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 33ms/step\n",
      "\u001b[1m2/2\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 43ms/step\n",
      "\n",
      "================================================================================\n",
      "HYBRID CNN-GRU MODEL RESULTS\n",
      "================================================================================\n",
      "\n",
      "Train Set:\n",
      "  Accuracy:  1.0000\n",
      "  Precision: 1.0000\n",
      "  Recall:    1.0000\n",
      "  F1-Score:  1.0000\n",
      "\n",
      "Validation Set:\n",
      "  Accuracy:  0.7407\n",
      "  Precision: 0.8000\n",
      "  Recall:    0.7407\n",
      "  F1-Score:  0.7083\n",
      "\n",
      "Test Set:\n",
      "  Accuracy:  0.9074\n",
      "  Precision: 0.9082\n",
      "  Recall:    0.9074\n",
      "  F1-Score:  0.9073\n",
      "\n",
      "\n",
      "Test Set Confusion Matrix:\n",
      "[[18  0  0]\n",
      " [ 0 15  3]\n",
      " [ 0  2 16]]\n",
      "\n",
      "\n",
      "Test Set Classification Report:\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         Low       1.00      1.00      1.00        18\n",
      "      Medium       0.88      0.83      0.86        18\n",
      "        High       0.84      0.89      0.86        18\n",
      "\n",
      "    accuracy                           0.91        54\n",
      "   macro avg       0.91      0.91      0.91        54\n",
      "weighted avg       0.91      0.91      0.91        54\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Evaluate Hybrid model\n",
    "print(\"\\nğŸ“Š Evaluating Hybrid model...\")\n",
    "\n",
    "y_hybrid_pred_train_probs = hybrid_model.predict([X_hybrid_temp_train_scaled, X_hybrid_stat_train_scaled])\n",
    "y_hybrid_pred_val_probs = hybrid_model.predict([X_hybrid_temp_val_scaled, X_hybrid_stat_val_scaled])\n",
    "y_hybrid_pred_test_probs = hybrid_model.predict([X_hybrid_temp_test_scaled, X_hybrid_stat_test_scaled])\n",
    "\n",
    "y_hybrid_pred_train = np.argmax(y_hybrid_pred_train_probs, axis=1)\n",
    "y_hybrid_pred_val = np.argmax(y_hybrid_pred_val_probs, axis=1)\n",
    "y_hybrid_pred_test = np.argmax(y_hybrid_pred_test_probs, axis=1)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"HYBRID CNN-GRU MODEL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "for split_name, y_true, y_pred in [\n",
    "    ('Train', y_hybrid_train_cat, y_hybrid_pred_train),\n",
    "    ('Validation', y_hybrid_val_cat, y_hybrid_pred_val),\n",
    "    ('Test', y_hybrid_test_cat, y_hybrid_pred_test)\n",
    "]:\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    prec = precision_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    rec = recall_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    f1 = f1_score(y_true, y_pred, average='weighted', zero_division=0)\n",
    "    \n",
    "    print(f\"\\n{split_name} Set:\")\n",
    "    print(f\"  Accuracy:  {acc:.4f}\")\n",
    "    print(f\"  Precision: {prec:.4f}\")\n",
    "    print(f\"  Recall:    {rec:.4f}\")\n",
    "    print(f\"  F1-Score:  {f1:.4f}\")\n",
    "\n",
    "print(\"\\n\\nTest Set Confusion Matrix:\")\n",
    "print(confusion_matrix(y_hybrid_test_cat, y_hybrid_pred_test))\n",
    "\n",
    "print(\"\\n\\nTest Set Classification Report:\")\n",
    "print(classification_report(y_hybrid_test_cat, y_hybrid_pred_test,\n",
    "                          target_names=['Low', 'Medium', 'High']))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2f545db9",
   "metadata": {},
   "source": [
    "---\n",
    "## Model Comparison"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "c2ceb519",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "================================================================================\n",
      "FINAL MODEL COMPARISON (Test Set)\n",
      "================================================================================\n",
      "\n",
      "\n",
      "         Model  Accuracy  Precision  Recall  F1-Score\n",
      "           CNN    0.7407     0.7831  0.7407    0.7285\n",
      "           GRU    0.6852     0.8381  0.6852    0.5948\n",
      "Hybrid CNN-GRU    0.9074     0.9082  0.9074    0.9073\n",
      "\n",
      "\n",
      "Best Model by Metric:\n",
      "  Accuracy: Hybrid CNN-GRU (0.9074)\n",
      "  Precision: Hybrid CNN-GRU (0.9082)\n",
      "  Recall: Hybrid CNN-GRU (0.9074)\n",
      "  F1-Score: Hybrid CNN-GRU (0.9073)\n"
     ]
    }
   ],
   "source": [
    "# Compare all models\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL MODEL COMPARISON (Test Set)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "comparison_data = {\n",
    "    'Model': ['CNN', 'GRU', 'Hybrid CNN-GRU'],\n",
    "    'Accuracy': [\n",
    "        accuracy_score(y_cnn_test_cat, y_cnn_pred_test),\n",
    "        accuracy_score(y_gru_test_cat, y_gru_pred_test),\n",
    "        accuracy_score(y_hybrid_test_cat, y_hybrid_pred_test)\n",
    "    ],\n",
    "    'Precision': [\n",
    "        precision_score(y_cnn_test_cat, y_cnn_pred_test, average='weighted', zero_division=0),\n",
    "        precision_score(y_gru_test_cat, y_gru_pred_test, average='weighted', zero_division=0),\n",
    "        precision_score(y_hybrid_test_cat, y_hybrid_pred_test, average='weighted', zero_division=0)\n",
    "    ],\n",
    "    'Recall': [\n",
    "        recall_score(y_cnn_test_cat, y_cnn_pred_test, average='weighted', zero_division=0),\n",
    "        recall_score(y_gru_test_cat, y_gru_pred_test, average='weighted', zero_division=0),\n",
    "        recall_score(y_hybrid_test_cat, y_hybrid_pred_test, average='weighted', zero_division=0)\n",
    "    ],\n",
    "    'F1-Score': [\n",
    "        f1_score(y_cnn_test_cat, y_cnn_pred_test, average='weighted', zero_division=0),\n",
    "        f1_score(y_gru_test_cat, y_gru_pred_test, average='weighted', zero_division=0),\n",
    "        f1_score(y_hybrid_test_cat, y_hybrid_pred_test, average='weighted', zero_division=0)\n",
    "    ]\n",
    "}\n",
    "\n",
    "comparison_df = pd.DataFrame(comparison_data)\n",
    "comparison_df = comparison_df.round(4)\n",
    "\n",
    "print(\"\\n\")\n",
    "print(comparison_df.to_string(index=False))\n",
    "\n",
    "print(\"\\n\\nBest Model by Metric:\")\n",
    "for metric in ['Accuracy', 'Precision', 'Recall', 'F1-Score']:\n",
    "    best_idx = comparison_df[metric].idxmax()\n",
    "    best_model = comparison_df.loc[best_idx, 'Model']\n",
    "    best_score = comparison_df.loc[best_idx, metric]\n",
    "    print(f\"  {metric}: {best_model} ({best_score:.4f})\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e5bbdb0b",
   "metadata": {},
   "source": [
    "---\n",
    "## Save Models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "0b9dc176",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ’¾ Saving models...\n",
      "âœ“ Models saved:\n",
      "  - models/cnn_model.keras\n",
      "  - models/gru_model.keras\n",
      "  - models/hybrid_model.keras\n",
      "  - models/cnn_best.weights.h5\n",
      "  - models/gru_best.weights.h5\n",
      "  - models/hybrid_best.weights.h5\n",
      "\n",
      "ğŸ’¾ Saving scalers...\n",
      "âœ“ Scalers saved:\n",
      "  - models/cnn_scaler.pkl\n",
      "  - models/gru_scaler.pkl\n",
      "  - models/hybrid_temp_scaler.pkl\n",
      "  - models/hybrid_stat_scaler.pkl\n",
      "\n",
      "ğŸ’¾ Saving encoders...\n",
      "âœ“ Encoders saved:\n",
      "  - models/crop_encoder.pkl\n",
      "  - models/region_encoder.pkl\n",
      "\n",
      "âœ… All models, scalers, and encoders saved successfully!\n"
     ]
    }
   ],
   "source": [
    "# Save complete models\n",
    "print(\"\\nğŸ’¾ Saving models...\")\n",
    "\n",
    "cnn_model.save('models/cnn_model.keras')\n",
    "gru_model.save('models/gru_model.keras')\n",
    "hybrid_model.save('models/hybrid_model.keras')\n",
    "\n",
    "print(\"âœ“ Models saved:\")\n",
    "print(\"  - models/cnn_model.keras\")\n",
    "print(\"  - models/gru_model.keras\")\n",
    "print(\"  - models/hybrid_model.keras\")\n",
    "print(\"  - models/cnn_best.weights.h5\")\n",
    "print(\"  - models/gru_best.weights.h5\")\n",
    "print(\"  - models/hybrid_best.weights.h5\")\n",
    "\n",
    "# Save scalers and encoders\n",
    "import joblib\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving scalers...\")\n",
    "joblib.dump(scaler_cnn, 'models/cnn_scaler.pkl')\n",
    "joblib.dump(scaler_gru, 'models/gru_scaler.pkl')\n",
    "joblib.dump(scaler_hybrid_temp, 'models/hybrid_temp_scaler.pkl')\n",
    "joblib.dump(scaler_hybrid_stat, 'models/hybrid_stat_scaler.pkl')\n",
    "\n",
    "print(\"âœ“ Scalers saved:\")\n",
    "print(\"  - models/cnn_scaler.pkl\")\n",
    "print(\"  - models/gru_scaler.pkl\")\n",
    "print(\"  - models/hybrid_temp_scaler.pkl\")\n",
    "print(\"  - models/hybrid_stat_scaler.pkl\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving encoders...\")\n",
    "joblib.dump(crop_encoder, 'models/crop_encoder.pkl')\n",
    "joblib.dump(region_encoder, 'models/region_encoder.pkl')\n",
    "\n",
    "print(\"âœ“ Encoders saved:\")\n",
    "print(\"  - models/crop_encoder.pkl\")\n",
    "print(\"  - models/region_encoder.pkl\")\n",
    "\n",
    "print(\"\\nâœ… All models, scalers, and encoders saved successfully!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "6f9796c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAVING TRAINED MODELS\n",
      "================================================================================\n",
      "\n",
      "âœ“ Models directory created/verified\n",
      "\n",
      "ğŸ“Š Models in memory:\n",
      "  CNN model: Sequential\n",
      "  GRU model: Sequential\n",
      "  Hybrid model: Functional\n",
      "\n",
      "ğŸ’¾ Saving models...\n",
      "  âœ“ models/cnn_model.keras\n",
      "  âœ“ models/gru_model.keras\n",
      "  âœ“ models/hybrid_model.keras\n",
      "\n",
      "ğŸ’¾ Saving scalers...\n",
      "  âœ“ All 4 scalers saved\n",
      "\n",
      "ğŸ’¾ Saving encoders...\n",
      "  âœ“ All 2 encoders saved\n",
      "\n",
      "ğŸ“ Verifying files...\n",
      "  cnn_best.weights.h5                     2.07 MB\n",
      "  cnn_model.keras                         2.08 MB\n",
      "  cnn_scaler.pkl                          0.00 MB\n",
      "  crop_encoder.pkl                        0.00 MB\n",
      "  gru_best.weights.h5                     2.50 MB\n",
      "  gru_model.keras                         2.52 MB\n",
      "  gru_scaler.pkl                          0.00 MB\n",
      "  hybrid_best.weights.h5                  6.26 MB\n",
      "  hybrid_model.keras                      6.30 MB\n",
      "  hybrid_stat_scaler.pkl                  0.00 MB\n",
      "  hybrid_temp_scaler.pkl                  0.00 MB\n",
      "  region_encoder.pkl                      0.00 MB\n",
      "\n",
      "================================================================================\n",
      "âœ… ALL MODELS, SCALERS, AND ENCODERS SAVED SUCCESSFULLY!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "# VERIFY AND SAVE MODELS\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "import os\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING TRAINED MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Ensure models directory exists\n",
    "Path('models').mkdir(exist_ok=True)\n",
    "print(\"\\nâœ“ Models directory created/verified\")\n",
    "\n",
    "# Check models are in memory\n",
    "print(\"\\nğŸ“Š Models in memory:\")\n",
    "print(f\"  CNN model: {type(cnn_model).__name__}\")\n",
    "print(f\"  GRU model: {type(gru_model).__name__}\")\n",
    "print(f\"  Hybrid model: {type(hybrid_model).__name__}\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving models...\")\n",
    "cnn_model.save('models/cnn_model.keras')\n",
    "print(\"  âœ“ models/cnn_model.keras\")\n",
    "\n",
    "gru_model.save('models/gru_model.keras')\n",
    "print(\"  âœ“ models/gru_model.keras\")\n",
    "\n",
    "hybrid_model.save('models/hybrid_model.keras')\n",
    "print(\"  âœ“ models/hybrid_model.keras\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving scalers...\")\n",
    "joblib.dump(scaler_cnn, 'models/cnn_scaler.pkl')\n",
    "joblib.dump(scaler_gru, 'models/gru_scaler.pkl')\n",
    "joblib.dump(scaler_hybrid_temp, 'models/hybrid_temp_scaler.pkl')\n",
    "joblib.dump(scaler_hybrid_stat, 'models/hybrid_stat_scaler.pkl')\n",
    "print(\"  âœ“ All 4 scalers saved\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving encoders...\")\n",
    "joblib.dump(crop_encoder, 'models/crop_encoder.pkl')\n",
    "joblib.dump(region_encoder, 'models/region_encoder.pkl')\n",
    "print(\"  âœ“ All 2 encoders saved\")\n",
    "\n",
    "print(\"\\nğŸ“ Verifying files...\")\n",
    "files = sorted(os.listdir('models'))\n",
    "for f in files:\n",
    "    size = os.path.getsize(f'models/{f}') / (1024*1024)\n",
    "    print(f\"  {f:<35} {size:>8.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ALL MODELS, SCALERS, AND ENCODERS SAVED SUCCESSFULLY!\")\n",
    "print(\"=\"*80)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce09ce4f",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary\n",
    "\n",
    "âœ… **Three models trained successfully:**\n",
    "- **CNN**: 1D convolutions for temporal pattern extraction\n",
    "- **GRU**: Bidirectional recurrent network for sequence modeling\n",
    "- **Hybrid CNN-GRU**: Combined architecture with CNNâ†’GRU pipeline + static features\n",
    "\n",
    "âœ… **Improvements implemented:**\n",
    "- Lag features (previous 1-3 years' yields)\n",
    "- Data augmentation (2x training data)\n",
    "- Class weights for balanced learning\n",
    "- Bidirectional processing for temporal context\n",
    "\n",
    "âœ… **Next Steps:**\n",
    "Proceed to phase4_validation.ipynb for detailed analysis and ensemble modeling."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "c7709ae2",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================================================================\n",
      "SAVING MODELS\n",
      "================================================================================\n",
      "\n",
      "ğŸ’¾ Saving CNN model...\n",
      "  âœ“ models/cnn_model.keras\n",
      "\n",
      "ğŸ’¾ Saving GRU model...\n",
      "  âœ“ models/gru_model.keras\n",
      "\n",
      "ğŸ’¾ Saving Hybrid model...\n",
      "  âœ“ models/hybrid_model.keras\n",
      "\n",
      "ğŸ’¾ Saving scalers...\n",
      "  âœ“ All scalers saved\n",
      "\n",
      "ğŸ’¾ Saving encoders...\n",
      "  âœ“ All encoders saved\n",
      "\n",
      "ğŸ“ Files created:\n",
      "  cnn_best.weights.h5                     2.07 MB\n",
      "  cnn_model.keras                         2.08 MB\n",
      "  cnn_scaler.pkl                          0.00 MB\n",
      "  crop_encoder.pkl                        0.00 MB\n",
      "  gru_best.weights.h5                     2.50 MB\n",
      "  gru_model.keras                         2.52 MB\n",
      "  gru_scaler.pkl                          0.00 MB\n",
      "  hybrid_best.weights.h5                  6.26 MB\n",
      "  hybrid_model.keras                      6.30 MB\n",
      "  hybrid_stat_scaler.pkl                  0.00 MB\n",
      "  hybrid_temp_scaler.pkl                  0.00 MB\n",
      "  region_encoder.pkl                      0.00 MB\n",
      "\n",
      "================================================================================\n",
      "âœ… ALL FILES SAVED!\n",
      "================================================================================\n"
     ]
    }
   ],
   "source": [
    "\n",
    "# SAVE MODELS FROM KERNEL\n",
    "from pathlib import Path\n",
    "import joblib\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"SAVING MODELS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "Path('models').mkdir(exist_ok=True)\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving CNN model...\")\n",
    "cnn_model.save('models/cnn_model.keras')\n",
    "print(\"  âœ“ models/cnn_model.keras\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving GRU model...\")\n",
    "gru_model.save('models/gru_model.keras')\n",
    "print(\"  âœ“ models/gru_model.keras\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving Hybrid model...\")\n",
    "hybrid_model.save('models/hybrid_model.keras')\n",
    "print(\"  âœ“ models/hybrid_model.keras\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving scalers...\")\n",
    "joblib.dump(scaler_cnn, 'models/cnn_scaler.pkl')\n",
    "joblib.dump(scaler_gru, 'models/gru_scaler.pkl')\n",
    "joblib.dump(scaler_hybrid_temp, 'models/hybrid_temp_scaler.pkl')\n",
    "joblib.dump(scaler_hybrid_stat, 'models/hybrid_stat_scaler.pkl')\n",
    "print(\"  âœ“ All scalers saved\")\n",
    "\n",
    "print(\"\\nğŸ’¾ Saving encoders...\")\n",
    "joblib.dump(crop_encoder, 'models/crop_encoder.pkl')\n",
    "joblib.dump(region_encoder, 'models/region_encoder.pkl')\n",
    "print(\"  âœ“ All encoders saved\")\n",
    "\n",
    "import os\n",
    "print(\"\\nğŸ“ Files created:\")\n",
    "for f in sorted(os.listdir('models')):\n",
    "    size = os.path.getsize(f'models/{f}') / (1024*1024)\n",
    "    print(f\"  {f:<35} {size:>8.2f} MB\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"âœ… ALL FILES SAVED!\")\n",
    "print(\"=\"*80)\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
