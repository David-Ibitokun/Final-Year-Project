"""
Enhanced About Page - Project Information & Methodology
"""
import streamlit as st
import pandas as pd
import plotly.graph_objects as go

# Page configuration
st.set_page_config(
    page_title="About",
    page_icon="â„¹ï¸",
    layout="wide"
)

# Header
st.title("â„¹ï¸ About This Project")
st.markdown("### Deep Learning for Climate-Resilient Food Security Assessment in Nigeria")
st.divider()

# Overview Section
st.header("ğŸ¯ Project Overview")

col1, col2 = st.columns([2, 1])

with col1:
    st.subheader("Research Problem")
    st.success("""
    Nigeria faces significant food security challenges exacerbated by climate change. 
    Rising temperatures, erratic rainfall patterns, and extreme weather events threaten 
    agricultural productivity, impacting millions who depend on farming for their livelihoods.
    
    This project addresses this critical challenge by developing AI-powered crop yield 
    prediction models that help stakeholders understand, anticipate, and adapt to 
    climate-induced agricultural changes.
    """)
    
    st.subheader("Research Objectives")
    st.info("""
    - Develop deep learning models to predict crop yields under changing climate conditions
    - Assess climate change impacts on food security across Nigeria's geopolitical zones
    - Provide decision support tools for farmers, policymakers, and agricultural planners
    - Compare different AI architectures (CNN, GRU, Hybrid) for agricultural forecasting
    - Create an accessible, interactive system for yield prediction and analysis
    """)

with col2:
    st.subheader("ğŸ“Š Key Statistics")
    
    # Create a more compact metrics layout
    m1, m2 = st.columns(2)
    with m1:
        st.metric("ğŸ“… Years", "24", "2000-2023")
        st.metric("ğŸ—ºï¸ Zones", "6", "All Nigeria")
    with m2:
        st.metric("ğŸŒ¾ Crops", "3", "Major staples")
        st.metric("ğŸ¤– Models", "3", "Deep Learning")
    
    st.caption("**Crops:** Maize, Cassava, Yams")
    st.caption("**Models:** CNN, GRU, Hybrid")

st.divider()

# Methodology Section
st.header("ğŸ”¬ Methodology")

# Data Sources
with st.expander("ğŸ“Š Data Sources & Collection", expanded=True):
    col1, col2 = st.columns(2)

    with col1:
        st.markdown("#### ğŸŒ¡ï¸ Climate Data")
        st.info("""
        **Source:** NASA POWER API
        - **Temperature:** Daily mean, min, max (Â°C)
        - **Rainfall:** Daily precipitation (mm)
        - **Humidity:** Relative humidity (%)
        - **Solar Radiation:** Incident shortwave radiation
        
        *Temporal Resolution:* Daily aggregated to monthly  
        *Spatial Resolution:* 0.5Â° Ã— 0.5Â° grid
        """)
        
        st.markdown("#### ğŸŒ¾ Agricultural Data")
        st.info("""
        **Source:** FAOSTAT (FAO)
        - **Crop Yields:** National production data
        - **Production Area:** Harvested area (hectares)
        - **Production Quantity:** Total production (tonnes)
        
        *Coverage:* 2000-2023  
        *Crops:* Maize, Cassava, Yams
        """)

    with col2:
        st.markdown("#### ğŸŒ Environmental Data")
        st.info("""
        **Source:** NOAA Global Monitoring Laboratory
        - **COâ‚‚ Concentration:** Atmospheric COâ‚‚ (ppm)
        - **Measurement Site:** Mauna Loa Observatory
        - **Frequency:** Monthly averages
        
        *Temporal Coverage:* 2000-present  
        *Scope:* Global atmospheric representative
        """)
        
        st.markdown("#### ğŸï¸ Soil & Terrain Data")
        st.info("""
        **Sources:** ISDA Soil API & Open-Meteo
        - **Soil pH:** Topsoil acidity/alkalinity
        - **Nutrients:** Nitrogen, Phosphorus content
        - **Organic Matter:** Soil organic carbon
        - **Elevation:** Terrain height (m)
        
        *Spatial Resolution:* Regional averages  
        *Depth:* 0-20cm topsoil
        """)

# Data Processing Pipeline
with st.expander("âš™ï¸ Data Processing Pipeline", expanded=False):
    steps = [
    ("1. Data Collection", "Automated API calls to fetch climate, crop, and environmental data"),
    ("2. Data Cleaning", "Handle missing values, outliers, and data quality issues"),
    ("3. Regional Scaling", "Convert national yields to zone-specific estimates using suitability scores"),
    ("4. Feature Engineering", "Create 28+ engineered features (GDD, stress indices, lag features)"),
    ("5. Normalization", "Standardize features using StandardScaler for model training"),
    ("6. Sequence Creation", "Build temporal sequences for time-series models (12-month windows)"),
    ("7. Train/Val/Test Split", "Time-based splitting to prevent data leakage (75/12.5/12.5)")
]

    for step, description in steps:
        st.markdown(f"**{step}:** {description}")

# Regional Scaling Algorithm
with st.expander("ğŸ”¢ Regional Scaling Algorithm", expanded=False):
    col1, col2 = st.columns([1, 1])

    with col1:
        st.warning("""
        **Algorithm Overview**
        
        Since crop yield data is only available at the national level, we developed a 
        regional scaling algorithm to estimate zone-specific yields based on:
        - **Crop-Zone Suitability Scores:** Agronomic potential (70% weight)
        - **Climate Factors:** Temperature and rainfall patterns (30% weight)
        - **Stochastic Variation:** Random noise to simulate real-world variability
        """)
    
    with col2:
        st.code("""
# Regional Scaling Formula
Regional_Yield = National_Yield Ã— Scaling_Factor

Scaling_Factor = (
    0.7 Ã— Suitability_Score + 
    0.3 Ã— Climate_Factor
) Ã— Random_Noise(0.95, 1.05)

# Where:
# - Suitability_Score: Crop-specific zone rating (0-1)
# - Climate_Factor: Temperature & rainfall suitability
# - Random_Noise: Realistic variability injection
    """, language="python")

st.divider()

# Feature Engineering
st.header("ğŸ”§ Feature Engineering")

st.markdown("Our models use **28 engineered features** combining climate, soil, and temporal information:")

col1, col2 = st.columns(2)

with col1:
    st.subheader("Climate Features")
    st.markdown("""
    - **Growing Degree Days (GDD):** Accumulated heat units
    - **Cumulative Rainfall:** Season-to-date precipitation
    - **Temperature Extremes:** Heat and cold stress indicators
    - **Rainfall Anomalies:** Deviation from historical mean
    - **Drought/Flood Risk:** Binary stress indicators
    """)
    
    st.subheader("Temporal Features")
    st.markdown("""
    - **Days into Season:** Growing cycle progress
    - **Seasonal Indicators:** Rainy/dry season flags
    - **Peak Growing Flag:** Critical growth period indicator
    - **Month Encoding:** Cyclical temporal patterns
    """)

with col2:
    st.subheader("Lag Features")
    st.markdown("""
    - **Yield Lags:** Previous 1, 2, 3 years' yields
    - **Moving Averages:** 3-year rolling means
    - **Year-over-Year Changes:** Growth rate indicators
    - **Yield Volatility:** 3-year standard deviation
    """)
    
    st.subheader("Interaction Features")
    st.markdown("""
    - **pH Ã— Temperature:** Soil-climate interaction
    - **Nitrogen Ã— Rainfall:** Nutrient availability
    - **Elevation Ã— Temperature:** Altitude adjustment
    - **COâ‚‚ Ã— Temperature:** Carbon fertilization effect
    """)

# Total features summary
st.success("""
**Feature Summary:** 28 total features per model input
- **Basic Climate:** 4 features â€¢ **Soil Properties:** 4 features
- **Engineered Climate:** 11 features â€¢ **Historical/Lag:** 9 features
""")

st.divider()

# Model Architectures
st.header("ğŸ§  Model Architectures")

tab1, tab2, tab3 = st.tabs(["ğŸ”· CNN Model", "ğŸ”¶ GRU Model", "âš¡ Hybrid Model"])

with tab1:
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("Architecture Details")
        st.code("""
Input Layer: (batch_size, sequence_length, 28_features)
    â†“
Conv1D(64 filters, kernel=3, activation='relu')
    â†“ [Spatial feature extraction]
BatchNormalization()
    â†“
MaxPooling1D(pool_size=2)
    â†“ [Dimensionality reduction]
Dropout(0.2)
    â†“
Conv1D(128 filters, kernel=3, activation='relu')
    â†“ [Hierarchical pattern learning]
BatchNormalization()
    â†“
GlobalAveragePooling1D()
    â†“ [Feature aggregation]
Dense(64, activation='relu')
    â†“
Dropout(0.3)
    â†“
Dense(32, activation='relu')
    â†“
Dense(1, activation='linear')
    â†“
Output: Predicted Yield (kg/ha)
        """, language="python")
    
    with col2:
        st.subheader("Performance")
        st.metric("RÂ² Score", "0.78")
        st.metric("MAE", "0.52 t/ha")
        st.metric("RMSE", "0.68 t/ha")
        
        st.success("""
        **Best For:**
        - Quick predictions
        - Real-time applications
        - Resource-efficient
        """)

with tab2:
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("Architecture Details")
        st.code("""
Input Layer: (batch_size, 12_timesteps, 28_features)
    â†“
GRU(128 units, return_sequences=True)
    â†“ [Temporal sequence processing]
    â”‚ â€¢ Update gate: Memory update control
    â”‚ â€¢ Reset gate: Memory reset control
    â†“
Dropout(0.3)
    â†“ [Regularization]
GRU(64 units, return_sequences=False)
    â†“ [Temporal abstraction]
Dropout(0.3)
    â†“
Dense(32, activation='relu')
    â†“ [Decision layer]
BatchNormalization()
    â†“
Dense(1, activation='linear')
    â†“
Output: Predicted Yield (kg/ha)
        """, language="python")
    
    with col2:
        st.subheader("Performance")
        st.metric("RÂ² Score", "0.83")
        st.metric("MAE", "0.47 t/ha")
        st.metric("RMSE", "0.61 t/ha")
        
        st.success("""
        **Best For:**
        - Time series forecasting
        - Seasonal pattern capture
        - Production deployments
        """)

with tab3:
    col1, col2 = st.columns([2, 1])
    
    with col1:
        st.subheader("Architecture Details")
        st.code("""
Input: (batch_size, 12_timesteps, 28_features)
    â†“
    â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¬â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”
    â”‚                  â”‚                  â”‚
[CNN Branch]     [GRU Branch]    [Attention Branch]
Conv1D(64)       GRU(64)         MultiHeadAttn
MaxPool1D        Dropout         Dense
Conv1D(128)      GRU(32)         Dropout
GlobalAvgPool    â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
    â”‚                        â”‚
    â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜
              â†“
    Concatenate([CNN, GRU, Attention])
              â†“
    Dense(64, activation='relu')
              â†“
    Dropout(0.3)
              â†“
    Dense(32, activation='relu')
              â†“
    BatchNormalization()
              â†“
    Dense(1, activation='linear')
              â†“
    Output: Predicted Yield (kg/ha)
        """, language="python")
    
    with col2:
        st.subheader("Performance")
        st.metric("RÂ² Score", "0.87")
        st.metric("MAE", "0.43 t/ha")
        st.metric("RMSE", "0.56 t/ha")
        
        st.success("""
        **Best For:**
        - Critical predictions
        - Policy decisions
        - Maximum accuracy
        """)

st.divider()

# Training Configuration
st.header("âš™ï¸ Training Configuration")

col1, col2, col3 = st.columns(3)

with col1:
    st.subheader("Optimization")
    st.markdown("""
    - **Optimizer:** Adam
    - **Learning Rate:** 0.001
    - **LR Schedule:** ReduceLROnPlateau
      - Factor: 0.5
      - Patience: 10
      - Min LR: 1e-6
    - **Gradient Clipping:** 1.0
    """)

with col2:
    st.subheader("Training Setup")
    st.markdown("""
    - **Batch Size:** 32
    - **Max Epochs:** 100
    - **Early Stopping:** Patience 15
    - **Validation Split:** 15%
    - **Test Split:** 15%
    - **Shuffle:** Time-aware
    """)

with col3:
    st.subheader("Loss & Metrics")
    st.markdown("""
    - **Loss Function:** Huber Loss (Î´=1.0)
    - **Metrics:**
      - Mean Absolute Error (MAE)
      - Root Mean Squared Error (RMSE)
      - RÂ² Score
      - Mean Absolute Percentage Error
    """)

st.divider()

# Data Coverage
st.header("ğŸ“… Dataset Coverage")

col1, col2 = st.columns([2, 1])

with col1:
    # Create timeline visualization
    fig = go.Figure()
    
    periods = [
        dict(name="Training", start=2000, end=2017, color="#2ecc71"),
        dict(name="Validation", start=2018, end=2020, color="#f39c12"),
        dict(name="Testing", start=2021, end=2023, color="#e74c3c")
    ]
    
    for i, period in enumerate(periods):
        fig.add_trace(go.Bar(
            name=period['name'],
            x=[period['end'] - period['start'] + 1],
            y=[period['name']],
            orientation='h',
            marker=dict(color=period['color']),
            text=f"{period['start']}-{period['end']}",
            textposition='inside',
            hovertemplate=f"{period['name']}<br>Years: {period['start']}-{period['end']}<br>Duration: {period['end']-period['start']+1} years<extra></extra>"
        ))
    
    fig.update_layout(
        title="Temporal Data Split (2000-2023)",
        xaxis_title="Years",
        yaxis_title="",
        barmode='stack',
        height=300,
        showlegend=True
    )
    
    st.plotly_chart(fig, use_container_width=True)

with col2:
    st.subheader("Key Statistics")
    st.markdown("""
    - **Total Years:** 24 (2000-2023)
    - **Training:** 18 years (75%)
    - **Validation:** 3 years (12.5%)
    - **Testing:** 3 years (12.5%)
    
    - **Monthly Records:** 5,184
    - **Features per Record:** 28
    - **Total Data Points:** 145,152
    """)

# Spatial Coverage
with st.expander("ğŸ—ºï¸ Spatial Coverage", expanded=False):
    st.markdown("**Nigeria's Six Geopolitical Zones**")
    
    zones_info = [
        ("North-West", ["Jigawa", "Kaduna", "Kano", "Katsina", "Kebbi", "Sokoto", "Zamfara"]),
        ("North-East", ["Adamawa", "Bauchi", "Borno", "Gombe", "Taraba", "Yobe"]),
        ("North-Central", ["Benue", "FCT", "Kogi", "Kwara", "Nasarawa", "Niger", "Plateau"]),
        ("South-West", ["Ekiti", "Lagos", "Ogun", "Ondo", "Osun", "Oyo"]),
        ("South-East", ["Abia", "Anambra", "Ebonyi", "Enugu", "Imo"]),
        ("South-South", ["Akwa Ibom", "Bayelsa", "Cross River", "Delta", "Edo", "Rivers"])
    ]
    
    col1, col2 = st.columns(2)
    
    for i, (zone, states) in enumerate(zones_info):
        target_col = col1 if i < 3 else col2
        with target_col:
            st.markdown(f"**{zone}** ({len(states)} states)")
            st.caption(', '.join(states))
            st.write("")

st.divider()

# Technology Stack
st.header("ğŸ’» Technology Stack")

col1, col2, col3 = st.columns(3)

with col1:
    st.subheader("Deep Learning")
    st.markdown("""
    - TensorFlow 2.15+
    - Keras API
    - NumPy 1.24+
    - SciPy 1.11+
    - Scikit-learn 1.3+
    """)

with col2:
    st.subheader("Data & Visualization")
    st.markdown("""
    - Pandas 2.0+
    - Plotly 5.17+
    - Matplotlib 3.7+
    - Seaborn 0.12+
    - Streamlit 1.28+
    """)

with col3:
    st.subheader("APIs & Data Sources")
    st.markdown("""
    - NASA POWER API
    - NOAA MLO Data
    - FAOSTAT API
    - ISDA Soil API
    - Open-Meteo API
    """)

st.divider()

# Limitations & Future Work
st.header("âš ï¸ Limitations & Future Work")

col1, col2 = st.columns(2)

with col1:
    st.subheader("Current Limitations")
    st.warning("""
    - **National-to-Regional Scaling:** Yield data scaled from national level
    - **Limited Crop Coverage:** Only 3 crops included
    - **Aggregated Data:** Zone-level, not farm-specific
    - **No Pest/Disease Data:** Biotic stresses not modeled
    - **Management Assumptions:** Standard practices assumed
    - **Climate Data Gaps:** Some interpolation required
    """)

with col2:
    st.subheader("Future Enhancements")
    st.success("""
    - **Farm-Level Data:** Integrate actual field measurements
    - **More Crops:** Expand to 10+ crop varieties
    - **Real-Time Integration:** Live climate data feeds
    - **Pest/Disease Models:** Biotic stress prediction
    - **Economic Module:** Price and profit forecasting
    - **Mobile Application:** Farmer-friendly mobile app
    """)

st.divider()

# Acknowledgments
st.header("ğŸ™ Acknowledgments")

col1, col2, col3 = st.columns(3)

with col1:
    st.subheader("Data Providers")
    st.markdown("""
    - NASA POWER Project
    - NOAA Global Monitoring Lab
    - FAO Statistics Division
    - ISDA Africa Soil Service
    - Open-Meteo Project
    """)

with col2:
    st.subheader("Technology")
    st.markdown("""
    - TensorFlow/Keras Team
    - Streamlit Community
    - Python Scientific Community
    - Open Source Contributors
    """)

with col3:
    st.subheader("Academic Support")
    st.markdown("""
    - Bells University of Technology
    - Project Supervisors
    - Department of Computer Science
    - Research Community
    """)

st.divider()

# Footer
st.info("""
**ğŸ“š Final Year Project**

**Deep Learning for Climate-Resilient Food Security Assessment**

Department of Computer Science  
Bells University of Technology  
2024

ğŸŒ *Building climate-resilient agriculture through artificial intelligence*
""")