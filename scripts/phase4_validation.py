{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate-Food Security Modeling Pipeline\n",
    "## Phase 4: Model Validation and Interpretation\n",
    "\n",
    "This notebook provides comprehensive validation and interpretation of trained models:\n",
    "1. **Regional Performance Analysis** - By geopolitical zone and state\n",
    "2. **Crop-Specific Analysis** - Performance across different crops\n",
    "3. **Temporal Analysis** - Trends over test period\n",
    "4. **Climate Scenario Testing** - Future climate projections\n",
    "5. **Feature Importance** - Understanding model drivers\n",
    "6. **Error Analysis** - Residual patterns and outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy import stats\n",
    "\n",
    "# Model interpretation\n",
    "import shap\n",
    "\n",
    "# Utilities\n",
    "import joblib\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Trained Models and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "models_dir = Path('models')\n",
    "data_path = Path('project_data')\n",
    "splits_path = data_path / 'train_test_split'\n",
    "\n",
    "print(\"Loading trained models...\")\n",
    "\n",
    "# Load models\n",
    "fnn_model = keras.models.load_model(models_dir / 'fnn_model.keras')\n",
    "lstm_model = keras.models.load_model(models_dir / 'lstm_model.keras')\n",
    "hybrid_model = keras.models.load_model(models_dir / 'hybrid_model.keras')\n",
    "\n",
    "print(\"  âœ“ Models loaded\")\n",
    "\n",
    "# Load scalers\n",
    "fnn_scaler = joblib.load(models_dir / 'fnn_scaler.pkl')\n",
    "lstm_scaler = joblib.load(models_dir / 'lstm_scaler.pkl')\n",
    "temporal_scaler = joblib.load(models_dir / 'temporal_scaler.pkl')\n",
    "static_scaler = joblib.load(models_dir / 'static_scaler.pkl')\n",
    "\n",
    "print(\"  âœ“ Scalers loaded\")\n",
    "\n",
    "# Load encoders\n",
    "le_crop = joblib.load(models_dir / 'crop_encoder.pkl')\n",
    "le_zone = joblib.load(models_dir / 'zone_encoder.pkl')\n",
    "le_state = joblib.load(models_dir / 'state_encoder.pkl')\n",
    "\n",
    "print(\"  âœ“ Encoders loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "print(\"\\nLoading test datasets...\")\n",
    "\n",
    "fnn_test = pd.read_csv(splits_path / 'fnn' / 'test.csv')\n",
    "lstm_test = pd.read_csv(splits_path / 'lstm' / 'test.csv')\n",
    "hybrid_test = pd.read_csv(splits_path / 'hybrid' / 'test.csv')\n",
    "\n",
    "# Remove missing yields\n",
    "fnn_test = fnn_test.dropna(subset=['Yield_tonnes_per_ha'])\n",
    "lstm_test = lstm_test.dropna(subset=['Yield_tonnes_per_ha'])\n",
    "hybrid_test = hybrid_test.dropna(subset=['Yield_tonnes_per_ha'])\n",
    "\n",
    "print(f\"  FNN test: {fnn_test.shape}\")\n",
    "print(f\"  LSTM test: {lstm_test.shape}\")\n",
    "print(f\"  Hybrid test: {hybrid_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Regional Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Generate Predictions with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare FNN predictions with metadata\n",
    "print(\"Generating FNN predictions...\")\n",
    "\n",
    "# Define FNN features (same as Phase 3)\n",
    "fnn_feature_cols = [\n",
    "    'Avg_Temp_C', 'Min_Temp_C', 'Max_Temp_C', 'Temp_Range_C',\n",
    "    'Rainfall_mm', 'Rainy_Days', 'Max_Daily_Rainfall_mm', 'Rainfall_Intensity',\n",
    "    'Avg_Humidity_Percent', 'Min_Humidity_Percent', 'Max_Humidity_Percent',\n",
    "    'CO2_ppm',\n",
    "    'Heat_Stress_Days', 'Cold_Stress_Days', 'Drought_Index', 'Flood_Risk_Index',\n",
    "    'Soil_pH', 'Organic_Matter_Percent', 'Nitrogen_ppm', 'Phosphorus_ppm', \n",
    "    'Potassium_ppm', 'Cation_Exchange_Capacity', 'Bulk_Density', \n",
    "    'Water_Holding_Capacity_Percent'\n",
    "]\n",
    "\n",
    "# Encode categoricals\n",
    "fnn_test['Crop_encoded'] = le_crop.transform(fnn_test['Crop'])\n",
    "fnn_test['Zone_encoded'] = le_zone.transform(fnn_test['Geopolitical_Zone'])\n",
    "fnn_test['State_encoded'] = le_state.transform(fnn_test['State'])\n",
    "\n",
    "fnn_feature_cols.extend(['Crop_encoded', 'Zone_encoded'])\n",
    "\n",
    "# Prepare and predict\n",
    "X_fnn_test = fnn_test[fnn_feature_cols].values\n",
    "X_fnn_test_scaled = fnn_scaler.transform(X_fnn_test)\n",
    "fnn_predictions = fnn_model.predict(X_fnn_test_scaled).flatten()\n",
    "\n",
    "# Add predictions to dataframe\n",
    "fnn_results = fnn_test[['Year', 'Geopolitical_Zone', 'State', 'Crop', 'Yield_tonnes_per_ha']].copy()\n",
    "fnn_results['Predicted_Yield'] = fnn_predictions\n",
    "fnn_results['Residual'] = fnn_results['Yield_tonnes_per_ha'] - fnn_results['Predicted_Yield']\n",
    "fnn_results['Abs_Error'] = np.abs(fnn_results['Residual'])\n",
    "fnn_results['Pct_Error'] = (fnn_results['Abs_Error'] / fnn_results['Yield_tonnes_per_ha']) * 100\n",
    "\n",
    "print(f\"  âœ“ FNN predictions generated: {len(fnn_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Performance by Geopolitical Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics by zone\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE BY GEOPOLITICAL ZONE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "zone_performance = fnn_results.groupby('Geopolitical_Zone').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'N_samples': len(x),\n",
    "        'RMSE': np.sqrt(mean_squared_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield'])),\n",
    "        'MAE': mean_absolute_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'R2': r2_score(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'Mean_Actual': x['Yield_tonnes_per_ha'].mean(),\n",
    "        'Mean_Predicted': x['Predicted_Yield'].mean(),\n",
    "        'MAPE': x['Pct_Error'].mean()\n",
    "    })\n",
    ").round(4)\n",
    "\n",
    "zone_performance = zone_performance.sort_values('R2', ascending=False)\n",
    "print(\"\\n\", zone_performance.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize zone performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('FNN Model Performance by Geopolitical Zone', fontsize=16, fontweight='bold')\n",
    "\n",
    "zones = zone_performance.index\n",
    "\n",
    "# RÂ² by zone\n",
    "axes[0,0].barh(zones, zone_performance['R2'], color='steelblue')\n",
    "axes[0,0].set_xlabel('RÂ² Score')\n",
    "axes[0,0].set_title('RÂ² Score by Zone')\n",
    "axes[0,0].axvline(x=0.8, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0,0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# RMSE by zone\n",
    "axes[0,1].barh(zones, zone_performance['RMSE'], color='coral')\n",
    "axes[0,1].set_xlabel('RMSE (tonnes/ha)')\n",
    "axes[0,1].set_title('RMSE by Zone')\n",
    "axes[0,1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# MAE by zone\n",
    "axes[1,0].barh(zones, zone_performance['MAE'], color='lightgreen')\n",
    "axes[1,0].set_xlabel('MAE (tonnes/ha)')\n",
    "axes[1,0].set_title('MAE by Zone')\n",
    "axes[1,0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Sample size by zone\n",
    "axes[1,1].barh(zones, zone_performance['N_samples'], color='gold')\n",
    "axes[1,1].set_xlabel('Number of Samples')\n",
    "axes[1,1].set_title('Test Samples by Zone')\n",
    "axes[1,1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Performance by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics by state\n",
    "state_performance = fnn_results.groupby('State').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Zone': x['Geopolitical_Zone'].iloc[0],\n",
    "        'N_samples': len(x),\n",
    "        'RMSE': np.sqrt(mean_squared_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield'])),\n",
    "        'MAE': mean_absolute_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'R2': r2_score(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'Mean_Actual': x['Yield_tonnes_per_ha'].mean()\n",
    "    })\n",
    ").round(4)\n",
    "\n",
    "state_performance = state_performance.sort_values('R2', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 STATES BY MODEL PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(state_performance.head(10).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BOTTOM 10 STATES BY MODEL PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(state_performance.tail(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Crop-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance by crop\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE BY CROP TYPE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "crop_performance = fnn_results.groupby('Crop').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'N_samples': len(x),\n",
    "        'RMSE': np.sqrt(mean_squared_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield'])),\n",
    "        'MAE': mean_absolute_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'R2': r2_score(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'Mean_Actual': x['Yield_tonnes_per_ha'].mean(),\n",
    "        'Mean_Predicted': x['Predicted_Yield'].mean(),\n",
    "        'MAPE': x['Pct_Error'].mean()\n",
    "    })\n",
    ").round(4)\n",
    "\n",
    "crop_performance = crop_performance.sort_values('R2', ascending=False)\n",
    "print(\"\\n\", crop_performance.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize crop performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Model Performance by Crop Type', fontsize=16, fontweight='bold')\n",
    "\n",
    "crops = crop_performance.index\n",
    "\n",
    "# RÂ² by crop\n",
    "axes[0,0].barh(crops, crop_performance['R2'])\n",
    "axes[0,0].set_xlabel('RÂ² Score')\n",
    "axes[0,0].set_title('RÂ² Score by Crop')\n",
    "axes[0,0].axvline(x=0.8, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0,0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# RMSE by crop\n",
    "axes[0,1].barh(crops, crop_performance['RMSE'], color='coral')\n",
    "axes[0,1].set_xlabel('RMSE (tonnes/ha)')\n",
    "axes[0,1].set_title('RMSE by Crop')\n",
    "axes[0,1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Actual vs Predicted means\n",
    "x = np.arange(len(crops))\n",
    "width = 0.35\n",
    "axes[1,0].barh(x - width/2, crop_performance['Mean_Actual'], width, label='Actual', alpha=0.8)\n",
    "axes[1,0].barh(x + width/2, crop_performance['Mean_Predicted'], width, label='Predicted', alpha=0.8)\n",
    "axes[1,0].set_yticks(x)\n",
    "axes[1,0].set_yticklabels(crops)\n",
    "axes[1,0].set_xlabel('Mean Yield (tonnes/ha)')\n",
    "axes[1,0].set_title('Mean Actual vs Predicted Yield')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# MAPE by crop\n",
    "axes[1,1].barh(crops, crop_performance['MAPE'], color='gold')\n",
    "axes[1,1].set_xlabel('MAPE (%)')\n",
    "axes[1,1].set_title('Mean Absolute Percentage Error')\n",
    "axes[1,1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop-specific predictions over time\n",
    "crops_list = fnn_results['Crop'].unique()\n",
    "n_crops = len(crops_list)\n",
    "n_rows = (n_crops + 3) // 4  # 4 columns\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, 4, figsize=(20, n_rows*4))\n",
    "axes = axes.flatten() if n_crops > 1 else [axes]\n",
    "fig.suptitle('Yield Predictions by Crop (2020-2023)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, crop in enumerate(crops_list):\n",
    "    crop_data = fnn_results[fnn_results['Crop'] == crop].groupby('Year').agg({\n",
    "        'Yield_tonnes_per_ha': 'mean',\n",
    "        'Predicted_Yield': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    axes[idx].plot(crop_data['Year'], crop_data['Yield_tonnes_per_ha'], \n",
    "                   'o-', label='Actual', linewidth=2, markersize=8)\n",
    "    axes[idx].plot(crop_data['Year'], crop_data['Predicted_Yield'], \n",
    "                   's--', label='Predicted', linewidth=2, markersize=7)\n",
    "    axes[idx].set_title(crop, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Year')\n",
    "    axes[idx].set_ylabel('Yield (t/ha)')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "# Hide extra subplots\n",
    "for idx in range(n_crops, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance by year\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE BY YEAR (2020-2023)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "yearly_performance = fnn_results.groupby('Year').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'N_samples': len(x),\n",
    "        'RMSE': np.sqrt(mean_squared_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield'])),\n",
    "        'MAE': mean_absolute_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'R2': r2_score(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'Mean_Actual': x['Yield_tonnes_per_ha'].mean(),\n",
    "        'Mean_Predicted': x['Predicted_Yield'].mean()\n",
    "    })\n",
    ").round(4)\n",
    "\n",
    "print(\"\\n\", yearly_performance.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temporal trends\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Model Performance Trends Over Test Period', fontsize=16, fontweight='bold')\n",
    "\n",
    "years = yearly_performance.index\n",
    "\n",
    "# RÂ² over time\n",
    "axes[0,0].plot(years, yearly_performance['R2'], 'o-', linewidth=2, markersize=8)\n",
    "axes[0,0].set_xlabel('Year')\n",
    "axes[0,0].set_ylabel('RÂ² Score')\n",
    "axes[0,0].set_title('RÂ² Score Over Time')\n",
    "axes[0,0].axhline(y=0.8, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE over time\n",
    "axes[0,1].plot(years, yearly_performance['RMSE'], 'o-', linewidth=2, markersize=8, color='coral')\n",
    "axes[0,1].set_xlabel('Year')\n",
    "axes[0,1].set_ylabel('RMSE (tonnes/ha)')\n",
    "axes[0,1].set_title('RMSE Over Time')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE over time\n",
    "axes[1,0].plot(years, yearly_performance['MAE'], 'o-', linewidth=2, markersize=8, color='green')\n",
    "axes[1,0].set_xlabel('Year')\n",
    "axes[1,0].set_ylabel('MAE (tonnes/ha)')\n",
    "axes[1,0].set_title('MAE Over Time')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Mean yields over time\n",
    "axes[1,1].plot(years, yearly_performance['Mean_Actual'], 'o-', label='Actual', linewidth=2, markersize=8)\n",
    "axes[1,1].plot(years, yearly_performance['Mean_Predicted'], 's--', label='Predicted', linewidth=2, markersize=7)\n",
    "axes[1,1].set_xlabel('Year')\n",
    "axes[1,1].set_ylabel('Mean Yield (tonnes/ha)')\n",
    "axes[1,1].set_title('Mean Yield Trends')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Climate Scenario Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLIMATE SCENARIO TESTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define climate scenarios\n",
    "scenarios = {\n",
    "    'baseline': {'temp_change': 0, 'rain_change': 1.0, 'co2_change': 0},\n",
    "    'moderate_warming': {'temp_change': 1.5, 'rain_change': 0.95, 'co2_change': 30},\n",
    "    'high_warming': {'temp_change': 2.0, 'rain_change': 0.9, 'co2_change': 50},\n",
    "    'extreme_warming': {'temp_change': 3.0, 'rain_change': 0.85, 'co2_change': 80},\n",
    "    'wet_scenario': {'temp_change': 1.5, 'rain_change': 1.1, 'co2_change': 30},\n",
    "    'dry_scenario': {'temp_change': 2.0, 'rain_change': 0.8, 'co2_change': 50}\n",
    "}\n",
    "\n",
    "print(\"\\nTesting climate scenarios:\")\n",
    "for name, params in scenarios.items():\n",
    "    print(f\"  {name}: Temp +{params['temp_change']}Â°C, \" +\n",
    "          f\"Rain {params['rain_change']*100:.0f}%, CO2 +{params['co2_change']} ppm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run scenario analysis\n",
    "scenario_results = {}\n",
    "\n",
    "for scenario_name, changes in scenarios.items():\n",
    "    # Create modified test data\n",
    "    X_scenario = X_fnn_test.copy()\n",
    "    \n",
    "    # Get column indices for climate variables\n",
    "    temp_cols = [fnn_feature_cols.index(col) for col in ['Avg_Temp_C', 'Min_Temp_C', 'Max_Temp_C']]\n",
    "    rain_cols = [fnn_feature_cols.index(col) for col in ['Rainfall_mm', 'Max_Daily_Rainfall_mm']]\n",
    "    co2_col = fnn_feature_cols.index('CO2_ppm')\n",
    "    \n",
    "    # Apply changes\n",
    "    for col in temp_cols:\n",
    "        X_scenario[:, col] += changes['temp_change']\n",
    "    for col in rain_cols:\n",
    "        X_scenario[:, col] *= changes['rain_change']\n",
    "    X_scenario[:, co2_col] += changes['co2_change']\n",
    "    \n",
    "    # Scale and predict\n",
    "    X_scenario_scaled = fnn_scaler.transform(X_scenario)\n",
    "    predictions = fnn_model.predict(X_scenario_scaled).flatten()\n",
    "    \n",
    "    # Calculate impact\n",
    "    baseline_mean = fnn_results['Yield_tonnes_per_ha'].mean()\n",
    "    scenario_mean = predictions.mean()\n",
    "    change_pct = ((scenario_mean - baseline_mean) / baseline_mean) * 100\n",
    "    \n",
    "    scenario_results[scenario_name] = {\n",
    "        'mean_yield': scenario_mean,\n",
    "        'change_pct': change_pct,\n",
    "        'predictions': predictions\n",
    "    }\n",
    "\n",
    "print(\"\\nâœ“ Scenario analysis complete\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Display scenario results\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLIMATE SCENARIO IMPACTS ON CROP YIELDS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "scenario_df = pd.DataFrame({\n",
    "    'Scenario': list(scenario_results.keys()),\n",
    "    'Mean_Yield': [v['mean_yield'] for v in scenario_results.values()],\n",
    "    'Change_%': [v['change_pct'] for v in scenario_results.values()]\n",
    "}).round(4)\n",
    "\n",
    "print(\"\\n\", scenario_df.to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize scenario impacts\n",
    "fig, axes = plt.subplots(1, 2, figsize=(16, 6))\n",
    "fig.suptitle('Climate Scenario Impacts on Crop Yields', fontsize=16, fontweight='bold')\n",
    "\n",
    "scenarios_list = list(scenario_results.keys())\n",
    "mean_yields = [scenario_results[s]['mean_yield'] for s in scenarios_list]\n",
    "changes = [scenario_results[s]['change_pct'] for s in scenarios_list]\n",
    "\n",
    "# Mean yield by scenario\n",
    "colors = ['green' if c >= 0 else 'red' for c in changes]\n",
    "axes[0].barh(scenarios_list, mean_yields, color=colors, alpha=0.7)\n",
    "axes[0].axvline(x=scenario_results['baseline']['mean_yield'], \n",
    "                color='blue', linestyle='--', linewidth=2, label='Baseline')\n",
    "axes[0].set_xlabel('Mean Yield (tonnes/ha)')\n",
    "axes[0].set_title('Projected Mean Yield by Scenario')\n",
    "axes[0].legend()\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Percent change from baseline\n",
    "axes[1].barh(scenarios_list, changes, color=colors, alpha=0.7)\n",
    "axes[1].axvline(x=0, color='black', linestyle='-', linewidth=1)\n",
    "axes[1].set_xlabel('Change from Baseline (%)')\n",
    "axes[1].set_title('Yield Change from Baseline')\n",
    "axes[1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Scenario impacts by crop\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SCENARIO IMPACTS BY CROP\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "crop_scenario_impacts = {}\n",
    "\n",
    "for crop in crops_list:\n",
    "    crop_mask = fnn_results['Crop'] == crop\n",
    "    baseline_crop_mean = fnn_results[crop_mask]['Yield_tonnes_per_ha'].mean()\n",
    "    \n",
    "    crop_scenario_impacts[crop] = {}\n",
    "    for scenario_name in scenarios.keys():\n",
    "        if scenario_name == 'baseline':\n",
    "            continue\n",
    "        scenario_crop_mean = scenario_results[scenario_name]['predictions'][crop_mask.values].mean()\n",
    "        change_pct = ((scenario_crop_mean - baseline_crop_mean) / baseline_crop_mean) * 100\n",
    "        crop_scenario_impacts[crop][scenario_name] = change_pct\n",
    "\n",
    "# Create heatmap data\n",
    "crop_scenario_df = pd.DataFrame(crop_scenario_impacts).T\n",
    "\n",
    "# Plot heatmap\n",
    "plt.figure(figsize=(14, 8))\n",
    "sns.heatmap(crop_scenario_df, annot=True, fmt='.2f', cmap='RdYlGn', \n",
    "            center=0, cbar_kws={'label': 'Yield Change (%)'})\n",
    "plt.title('Crop Yield Changes Under Climate Scenarios (%)', fontsize=14, fontweight='bold', pad=20)\n",
    "plt.xlabel('Climate Scenario', fontsize=12)\n",
    "plt.ylabel('Crop', fontsize=12)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 5. Feature Importance Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FEATURE IMPORTANCE ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use a subset for SHAP (computationally expensive)\n",
    "n_samples_shap = min(500, len(X_fnn_test_scaled))\n",
    "X_shap = X_fnn_test_scaled[:n_samples_shap]\n",
    "\n",
    "print(f\"\\nCalculating SHAP values for {n_samples_shap} samples...\")\n",
    "print(\"(This may take a few minutes)\")\n",
    "\n",
    "# Create SHAP explainer\n",
    "explainer = shap.KernelExplainer(fnn_model.predict, X_shap[:100])  # Use 100 background samples\n",
    "shap_values = explainer.shap_values(X_shap)\n",
    "\n",
    "print(\"âœ“ SHAP values calculated\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature importance from SHAP\n",
    "shap_importance = pd.DataFrame({\n",
    "    'feature': fnn_feature_cols,\n",
    "    'importance': np.abs(shap_values).mean(axis=0)\n",
    "}).sort_values('importance', ascending=False)\n",
    "\n",
    "print(\"\\nTop 15 Most Important Features:\")\n",
    "print(\"=\"*80)\n",
    "print(shap_importance.head(15).to_string(index=False))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize feature importance\n",
    "fig, axes = plt.subplots(1, 2, figsize=(18, 8))\n",
    "fig.suptitle('Feature Importance Analysis', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Top 15 features\n",
    "top_15 = shap_importance.head(15)\n",
    "axes[0].barh(top_15['feature'], top_15['importance'])\n",
    "axes[0].set_xlabel('Mean |SHAP Value|')\n",
    "axes[0].set_title('Top 15 Most Important Features')\n",
    "axes[0].invert_yaxis()\n",
    "axes[0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Feature groups\n",
    "feature_groups = {\n",
    "    'Temperature': ['Avg_Temp_C', 'Min_Temp_C', 'Max_Temp_C', 'Temp_Range_C', 'Heat_Stress_Days', 'Cold_Stress_Days'],\n",
    "    'Rainfall': ['Rainfall_mm', 'Rainy_Days', 'Max_Daily_Rainfall_mm', 'Rainfall_Intensity', 'Drought_Index', 'Flood_Risk_Index'],\n",
    "    'Humidity': ['Avg_Humidity_Percent', 'Min_Humidity_Percent', 'Max_Humidity_Percent'],\n",
    "    'CO2': ['CO2_ppm'],\n",
    "    'Soil': ['Soil_pH', 'Organic_Matter_Percent', 'Nitrogen_ppm', 'Phosphorus_ppm', \n",
    "             'Potassium_ppm', 'Cation_Exchange_Capacity', 'Bulk_Density', 'Water_Holding_Capacity_Percent'],\n",
    "    'Location': ['Crop_encoded', 'Zone_encoded']\n",
    "}\n",
    "\n",
    "group_importance = {}\n",
    "for group, features in feature_groups.items():\n",
    "    group_features = shap_importance[shap_importance['feature'].isin(features)]\n",
    "    group_importance[group] = group_features['importance'].sum()\n",
    "\n",
    "groups = list(group_importance.keys())\n",
    "importances = list(group_importance.values())\n",
    "\n",
    "axes[1].bar(groups, importances, color='steelblue', alpha=0.7)\n",
    "axes[1].set_ylabel('Total SHAP Importance')\n",
    "axes[1].set_title('Feature Group Importance')\n",
    "axes[1].tick_params(axis='x', rotation=45)\n",
    "axes[1].grid(True, alpha=0.3, axis='y')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 6. Error Analysis and Diagnostics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual analysis\n",
    "residuals = fnn_results['Residual'].values\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"RESIDUAL ANALYSIS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nResidual Statistics:\")\n",
    "print(f\"  Mean: {residuals.mean():.4f}\")\n",
    "print(f\"  Std Dev: {residuals.std():.4f}\")\n",
    "print(f\"  Min: {residuals.min():.4f}\")\n",
    "print(f\"  Max: {residuals.max():.4f}\")\n",
    "print(f\"  Median: {np.median(residuals):.4f}\")\n",
    "\n",
    "# Test for normality\n",
    "_, p_value = stats.normaltest(residuals)\n",
    "print(f\"\\nNormality Test (p-value): {p_value:.4f}\")\n",
    "if p_value > 0.05:\n",
    "    print(\"  â†’ Residuals appear normally distributed\")\n",
    "else:\n",
    "    print(\"  â†’ Residuals deviate from normal distribution\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Residual diagnostic plots\n",
    "fig, axes = plt.subplots(2, 3, figsize=(18, 10))\n",
    "fig.suptitle('Residual Diagnostics', fontsize=16, fontweight='bold')\n",
    "\n",
    "# Residuals vs Predicted\n",
    "axes[0,0].scatter(fnn_results['Predicted_Yield'], residuals, alpha=0.5)\n",
    "axes[0,0].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0,0].set_xlabel('Predicted Yield')\n",
    "axes[0,0].set_ylabel('Residuals')\n",
    "axes[0,0].set_title('Residuals vs Predicted')\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals vs Actual\n",
    "axes[0,1].scatter(fnn_results['Yield_tonnes_per_ha'], residuals, alpha=0.5)\n",
    "axes[0,1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0,1].set_xlabel('Actual Yield')\n",
    "axes[0,1].set_ylabel('Residuals')\n",
    "axes[0,1].set_title('Residuals vs Actual')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Histogram of residuals\n",
    "axes[0,2].hist(residuals, bins=30, edgecolor='black', alpha=0.7)\n",
    "axes[0,2].axvline(x=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[0,2].set_xlabel('Residuals')\n",
    "axes[0,2].set_ylabel('Frequency')\n",
    "axes[0,2].set_title('Distribution of Residuals')\n",
    "axes[0,2].grid(True, alpha=0.3)\n",
    "\n",
    "# Q-Q plot\n",
    "stats.probplot(residuals, dist=\"norm\", plot=axes[1,0])\n",
    "axes[1,0].set_title('Q-Q Plot')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Residuals over time\n",
    "axes[1,1].scatter(fnn_results['Year'], residuals, alpha=0.5)\n",
    "axes[1,1].axhline(y=0, color='red', linestyle='--', linewidth=2)\n",
    "axes[1,1].set_xlabel('Year')\n",
    "axes[1,1].set_ylabel('Residuals')\n",
    "axes[1,1].set_title('Residuals Over Time')\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "# Absolute error by zone\n",
    "zone_errors = fnn_results.groupby('Geopolitical_Zone')['Abs_Error'].mean().sort_values()\n",
    "axes[1,2].barh(zone_errors.index, zone_errors.values)\n",
    "axes[1,2].set_xlabel('Mean Absolute Error')\n",
    "axes[1,2].set_title('Error by Geopolitical Zone')\n",
    "axes[1,2].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Identify outliers (large errors)\n",
    "threshold = fnn_results['Abs_Error'].quantile(0.95)  # Top 5% errors\n",
    "outliers = fnn_results[fnn_results['Abs_Error'] > threshold].copy()\n",
    "outliers = outliers.sort_values('Abs_Error', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(f\"OUTLIERS (Top 5% Errors > {threshold:.2f} tonnes/ha)\")\n",
    "print(\"=\"*80)\n",
    "print(f\"\\nNumber of outliers: {len(outliers)}\")\n",
    "print(f\"\\nTop 10 largest errors:\")\n",
    "print(outliers[['Year', 'Geopolitical_Zone', 'State', 'Crop', \n",
    "                'Yield_tonnes_per_ha', 'Predicted_Yield', 'Abs_Error']].head(10).to_string(index=False))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 7. Save Validation Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create outputs directory\n",
    "output_dir = Path('outputs/validation')\n",
    "output_dir.mkdir(parents=True, exist_ok=True)\n",
    "\n",
    "print(\"Saving validation results...\")\n",
    "\n",
    "# Save performance summaries\n",
    "zone_performance.to_csv(output_dir / 'zone_performance.csv')\n",
    "state_performance.to_csv(output_dir / 'state_performance.csv')\n",
    "crop_performance.to_csv(output_dir / 'crop_performance.csv')\n",
    "yearly_performance.to_csv(output_dir / 'yearly_performance.csv')\n",
    "print(\"  âœ“ Performance summaries saved\")\n",
    "\n",
    "# Save predictions with metadata\n",
    "fnn_results.to_csv(output_dir / 'fnn_test_predictions.csv', index=False)\n",
    "print(\"  âœ“ Detailed predictions saved\")\n",
    "\n",
    "# Save scenario results\n",
    "scenario_df.to_csv(output_dir / 'climate_scenario_results.csv', index=False)\n",
    "crop_scenario_df.to_csv(output_dir / 'crop_scenario_impacts.csv')\n",
    "print(\"  âœ“ Scenario analysis saved\")\n",
    "\n",
    "# Save feature importance\n",
    "shap_importance.to_csv(output_dir / 'feature_importance_shap.csv', index=False)\n",
    "print(\"  âœ“ Feature importance saved\")\n",
    "\n",
    "# Save outliers\n",
    "outliers.to_csv(output_dir / 'prediction_outliers.csv', index=False)\n",
    "print(\"  âœ“ Outliers saved\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create validation report\n",
    "validation_report = {\n",
    "    'validation_date': pd.Timestamp.now().strftime('%Y-%m-%d %H:%M:%S'),\n",
    "    'test_period': '2020-2023',\n",
    "    'n_test_samples': len(fnn_results),\n",
    "    \n",
    "    'overall_performance': {\n",
    "        'rmse': float(np.sqrt(mean_squared_error(fnn_results['Yield_tonnes_per_ha'], \n",
    "                                                   fnn_results['Predicted_Yield']))),\n",
    "        'mae': float(mean_absolute_error(fnn_results['Yield_tonnes_per_ha'], \n",
    "                                          fnn_results['Predicted_Yield'])),\n",
    "        'r2': float(r2_score(fnn_results['Yield_tonnes_per_ha'], \n",
    "                             fnn_results['Predicted_Yield']))\n",
    "    },\n",
    "    \n",
    "    'best_performing_zone': zone_performance.index[0],\n",
    "    'worst_performing_zone': zone_performance.index[-1],\n",
    "    \n",
    "    'best_performing_crop': crop_performance.index[0],\n",
    "    'worst_performing_crop': crop_performance.index[-1],\n",
    "    \n",
    "    'climate_scenario_impacts': {\n",
    "        'moderate_warming': float(scenario_results['moderate_warming']['change_pct']),\n",
    "        'high_warming': float(scenario_results['high_warming']['change_pct']),\n",
    "        'extreme_warming': float(scenario_results['extreme_warming']['change_pct'])\n",
    "    },\n",
    "    \n",
    "    'top_5_features': shap_importance.head(5)['feature'].tolist(),\n",
    "    \n",
    "    'outliers_count': len(outliers),\n",
    "    'outliers_threshold': float(threshold)\n",
    "}\n",
    "\n",
    "with open(output_dir / 'validation_report.json', 'w') as f:\n",
    "    json.dump(validation_report, f, indent=2)\n",
    "\n",
    "print(\"  âœ“ Validation report saved\")\n",
    "print(f\"\\nâœ“ All validation results saved to: {output_dir}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Summary Report"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"MODEL VALIDATION COMPLETE - SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(\"\\nðŸ“Š OVERALL PERFORMANCE:\")\n",
    "print(f\"  Test Period: 2020-2023\")\n",
    "print(f\"  Samples: {len(fnn_results):,}\")\n",
    "print(f\"  RMSE: {validation_report['overall_performance']['rmse']:.4f} tonnes/ha\")\n",
    "print(f\"  MAE: {validation_report['overall_performance']['mae']:.4f} tonnes/ha\")\n",
    "print(f\"  RÂ²: {validation_report['overall_performance']['r2']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸ—ºï¸ REGIONAL PERFORMANCE:\")\n",
    "print(f\"  Best Zone: {validation_report['best_performing_zone']}\")\n",
    "print(f\"    RÂ²: {zone_performance.loc[validation_report['best_performing_zone'], 'R2']:.4f}\")\n",
    "print(f\"  Worst Zone: {validation_report['worst_performing_zone']}\")\n",
    "print(f\"    RÂ²: {zone_performance.loc[validation_report['worst_performing_zone'], 'R2']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸŒ¾ CROP-SPECIFIC PERFORMANCE:\")\n",
    "print(f\"  Best Crop: {validation_report['best_performing_crop']}\")\n",
    "print(f\"    RÂ²: {crop_performance.loc[validation_report['best_performing_crop'], 'R2']:.4f}\")\n",
    "print(f\"  Worst Crop: {validation_report['worst_performing_crop']}\")\n",
    "print(f\"    RÂ²: {crop_performance.loc[validation_report['worst_performing_crop'], 'R2']:.4f}\")\n",
    "\n",
    "print(\"\\nðŸŒ¡ï¸ CLIMATE SCENARIO PROJECTIONS:\")\n",
    "print(f\"  Moderate Warming (+1.5Â°C, -5% rain): {validation_report['climate_scenario_impacts']['moderate_warming']:.2f}% yield change\")\n",
    "print(f\"  High Warming (+2.0Â°C, -10% rain): {validation_report['climate_scenario_impacts']['high_warming']:.2f}% yield change\")\n",
    "print(f\"  Extreme Warming (+3.0Â°C, -15% rain): {validation_report['climate_scenario_impacts']['extreme_warming']:.2f}% yield change\")\n",
    "\n",
    "print(\"\\nðŸ” TOP 5 MOST IMPORTANT FEATURES:\")\n",
    "for i, feature in enumerate(validation_report['top_5_features'], 1):\n",
    "    importance = shap_importance[shap_importance['feature'] == feature]['importance'].values[0]\n",
    "    print(f\"  {i}. {feature}: {importance:.4f}\")\n",
    "\n",
    "print(\"\\nâš ï¸ ERROR ANALYSIS:\")\n",
    "print(f\"  Outliers identified: {validation_report['outliers_count']}\")\n",
    "print(f\"  Outlier threshold: >{validation_report['outliers_threshold']:.2f} tonnes/ha error\")\n",
    "print(f\"  Residuals normally distributed: {'Yes' if p_value > 0.05 else 'No'}\")\n",
    "\n",
    "print(\"\\nðŸ’¾ SAVED OUTPUTS:\")\n",
    "print(f\"  Location: {output_dir}\")\n",
    "print(\"  Files:\")\n",
    "print(\"    - zone_performance.csv\")\n",
    "print(\"    - state_performance.csv\")\n",
    "print(\"    - crop_performance.csv\")\n",
    "print(\"    - yearly_performance.csv\")\n",
    "print(\"    - fnn_test_predictions.csv\")\n",
    "print(\"    - climate_scenario_results.csv\")\n",
    "print(\"    - crop_scenario_impacts.csv\")\n",
    "print(\"    - feature_importance_shap.csv\")\n",
    "print(\"    - prediction_outliers.csv\")\n",
    "print(\"    - validation_report.json\")\n",
    "\n",
    "print(\"\\nâœ… KEY INSIGHTS:\")\n",
    "if validation_report['overall_performance']['r2'] > 0.8:\n",
    "    print(\"  âœ“ Model shows strong predictive performance (RÂ² > 0.8)\")\n",
    "else:\n",
    "    print(\"  âš  Model performance could be improved (RÂ² < 0.8)\")\n",
    "\n",
    "if validation_report['climate_scenario_impacts']['high_warming'] < -5:\n",
    "    print(\"  âš  Significant yield losses projected under climate change\")\n",
    "elif validation_report['climate_scenario_impacts']['high_warming'] < 0:\n",
    "    print(\"  â†’ Moderate yield losses projected under climate change\")\n",
    "else:\n",
    "    print(\"  âœ“ Yields may be resilient under moderate climate change\")\n",
    "\n",
    "print(\"\\nâœ… NEXT STEPS:\")\n",
    "print(\"  1. Review zone-specific and crop-specific performance\")\n",
    "print(\"  2. Investigate outliers and high-error predictions\")\n",
    "print(\"  3. Consider ensemble models for improved performance\")\n",
    "print(\"  4. Develop policy recommendations based on scenario analysis\")\n",
    "print(\"  5. Create interactive dashboards for stakeholder communication\")\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Climate-Food Security Modeling Pipeline\n",
    "## Phase 4: Model Validation and Interpretation\n",
    "\n",
    "This notebook provides comprehensive validation and interpretation of trained models:\n",
    "1. **Regional Performance Analysis** - By geopolitical zone and state\n",
    "2. **Crop-Specific Analysis** - Performance across different crops\n",
    "3. **Temporal Analysis** - Trends over test period\n",
    "4. **Climate Scenario Testing** - Future climate projections\n",
    "5. **Feature Importance** - Understanding model drivers\n",
    "6. **Error Analysis** - Residual patterns and outliers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Setup and Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Standard libraries\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from pathlib import Path\n",
    "import json\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "# Deep Learning\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "\n",
    "# Scikit-learn\n",
    "from sklearn.metrics import mean_squared_error, r2_score, mean_absolute_error\n",
    "from scipy import stats\n",
    "\n",
    "# Model interpretation\n",
    "import shap\n",
    "\n",
    "# Utilities\n",
    "import joblib\n",
    "\n",
    "# Display settings\n",
    "pd.set_option('display.max_columns', None)\n",
    "pd.set_option('display.precision', 4)\n",
    "sns.set_style('whitegrid')\n",
    "plt.rcParams['figure.figsize'] = (12, 6)\n",
    "\n",
    "print(\"âœ“ All libraries imported successfully!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## Load Trained Models and Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define paths\n",
    "models_dir = Path('models')\n",
    "data_path = Path('project_data')\n",
    "splits_path = data_path / 'train_test_split'\n",
    "\n",
    "print(\"Loading trained models...\")\n",
    "\n",
    "# Load models\n",
    "fnn_model = keras.models.load_model(models_dir / 'fnn_model.keras')\n",
    "lstm_model = keras.models.load_model(models_dir / 'lstm_model.keras')\n",
    "hybrid_model = keras.models.load_model(models_dir / 'hybrid_model.keras')\n",
    "\n",
    "print(\"  âœ“ Models loaded\")\n",
    "\n",
    "# Load scalers\n",
    "fnn_scaler = joblib.load(models_dir / 'fnn_scaler.pkl')\n",
    "lstm_scaler = joblib.load(models_dir / 'lstm_scaler.pkl')\n",
    "temporal_scaler = joblib.load(models_dir / 'temporal_scaler.pkl')\n",
    "static_scaler = joblib.load(models_dir / 'static_scaler.pkl')\n",
    "\n",
    "print(\"  âœ“ Scalers loaded\")\n",
    "\n",
    "# Load encoders\n",
    "le_crop = joblib.load(models_dir / 'crop_encoder.pkl')\n",
    "le_zone = joblib.load(models_dir / 'zone_encoder.pkl')\n",
    "le_state = joblib.load(models_dir / 'state_encoder.pkl')\n",
    "\n",
    "print(\"  âœ“ Encoders loaded\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load test data\n",
    "print(\"\\nLoading test datasets...\")\n",
    "\n",
    "fnn_test = pd.read_csv(splits_path / 'fnn' / 'test.csv')\n",
    "lstm_test = pd.read_csv(splits_path / 'lstm' / 'test.csv')\n",
    "hybrid_test = pd.read_csv(splits_path / 'hybrid' / 'test.csv')\n",
    "\n",
    "# Remove missing yields\n",
    "fnn_test = fnn_test.dropna(subset=['Yield_tonnes_per_ha'])\n",
    "lstm_test = lstm_test.dropna(subset=['Yield_tonnes_per_ha'])\n",
    "hybrid_test = hybrid_test.dropna(subset=['Yield_tonnes_per_ha'])\n",
    "\n",
    "print(f\"  FNN test: {fnn_test.shape}\")\n",
    "print(f\"  LSTM test: {lstm_test.shape}\")\n",
    "print(f\"  Hybrid test: {hybrid_test.shape}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 1. Regional Performance Analysis"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.1 Generate Predictions with Metadata"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Prepare FNN predictions with metadata\n",
    "print(\"Generating FNN predictions...\")\n",
    "\n",
    "# Define FNN features (same as Phase 3)\n",
    "fnn_feature_cols = [\n",
    "    'Avg_Temp_C', 'Min_Temp_C', 'Max_Temp_C', 'Temp_Range_C',\n",
    "    'Rainfall_mm', 'Rainy_Days', 'Max_Daily_Rainfall_mm', 'Rainfall_Intensity',\n",
    "    'Avg_Humidity_Percent', 'Min_Humidity_Percent', 'Max_Humidity_Percent',\n",
    "    'CO2_ppm',\n",
    "    'Heat_Stress_Days', 'Cold_Stress_Days', 'Drought_Index', 'Flood_Risk_Index',\n",
    "    'Soil_pH', 'Organic_Matter_Percent', 'Nitrogen_ppm', 'Phosphorus_ppm', \n",
    "    'Potassium_ppm', 'Cation_Exchange_Capacity', 'Bulk_Density', \n",
    "    'Water_Holding_Capacity_Percent'\n",
    "]\n",
    "\n",
    "# Encode categoricals\n",
    "fnn_test['Crop_encoded'] = le_crop.transform(fnn_test['Crop'])\n",
    "fnn_test['Zone_encoded'] = le_zone.transform(fnn_test['Geopolitical_Zone'])\n",
    "fnn_test['State_encoded'] = le_state.transform(fnn_test['State'])\n",
    "\n",
    "fnn_feature_cols.extend(['Crop_encoded', 'Zone_encoded'])\n",
    "\n",
    "# Prepare and predict\n",
    "X_fnn_test = fnn_test[fnn_feature_cols].values\n",
    "X_fnn_test_scaled = fnn_scaler.transform(X_fnn_test)\n",
    "fnn_predictions = fnn_model.predict(X_fnn_test_scaled).flatten()\n",
    "\n",
    "# Add predictions to dataframe\n",
    "fnn_results = fnn_test[['Year', 'Geopolitical_Zone', 'State', 'Crop', 'Yield_tonnes_per_ha']].copy()\n",
    "fnn_results['Predicted_Yield'] = fnn_predictions\n",
    "fnn_results['Residual'] = fnn_results['Yield_tonnes_per_ha'] - fnn_results['Predicted_Yield']\n",
    "fnn_results['Abs_Error'] = np.abs(fnn_results['Residual'])\n",
    "fnn_results['Pct_Error'] = (fnn_results['Abs_Error'] / fnn_results['Yield_tonnes_per_ha']) * 100\n",
    "\n",
    "print(f\"  âœ“ FNN predictions generated: {len(fnn_results)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.2 Performance by Geopolitical Zone"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics by zone\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE BY GEOPOLITICAL ZONE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "zone_performance = fnn_results.groupby('Geopolitical_Zone').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'N_samples': len(x),\n",
    "        'RMSE': np.sqrt(mean_squared_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield'])),\n",
    "        'MAE': mean_absolute_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'R2': r2_score(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'Mean_Actual': x['Yield_tonnes_per_ha'].mean(),\n",
    "        'Mean_Predicted': x['Predicted_Yield'].mean(),\n",
    "        'MAPE': x['Pct_Error'].mean()\n",
    "    })\n",
    ").round(4)\n",
    "\n",
    "zone_performance = zone_performance.sort_values('R2', ascending=False)\n",
    "print(\"\\n\", zone_performance.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize zone performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('FNN Model Performance by Geopolitical Zone', fontsize=16, fontweight='bold')\n",
    "\n",
    "zones = zone_performance.index\n",
    "\n",
    "# RÂ² by zone\n",
    "axes[0,0].barh(zones, zone_performance['R2'], color='steelblue')\n",
    "axes[0,0].set_xlabel('RÂ² Score')\n",
    "axes[0,0].set_title('RÂ² Score by Zone')\n",
    "axes[0,0].axvline(x=0.8, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0,0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# RMSE by zone\n",
    "axes[0,1].barh(zones, zone_performance['RMSE'], color='coral')\n",
    "axes[0,1].set_xlabel('RMSE (tonnes/ha)')\n",
    "axes[0,1].set_title('RMSE by Zone')\n",
    "axes[0,1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# MAE by zone\n",
    "axes[1,0].barh(zones, zone_performance['MAE'], color='lightgreen')\n",
    "axes[1,0].set_xlabel('MAE (tonnes/ha)')\n",
    "axes[1,0].set_title('MAE by Zone')\n",
    "axes[1,0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Sample size by zone\n",
    "axes[1,1].barh(zones, zone_performance['N_samples'], color='gold')\n",
    "axes[1,1].set_xlabel('Number of Samples')\n",
    "axes[1,1].set_title('Test Samples by Zone')\n",
    "axes[1,1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 1.3 Performance by State"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate metrics by state\n",
    "state_performance = fnn_results.groupby('State').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'Zone': x['Geopolitical_Zone'].iloc[0],\n",
    "        'N_samples': len(x),\n",
    "        'RMSE': np.sqrt(mean_squared_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield'])),\n",
    "        'MAE': mean_absolute_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'R2': r2_score(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'Mean_Actual': x['Yield_tonnes_per_ha'].mean()\n",
    "    })\n",
    ").round(4)\n",
    "\n",
    "state_performance = state_performance.sort_values('R2', ascending=False)\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"TOP 10 STATES BY MODEL PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(state_performance.head(10).to_string())\n",
    "\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"BOTTOM 10 STATES BY MODEL PERFORMANCE\")\n",
    "print(\"=\"*80)\n",
    "print(state_performance.tail(10).to_string())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 2. Crop-Specific Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance by crop\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE BY CROP TYPE\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "crop_performance = fnn_results.groupby('Crop').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'N_samples': len(x),\n",
    "        'RMSE': np.sqrt(mean_squared_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield'])),\n",
    "        'MAE': mean_absolute_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'R2': r2_score(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'Mean_Actual': x['Yield_tonnes_per_ha'].mean(),\n",
    "        'Mean_Predicted': x['Predicted_Yield'].mean(),\n",
    "        'MAPE': x['Pct_Error'].mean()\n",
    "    })\n",
    ").round(4)\n",
    "\n",
    "crop_performance = crop_performance.sort_values('R2', ascending=False)\n",
    "print(\"\\n\", crop_performance.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize crop performance\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 12))\n",
    "fig.suptitle('Model Performance by Crop Type', fontsize=16, fontweight='bold')\n",
    "\n",
    "crops = crop_performance.index\n",
    "\n",
    "# RÂ² by crop\n",
    "axes[0,0].barh(crops, crop_performance['R2'])\n",
    "axes[0,0].set_xlabel('RÂ² Score')\n",
    "axes[0,0].set_title('RÂ² Score by Crop')\n",
    "axes[0,0].axvline(x=0.8, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0,0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# RMSE by crop\n",
    "axes[0,1].barh(crops, crop_performance['RMSE'], color='coral')\n",
    "axes[0,1].set_xlabel('RMSE (tonnes/ha)')\n",
    "axes[0,1].set_title('RMSE by Crop')\n",
    "axes[0,1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# Actual vs Predicted means\n",
    "x = np.arange(len(crops))\n",
    "width = 0.35\n",
    "axes[1,0].barh(x - width/2, crop_performance['Mean_Actual'], width, label='Actual', alpha=0.8)\n",
    "axes[1,0].barh(x + width/2, crop_performance['Mean_Predicted'], width, label='Predicted', alpha=0.8)\n",
    "axes[1,0].set_yticks(x)\n",
    "axes[1,0].set_yticklabels(crops)\n",
    "axes[1,0].set_xlabel('Mean Yield (tonnes/ha)')\n",
    "axes[1,0].set_title('Mean Actual vs Predicted Yield')\n",
    "axes[1,0].legend()\n",
    "axes[1,0].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "# MAPE by crop\n",
    "axes[1,1].barh(crops, crop_performance['MAPE'], color='gold')\n",
    "axes[1,1].set_xlabel('MAPE (%)')\n",
    "axes[1,1].set_title('Mean Absolute Percentage Error')\n",
    "axes[1,1].grid(True, alpha=0.3, axis='x')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Crop-specific predictions over time\n",
    "crops_list = fnn_results['Crop'].unique()\n",
    "n_crops = len(crops_list)\n",
    "n_rows = (n_crops + 3) // 4  # 4 columns\n",
    "\n",
    "fig, axes = plt.subplots(n_rows, 4, figsize=(20, n_rows*4))\n",
    "axes = axes.flatten() if n_crops > 1 else [axes]\n",
    "fig.suptitle('Yield Predictions by Crop (2020-2023)', fontsize=16, fontweight='bold')\n",
    "\n",
    "for idx, crop in enumerate(crops_list):\n",
    "    crop_data = fnn_results[fnn_results['Crop'] == crop].groupby('Year').agg({\n",
    "        'Yield_tonnes_per_ha': 'mean',\n",
    "        'Predicted_Yield': 'mean'\n",
    "    }).reset_index()\n",
    "    \n",
    "    axes[idx].plot(crop_data['Year'], crop_data['Yield_tonnes_per_ha'], \n",
    "                   'o-', label='Actual', linewidth=2, markersize=8)\n",
    "    axes[idx].plot(crop_data['Year'], crop_data['Predicted_Yield'], \n",
    "                   's--', label='Predicted', linewidth=2, markersize=7)\n",
    "    axes[idx].set_title(crop, fontweight='bold')\n",
    "    axes[idx].set_xlabel('Year')\n",
    "    axes[idx].set_ylabel('Yield (t/ha)')\n",
    "    axes[idx].legend()\n",
    "    axes[idx].grid(True, alpha=0.3)\n",
    "\n",
    "# Hide extra subplots\n",
    "for idx in range(n_crops, len(axes)):\n",
    "    axes[idx].axis('off')\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 3. Temporal Analysis"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Performance by year\n",
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PERFORMANCE BY YEAR (2020-2023)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "yearly_performance = fnn_results.groupby('Year').apply(\n",
    "    lambda x: pd.Series({\n",
    "        'N_samples': len(x),\n",
    "        'RMSE': np.sqrt(mean_squared_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield'])),\n",
    "        'MAE': mean_absolute_error(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'R2': r2_score(x['Yield_tonnes_per_ha'], x['Predicted_Yield']),\n",
    "        'Mean_Actual': x['Yield_tonnes_per_ha'].mean(),\n",
    "        'Mean_Predicted': x['Predicted_Yield'].mean()\n",
    "    })\n",
    ").round(4)\n",
    "\n",
    "print(\"\\n\", yearly_performance.to_string())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Visualize temporal trends\n",
    "fig, axes = plt.subplots(2, 2, figsize=(16, 10))\n",
    "fig.suptitle('Model Performance Trends Over Test Period', fontsize=16, fontweight='bold')\n",
    "\n",
    "years = yearly_performance.index\n",
    "\n",
    "# RÂ² over time\n",
    "axes[0,0].plot(years, yearly_performance['R2'], 'o-', linewidth=2, markersize=8)\n",
    "axes[0,0].set_xlabel('Year')\n",
    "axes[0,0].set_ylabel('RÂ² Score')\n",
    "axes[0,0].set_title('RÂ² Score Over Time')\n",
    "axes[0,0].axhline(y=0.8, color='red', linestyle='--', alpha=0.5)\n",
    "axes[0,0].grid(True, alpha=0.3)\n",
    "\n",
    "# RMSE over time\n",
    "axes[0,1].plot(years, yearly_performance['RMSE'], 'o-', linewidth=2, markersize=8, color='coral')\n",
    "axes[0,1].set_xlabel('Year')\n",
    "axes[0,1].set_ylabel('RMSE (tonnes/ha)')\n",
    "axes[0,1].set_title('RMSE Over Time')\n",
    "axes[0,1].grid(True, alpha=0.3)\n",
    "\n",
    "# MAE over time\n",
    "axes[1,0].plot(years, yearly_performance['MAE'], 'o-', linewidth=2, markersize=8, color='green')\n",
    "axes[1,0].set_xlabel('Year')\n",
    "axes[1,0].set_ylabel('MAE (tonnes/ha)')\n",
    "axes[1,0].set_title('MAE Over Time')\n",
    "axes[1,0].grid(True, alpha=0.3)\n",
    "\n",
    "# Mean yields over time\n",
    "axes[1,1].plot(years, yearly_performance['Mean_Actual'], 'o-', label='Actual', linewidth=2, markersize=8)\n",
    "axes[1,1].plot(years, yearly_performance['Mean_Predicted'], 's--', label='Predicted', linewidth=2, markersize=7)\n",
    "axes[1,1].set_xlabel('Year')\n",
    "axes[1,1].set_ylabel('Mean Yield (tonnes/ha)')\n",
    "axes[1,1].set_title('Mean Yield Trends')\n",
    "axes[1,1].legend()\n",
    "axes[1,1].grid(True, alpha=0.3)\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---\n",
    "## 4. Climate Scenario Testing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"CLIMATE SCENARIO TESTING\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Define climate scenarios\n",
    "scenarios = {\n",
    "    'baseline': {'temp_change': 0, 'rain_change': 1.0, 'co2_change': 0},\n",
    "    'moderate_warming': {'temp_change': 1.5, 'rain_change': 0.95, 'co2_change': 30},\n",
    "    'high_warming': {'temp_change': 2.0, 'rain_change': 0.9, 'co2_change': 50},\n",
    "    'extreme_warming': {'temp_change': 3.0, 'rain_change': 0.85, 'co2_change': 80},\n",
    "    'wet_scenario': {'temp_change': 1.5, 'rain_change': 1.1, 'co2_change': 30},\n",
    "    'dry_scenario': {'temp_change': 2.0, 'rain_change': 0.8, 'co2_change': 50}\n",
    "}\n",
    "\n",
    "print(\"\\nTesting climate scenarios:\")\n",
    "for name, params in scenarios.items():\n",
    "    print(f\"  {name}: Temp +{params['temp_change']}Â°C, \" +\n",
    "          f\"Rain {params['rain_change']*100:.0f}%, CO2 +{params['co2_change']} ppm\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Run scenario analysis\n",
    "scenario_results = {}\n",
    "\n",
    "for scenario_name, changes in scenarios.items():\n",
    "    # Create modified test data\n",
    "    X_scenario = X_fnn_test.copy()\n",
    "    \n",
    "    # Get column indices for climate variables\n",
    "    temp_cols = [fnn_feature_cols.index(col) for col in ['Avg_Temp_C', 'Min_Temp_C', 'Max_Temp_C']]\n",
    "    rain_cols = [fnn_feature_cols.index(col) for col in ['Rainfall_mm', 'Max_Daily_Rainfall_